<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[并发容器ConcurrentHashMap]]></title>
    <url>%2Fjava-concurrenthashmap.html</url>
    <content type="text"><![CDATA[原文出处：pettyandydog HashMap在put的时候，插入的元素超过了容量（由负载因子决定）的范围就会触发扩容操作，就是rehash，这个会重新将原数组的内容重新hash到新的扩容数组中，在多线程的环境下，存在同时其他的元素也在进行put操作，如果hash值相同，可能出现同时在同一数组下用链表表示，造成闭环，导致在get时会出现死循环，所以HashMap是线程不安全的。我们来了解另一个键值存储集合HashTable，它是线程安全的，它在所有涉及到多线程操作的都加上了synchronized关键字来锁住整个table，这就意味着所有的线程都在竞争一把锁，在多线程的环境下，它是安全的，但是无疑是效率低下的。其实HashTable有很多的优化空间，锁住整个table这么粗暴的方法可以变相的柔和点，比如在多线程的环境下，对不同的数据集进行操作时其实根本就不需要去竞争一个锁，因为他们不同hash值，不会因为rehash造成线程不安全，所以互不影响，这就是锁分离技术，将锁的粒度降低，利用多个锁来控制多个小的table，这就是这篇文章的主角ConcurrentHashMap JDK1.7版本的核心思想。 ConcurrentHashMap可以做到读取数据不加锁，并且其内部的结构可以让其在进行写操作的时候能够将锁的粒度保持地尽量地小，不用对整个ConcurrentHashMap加锁。 JDK1.7的实现在java 8 以前ConcurrentHashMap使用分段锁技术，将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问，能够实现真正的并发访问。 java 8 中。实现线程安全的思想已经完全变了，它摒弃了Segment（锁段）的概念，而是启用了一种全新的方式实现,利用CAS算法。它沿用了与它同时期的HashMap版本的思想，底层依然由“数组”+链表+红黑树的方式思想，但是为了做到并发，又增加了很多辅助的类，例如TreeBin，Traverser等对象内部类。 ConcurrentHashMap为了提高本身的并发能力，在内部采用了一个叫做Segment的结构，一个Segment其实就是一个类Hash Table的结构，Segment内部维护了一个链表数组，我们用下面这一幅图来看下ConcurrentHashMap的内部结构： 从图中可以看到，ConcurrentHashMap内部分为很多个Segment，每一个Segment拥有一把锁，然后每个Segment（继承ReentrantLock）下面包含很多个HashEntry列表数组。对于一个key，需要经过三次（为什么要hash三次下文会详细讲解）hash操作，才能最终定位这个元素的位置，这三次hash分别为： 对于一个key，先进行一次hash操作，得到hash值h1，也即h1 = hash1(key)； 将得到的h1的高几位进行第二次hash，得到hash值h2，也即h2 = hash2(h1高几位)，通过h2能够确定该元素的放在哪个Segment； 将得到的h1进行第三次hash，得到hash值h3，也即h3 = hash3(h1)，通过h3能够确定该元素放置在哪个HashEntry。 初始化ConcurrentHashMap的初始化是会通过位与运算来初始化Segment的大小，用ssize来表示，如下所示123456int sshift = 0;int ssize = 1;while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1;&#125; 如上所示，因为ssize用位于运算来计算（ssize &lt;&lt;=1），所以Segment的大小取值都是以2的N次方，无关concurrencyLevel的取值，当然concurrencyLevel最大只能用16位的二进制来表示，即65536，换句话说，Segment的大小最多65536个，没有指定concurrencyLevel元素初始化，Segment的大小ssize默认为16 每一个Segment元素下的HashEntry的初始化也是按照位于运算来计算，用cap来表示，如下所示 123int cap = 1;while (cap &lt; c) cap &lt;&lt;= 1; 如上所示，HashEntry大小的计算也是2的N次方（cap &lt;&lt;=1）， cap的初始值为1，所以HashEntry最小的容量为2 put操作对于ConcurrentHashMap的数据插入，这里要进行两次Hash去定位数据的存储位置1static class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; 从上Segment的继承体系可以看出，Segment实现了ReentrantLock,也就带有锁的功能，当执行put操作时，会进行第一次key的hash来定位Segment的位置，如果该Segment还没有初始化，即通过CAS操作进行赋值，然后进行第二次hash操作，找到相应的HashEntry的位置，这里会利用继承过来的锁的特性，在将数据插入指定的HashEntry位置时（链表的尾端），会通过继承ReentrantLock的tryLock（）方法尝试去获取锁，如果获取成功就直接插入相应的位置，如果已经有线程获取该Segment的锁，那当前线程会以自旋的方式去继续的调用tryLock（）方法去获取锁，超过指定次数就挂起，等待唤醒。 get操作ConcurrentHashMap的get操作跟HashMap类似，只是ConcurrentHashMap第一次需要经过一次hash定位到Segment的位置，然后再hash定位到指定的HashEntry，遍历该HashEntry下的链表进行对比，成功就返回，不成功就返回null。 size操作计算ConcurrentHashMap的元素大小是一个有趣的问题，因为他是并发操作的，就是在你计算size的时候，他还在并发的插入数据，可能会导致你计算出来的size和你实际的size有相差（在你return size的时候，插入了多个数据），要解决这个问题，JDK1.7版本用两种方案。 123456789101112131415161718192021try &#123; for (;;) &#123; if (retries++ == RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) ensureSegment(j).lock(); // force creation &#125; sum = 0L; size = 0; overflow = false; for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; sum += seg.modCount; int c = seg.count; if (c &lt; 0 || (size += c) &lt; 0) overflow = true; &#125; &#125; if (sum == last) break; last = sum; &#125; &#125;finally &#123; if (retries &gt; RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); &#125;&#125; 第一种方案他会使用不加锁的模式去尝试多次计算ConcurrentHashMap的size，最多三次，比较前后两次计算的结果，结果一致就认为当前没有元素加入，计算的结果是准确的； 第二种方案是如果第一种方案不符合，他就会给每个Segment加上锁，然后计算ConcurrentHashMap的size返回。 JDK1.8的实现JDK1.8的实现已经摒弃了Segment的概念，而是直接用Node数组+链表+红黑树的数据结构来实现，并发控制使用Synchronized和CAS来操作，整个看起来就像是优化过且线程安全的HashMap，虽然在JDK1.8中还能看到Segment的数据结构，但是已经简化了属性，只是为了兼容旧版本。 在深入JDK1.8的put和get实现之前要知道一些常量设计和数据结构，这些是构成ConcurrentHashMap实现结构的基础，下面看一下基本属性： 123456789101112131415161718192021222324252627282930313233343536// node数组最大容量：2^30=1073741824private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 默认初始值，必须是2的幕数private static final int DEFAULT_CAPACITY = 16;//数组可能最大值，需要与toArray（）相关方法关联static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;//并发级别，遗留下来的，为兼容以前的版本private static final int DEFAULT_CONCURRENCY_LEVEL = 16;// 负载因子private static final float LOAD_FACTOR = 0.75f;// 链表转红黑树阀值,&gt; 8 链表转换为红黑树static final int TREEIFY_THRESHOLD = 8;//树转链表阀值，小于等于6（tranfer时，lc、hc=0两个计数器分别++记录原bin、新binTreeNode数量，&lt;=UNTREEIFY_THRESHOLD 则untreeify(lo)）static final int UNTREEIFY_THRESHOLD = 6;static final int MIN_TREEIFY_CAPACITY = 64;private static final int MIN_TRANSFER_STRIDE = 16;private static int RESIZE_STAMP_BITS = 16;// 2^15-1，help resize的最大线程数private static final int MAX_RESIZERS = (1 &lt;&lt; (32 - RESIZE_STAMP_BITS)) - 1;// 32-16=16，sizeCtl中记录size大小的偏移量private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;// forwarding nodes的hash值static final int MOVED = -1; // 树根节点的hash值static final int TREEBIN = -2; // ReservationNode的hash值static final int RESERVED = -3; // 可用处理器数量static final int NCPU = Runtime.getRuntime().availableProcessors();//存放node的数组transient volatile Node&lt;K,V&gt;[] table;/*控制标识符，用来控制table的初始化和扩容的操作，不同的值有不同的含义 *当为负数时：-1代表正在初始化，-N代表有N-1个线程正在 进行扩容 *当为0时：代表当时的table还没有被初始化 *当为正数时：表示初始化或者下一次进行扩容的大小private transient volatile int sizeCtl; 基本属性定义了ConcurrentHashMap的一些边界以及操作时的一些控制，下面看一些内部的一些结构组成，这些是整个ConcurrentHashMap整个数据结构的核心。 NodeNode是ConcurrentHashMap存储结构的基本单元，继承于HashMap中的Entry，用于存储数据，源代码如下12345678910111213141516171819202122232425262728293031323334353637383940414243static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; //链表的数据结构 final int hash; final K key; //val和next都会在扩容时发生变化，所以加上volatile来保持可见性和禁止重排序 volatile V val; volatile Node&lt;K,V&gt; next; Node(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.val = val; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return val; &#125; public final int hashCode() &#123; return key.hashCode() ^ val.hashCode(); &#125; public final String toString()&#123; return key + "=" + val; &#125; //不允许更新value public final V setValue(V value) &#123; throw new UnsupportedOperationException(); &#125; public final boolean equals(Object o) &#123; Object k, v, u; Map.Entry&lt;?,?&gt; e; return ((o instanceof Map.Entry) &amp;&amp; (k = (e = (Map.Entry&lt;?,?&gt;)o).getKey()) != null &amp;&amp; (v = e.getValue()) != null &amp;&amp; (k == key || k.equals(key)) &amp;&amp; (v == (u = val) || v.equals(u))); &#125; //用于map中的get（）方法，子类重写 Node&lt;K,V&gt; find(int h, Object k) &#123; Node&lt;K,V&gt; e = this; if (k != null) &#123; do &#123; K ek; if (e.hash == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; &#125; while ((e = e.next) != null); &#125; return null; &#125;&#125; Node数据结构很简单，从上可知，就是一个链表，但是只允许对数据进行查找，不允许进行修改。 TreeNodeTreeNode继承与Node，但是数据结构换成了二叉树结构，它是红黑树的数据的存储结构，用于红黑树中存储数据，当链表的节点数大于8时会转换成红黑树的结构，他就是通过TreeNode作为存储结构代替Node来转换成黑红树源代码如下:123456789101112131415161718192021222324252627282930313233343536373839404142434445static final class TreeNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; //树形结构的属性定义 TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; //标志红黑树的红节点 TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next, TreeNode&lt;K,V&gt; parent) &#123; super(hash, key, val, next); this.parent = parent; &#125; Node&lt;K,V&gt; find(int h, Object k) &#123; return findTreeNode(h, k, null); &#125; //根据key查找 从根节点开始找出相应的TreeNode， final TreeNode&lt;K,V&gt; findTreeNode(int h, Object k, Class&lt;?&gt; kc) &#123; if (k != null) &#123; TreeNode&lt;K,V&gt; p = this; do &#123; int ph, dir; K pk; TreeNode&lt;K,V&gt; q; TreeNode&lt;K,V&gt; pl = p.left, pr = p.right; if ((ph = p.hash) &gt; h) p = pl; else if (ph &lt; h) p = pr; else if ((pk = p.key) == k || (pk != null &amp;&amp; k.equals(pk))) return p; else if (pl == null) p = pr; else if (pr == null) p = pl; else if ((kc != null || (kc = comparableClassFor(k)) != null) &amp;&amp; (dir = compareComparables(kc, k, pk)) != 0) p = (dir &lt; 0) ? pl : pr; else if ((q = pr.findTreeNode(h, k, kc)) != null) return q; else p = pl; &#125; while (p != null); &#125; return null; &#125;&#125; TreeBinTreeBin从字面含义中可以理解为存储树形结构的容器，而树形结构就是指TreeNode，所以TreeBin就是封装TreeNode的容器，它提供转换黑红树的一些条件和锁的控制，部分源码结构如下。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758static final class TreeBin&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; //指向TreeNode列表和根节点 TreeNode&lt;K,V&gt; root; volatile TreeNode&lt;K,V&gt; first; volatile Thread waiter; volatile int lockState; // 读写锁状态 static final int WRITER = 1; // 获取写锁的状态 static final int WAITER = 2; // 等待写锁的状态 static final int READER = 4; // 增加数据时读锁的状态 /** * 初始化红黑树 */ TreeBin(TreeNode&lt;K,V&gt; b) &#123; super(TREEBIN, null, null, null); this.first = b; TreeNode&lt;K,V&gt; r = null; for (TreeNode&lt;K,V&gt; x = b, next; x != null; x = next) &#123; next = (TreeNode&lt;K,V&gt;)x.next; x.left = x.right = null; if (r == null) &#123; x.parent = null; x.red = false; r = x; &#125; else &#123; K k = x.key; int h = x.hash; Class&lt;?&gt; kc = null; for (TreeNode&lt;K,V&gt; p = r;;) &#123; int dir, ph; K pk = p.key; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk); TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; r = balanceInsertion(r, x); break; &#125; &#125; &#125; &#125; this.root = r; assert checkInvariants(root); &#125; ......&#125; 初始化通过一个简单的例子以debug的视角看看ConcurrentHashMap的具体操作细节。123456789101112131415public class TestConcurrentHashMap&#123; public static void main(String[] args)&#123; ConcurrentHashMap&lt;String,String&gt; map = new ConcurrentHashMap(); //初始化ConcurrentHashMap //新增个人信息 map.put("id","1"); map.put("name","andy"); map.put("sex","男"); //获取姓名 String name = map.get("name"); Assert.assertEquals(name,"andy"); //计算大小 int size = map.size(); Assert.assertEquals(size,3); &#125;&#125; 通过new ConcurrentHashMap()来进行初始化：12public ConcurrentHashMap() &#123;&#125; 由上你会发现ConcurrentHashMap的初始化其实是一个空实现，并没有做任何事，这里后面会讲到，这也是和其他的集合类有区别的地方，初始化操作并不是在构造函数实现的，而是在put操作中实现，当然ConcurrentHashMap还提供了其他的构造函数，有指定容量大小或者指定负载因子，跟HashMap一样，这里就不做介绍了。 put操作在上面的例子中我们新增个人信息会调用put方法，我们来看下它的实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public V put(K key, V value) &#123; return putVal(key, value, false);&#125;/** Implementation for put and putIfAbsent */final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); //两次hash，减少hash冲突，可以均匀分布 int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; //对这个table进行迭代 Node&lt;K,V&gt; f; int n, i, fh; //这里就是上面构造方法没有进行初始化，在这里进行判断，为null就调用initTable进行初始化，属于懒汉模式初始化 if (tab == null || (n = tab.length) == 0) tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123;//如果i位置没有数据，就直接无锁插入 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; else if ((fh = f.hash) == MOVED)//如果在进行扩容，则先进行扩容操作 tab = helpTransfer(tab, f); else &#123; V oldVal = null; //如果以上条件都不满足，那就要进行加锁操作，也就是存在hash冲突，锁住链表或者红黑树的头结点 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; //表示该节点是链表结构 binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; //这里涉及到相同的key进行put就会覆盖原先的value if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; //插入链表尾部 pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123;//红黑树结构 Node&lt;K,V&gt; p; binCount = 2; //红黑树结构旋转插入 if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; // 如果链表的长度大于8时就会进行红黑树的转换 if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount);//统计size，并且检查是否需要扩容 return null;&#125; 这个put的过程很清晰，对当前的table进行无条件自循环直到put成功，可以分成以下六步流程来概述。 如果没有初始化就先调用initTable（）方法来进行初始化过程 如果没有hash冲突就直接CAS插入 如果还在进行扩容操作就先进行扩容 如果存在hash冲突，就加锁来保证线程安全，这里有两种情况，一种是链表形式就直接遍历到尾端插入，一种是红黑树就按照红黑树结构插入， 最后一个如果该链表的数量大于阈值8，就要先转换成黑红树的结构，break再一次进入循环 如果添加成功就调用addCount（）方法统计size，并且检查是否需要扩容 第一步 initTable（）现在我们来对每一步的细节进行源码分析，在第一步中，符合条件会进行初始化操作，我们来看看initTable（）方法： 12345678910111213141516171819202122232425/** * Initializes table, using the size recorded in sizeCtl. */private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123;//空的table才能进入初始化操作 if ((sc = sizeCtl) &lt; 0) //sizeCtl&lt;0表示其他线程已经在初始化了或者扩容了，挂起当前线程 Thread.yield(); // lost initialization race; just spin else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123;//CAS操作SIZECTL为-1，表示初始化状态 try &#123; if ((tab = table) == null || tab.length == 0) &#123; int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];//初始化 table = tab = nt; sc = n - (n &gt;&gt;&gt; 2);//记录下次扩容的大小 &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125; 第二步 Unsafe在第二步中没有hash冲突就直接调用Unsafe的方法CAS插入该元素，进入第三步如果容器正在扩容，则会调用helpTransfer（）方法帮助扩容，现在我们跟进helpTransfer（）方法看看： 12345678910111213141516171819202122/** *帮助从旧的table的元素复制到新的table中 */final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; Node&lt;K,V&gt;[] nextTab; int sc; if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; //新的table nextTba已经存在前提下才能帮助扩容 int rs = resizeStamp(tab.length); while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; transfer(tab, nextTab);//调用扩容方法 break; &#125; &#125; return nextTab; &#125; return table;&#125; 其实helpTransfer（）方法的目的就是调用多个工作线程一起帮助进行扩容，这样的效率就会更高，而不是只有检查到要扩容的那个线程进行扩容操作，其他线程就要等待扩容操作完成才能工作。 第三步 扩容transfer（）既然这里涉及到扩容的操作，我们也一起来看看扩容方法transfer（）：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; // 每核处理的量小于16，则强制赋值16 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range if (nextTab == null) &#123; // initiating try &#123; @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; //构建一个nextTable对象，其容量为原来容量的两倍 nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; transferIndex = n; &#125; int nextn = nextTab.length; // 连接点指针，用于标志位（fwd的hash值为-1，fwd.nextTable=nextTab） ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); // 当advance == true时，表明该节点已经处理过了 boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; // 控制 --i ,遍历原hash表中的节点 while (advance) &#123; int nextIndex, nextBound; if (--i &gt;= bound || finishing) advance = false; else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; // 用CAS计算得到的transferIndex else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; // 已经完成所有节点复制了 if (finishing) &#123; nextTable = null; table = nextTab; // table 指向nextTable sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); // sizeCtl阈值为原来的1.5倍 return; // 跳出死循环， &#125; // CAS 更扩容阈值，在这里面sizectl值减一，说明新加入一个线程参与到扩容操作 if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit &#125; &#125; // 遍历的节点为null，则放入到ForwardingNode 指针节点 else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); // f.hash == -1 表示遍历到了ForwardingNode节点，意味着该节点已经处理过了 // 这里是控制并发扩容的核心 else if ((fh = f.hash) == MOVED) advance = true; // already processed else &#123; // 节点加锁 synchronized (f) &#123; // 节点复制工作 if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; // fh &gt;= 0 ,表示为链表节点 if (fh &gt;= 0) &#123; // 构造两个链表 一个是原链表 另一个是原链表的反序排列 int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; // 在nextTable i 位置处插上链表 setTabAt(nextTab, i, ln); // 在nextTable i + n 位置处插上链表 setTabAt(nextTab, i + n, hn); // 在table i 位置处插上ForwardingNode 表示该节点已经处理过了 setTabAt(tab, i, fwd); // advance = true 可以执行--i动作，遍历节点 advance = true; &#125; // 如果是TreeBin，则按照红黑树进行处理，处理逻辑与上面一致 else if (f instanceof TreeBin) &#123; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; // 扩容后树节点个数若&lt;=6，将树转链表 ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125; &#125; 扩容过程有点复杂，这里主要涉及到多线程并发扩容,ForwardingNode的作用就是支持扩容操作，将已处理的节点和空节点置为ForwardingNode，并发处理时多个线程经过ForwardingNode就表示已经遍历了，就往后遍历，下图是多线程合作扩容的过程： 第四步 加入向链表或者红黑树里加节点 第五步 链表转红黑树介绍完扩容过程，我们再次回到put流程，在第四步中是向链表或者红黑树里加节点，到第五步，会调用treeifyBin（）方法进行链表转红黑树的过程。12345678910111213141516171819202122232425262728 Node&lt;K,V&gt; b; int n, sc; if (tab != null) &#123; //如果整个table的数量小于64，就扩容至原来的一倍，不转红黑树了 //因为这个阈值扩容可以减少hash冲突，不必要去转红黑树 if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) tryPresize(n &lt;&lt; 1); else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) &#123; synchronized (b) &#123; if (tabAt(tab, index) == b) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; e = b; e != null; e = e.next) &#123; //封装成TreeNode TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val, null, null); if ((p.prev = tl) == null) hd = p; else tl.next = p; tl = p; &#125; //通过TreeBin对象对TreeNode转换成红黑树 setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd)); &#125; &#125; &#125; &#125;&#125; 第六步 添加成功addCount（）到第六步表示已经数据加入成功了，现在调用addCount()方法计算ConcurrentHashMap的size，在原来的基础上加一，现在来看看addCount()方法。 1234567891011121314151617181920212223242526272829303132333435363738394041private final void addCount(long x, int check) &#123; CounterCell[] as; long b, s; //更新baseCount，table的数量，counterCells表示元素个数的变化 if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; CounterCell a; long v; int m; boolean uncontended = true; //如果多个线程都在执行，则CAS失败，执行fullAddCount，全部加入count if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; fullAddCount(x, uncontended); return; &#125; if (check &lt;= 1) return; s = sumCount(); &#125; //check&gt;=0表示需要进行扩容操作 if (check &gt;= 0) &#123; Node&lt;K,V&gt;[] tab, nt; int n, sc; while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; int rs = resizeStamp(n); if (sc &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; //当前线程发起库哦哦让操作，nextTable=null else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); s = sumCount(); &#125; &#125;&#125; put的流程现在已经分析完了，你可以从中发现，他在并发处理中使用的是乐观锁，当有冲突的时候才进行并发处理，而且流程步骤很清晰，但是细节设计的很复杂，毕竟多线程的场景也复杂。 get操作我们现在要回到开始的例子中，我们对个人信息进行了新增之后，我们要获取所新增的信息，使用String name = map.get(“name”)获取新增的name信息，现在我们依旧用debug的方式来分析下ConcurrentHashMap的获取方法get()：123456789101112131415161718192021public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); //计算两次hash if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123;//读取首节点的Node元素 if ((eh = e.hash) == h) &#123; //如果该节点就是首节点就返回 if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; //hash值为负值表示正在扩容，这个时候查的是ForwardingNode的find方法来定位到nextTable来 //查找，查找到就返回 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) &#123;//既不是首节点也不是ForwardingNode，那就往下遍历 if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; ConcurrentHashMap的get操作的流程很简单，也很清晰，可以分为三个步骤来描述 计算hash值，定位到该table索引位置，如果是首节点符合就返回； 如果遇到扩容的时候，会调用标志正在扩容节点ForwardingNode的find方法，查找该节点，匹配就返回； 以上都不符合的话，就往下遍历节点，匹配就返回，否则最后就返回null。 size操作最后我们来看下例子中最后获取size的方式int size = map.size();，现在让我们看下size()方法 1234567891011121314151617public int size() &#123; long n = sumCount(); return ((n &lt; 0L) ? 0 : (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n);&#125;final long sumCount() &#123; CounterCell[] as = counterCells; CounterCell a; //变化的数量 long sum = baseCount; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum;&#125; 在JDK1.8版本中，对于size的计算，在扩容和addCount()方法就已经有处理了，JDK1.7是在调用size()方法才去计算，其实在并发集合中去计算size是没有多大的意义的，因为size是实时在变的，只能计算某一刻的大小，但是某一刻太快了，人的感知是一个时间段，所以并不是很精确。 总结与思考其实可以看出JDK1.8版本的ConcurrentHashMap的数据结构已经接近HashMap，相对而言，ConcurrentHashMap只是增加了同步的操作来控制并发，从JDK1.7版本的ReentrantLock+Segment+HashEntry，到JDK1.8版本中synchronized+CAS+HashEntry+红黑树,相对而言，总结如下思考： JDK1.8的实现降低锁的粒度，JDK1.7版本锁的粒度是基于Segment的，包含多个HashEntry，而JDK1.8锁的粒度就是HashEntry（首节点） JDK1.8版本的数据结构变得更加简单，使得操作也更加清晰流畅，因为已经使用synchronized来进行同步，所以不需要分段锁的概念，也就不需要Segment这种数据结构了，由于粒度的降低，实现的复杂度也增加了 JDK1.8使用红黑树来优化链表，基于长度很长的链表的遍历是一个很漫长的过程，而红黑树的遍历效率是很快的，代替一定阈值的链表，这样形成一个最佳拍档 JDK1.8为什么使用内置锁synchronized来代替重入锁ReentrantLock，我觉得有以下几点： 因为粒度降低了，在相对而言的低粒度加锁方式，synchronized并不比ReentrantLock差，在粗粒度加锁中ReentrantLock可能通过Condition来控制各个低粒度的边界，更加的灵活，而在低粒度中，Condition的优势就没有了; JVM的开发团队从来都没有放弃synchronized，而且基于JVM的synchronized优化空间更大，使用内嵌的关键字比使用API更加自然 在大量的数据操作下，对于JVM的内存压力，基于API的ReentrantLock会开销更多的内存，虽然不是瓶颈，但是也是一个选择依据 参考 http://blog.csdn.net/u010412719/article/details/52145145 http://www.jianshu.com/p/e694f1e868ec https://my.oschina.net/liuxiaomian/blog/880088 https://bentang.me/tech/2016/12/01/jdk8-concurrenthashmap-1/ http://cmsblogs.com/?p=2283]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程：线程间协作的两种方式：wait、notify、notifyAll和Condition]]></title>
    <url>%2Fjava-thread-cooperation.html</url>
    <content type="text"><![CDATA[原文链接 Java并发编程：线程间协作的两种方式：wait、notify、notifyAll和Condition 在前面我们将了很多关于同步的问题，然而在现实中，需要线程之间的协作。比如说最经典的生产者-消费者模型：当队列满时，生产者需要等待队列有空间才能继续往里面放入商品，而在等待的期间内，生产者必须释放对临界资源（即队列）的占用权。因为生产者如果不释放对临界资源的占用权，那么消费者就无法消费队列中的商品，就不会让队列有空间，那么生产者就会一直无限等待下去。因此，一般情况下，当队列满时，会让生产者交出对临界资源的占用权，并进入挂起状态。然后等待消费者消费了商品，然后消费者通知生产者队列有空间了。同样地，当队列空时，消费者也必须等待，等待生产者通知它队列中有商品了。这种互相通信的过程就是线程间的协作。 今天我们就来探讨一下Java中线程协作的最常见的两种方式：利用Object.wait()、Object.notify()和使用Condition。 wait()、notify()和notifyAll()wait()、notify()和notifyAll()是Object类中的方法：12345678910111213141516171819202122232425/** * Wakes up a single thread that is waiting on this object's * monitor. If any threads are waiting on this object, one of them * is chosen to be awakened. The choice is arbitrary and occurs at * the discretion of the implementation. A thread waits on an object's * monitor by calling one of the wait methods */public final native void notify(); /** * Wakes up all threads that are waiting on this object's monitor. A * thread waits on an object's monitor by calling one of the * wait methods. */public final native void notifyAll(); /** * Causes the current thread to wait until either another thread invokes the * &#123;@link java.lang.Object#notify()&#125; method or the * &#123;@link java.lang.Object#notifyAll()&#125; method for this object, or a * specified amount of time has elapsed. * &lt;p&gt; * The current thread must own this object's monitor. */public final native void wait(long timeout) throws InterruptedException; 从这三个方法的文字描述可以知道以下几点信息： 1. wait()、notify()和notifyAll()方法是本地方法，并且为final方法，无法被重写。 2. 调用某个对象的wait()方法能让当前线程阻塞，并且当前线程必须拥有此对象的monitor（即锁） 3. 调用某个对象的notify()方法能够唤醒一个正在等待这个对象的monitor的线程，如果有多个线程都在等待这个对象的monitor，则只能唤醒其中一个线程； 4. 调用notifyAll()方法能够唤醒所有正在等待这个对象的monitor的线程； 有朋友可能会有疑问：为何这三个不是Thread类声明中的方法，而是Object类中声明的方法（当然由于Thread类继承了Object类，所以Thread也可以调用者三个方法）？其实这个问题很简单，由于每个对象都拥有monitor（即锁），所以让当前线程等待某个对象的锁，当然应该通过这个对象来操作了。而不是用当前线程来操作，因为当前线程可能会等待多个线程的锁，如果通过线程来操作，就非常复杂了。 上面已经提到，如果调用某个对象的wait()方法，当前线程必须拥有这个对象的monitor（即锁），因此调用wait()方法必须在同步块或者同步方法中进行（synchronized块或者synchronized方法）。 调用某个对象的wait()方法，相当于让当前线程交出此对象的monitor，然后进入等待状态，等待后续再次获得此对象的锁（Thread类中的sleep方法使当前线程暂停执行一段时间，从而让其他线程有机会继续执行，但它并不释放对象锁）； notify()方法能够唤醒一个正在等待该对象的monitor的线程，当有多个线程都在等待该对象的monitor的话，则只能唤醒其中一个线程，具体唤醒哪个线程则不得而知。 同样地，调用某个对象的notify()方法，当前线程也必须拥有这个对象的monitor，因此调用notify()方法必须在同步块或者同步方法中进行（synchronized块或者synchronized方法）。 nofityAll()方法能够唤醒所有正在等待该对象的monitor的线程，这一点与notify()方法是不同的。 这里要注意一点：notify()和notifyAll()方法只是唤醒等待该对象的monitor的线程，并不决定哪个线程能够获取到monitor。 举个简单的例子：假如有三个线程Thread1、Thread2和Thread3都在等待对象objectA的monitor，此时Thread4拥有对象objectA的monitor，当在Thread4中调用objectA.notify()方法之后，Thread1、Thread2和Thread3只有一个能被唤醒。注意，被唤醒不等于立刻就获取了objectA的monitor。假若在Thread4中调用objectA.notifyAll()方法，则Thread1、Thread2和Thread3三个线程都会被唤醒，至于哪个线程接下来能够获取到objectA的monitor就具体依赖于操作系统的调度了。 上面尤其要注意一点，一个线程被唤醒不代表立即获取了对象的monitor，只有等调用完notify()或者notifyAll()并退出synchronized块，释放对象锁后，其余线程才可获得锁执行。 下面看一个例子就明白了：1234567891011121314151617181920212223242526272829303132333435363738394041public class Test &#123; public static Object object = new Object(); public static void main(String[] args) &#123; Thread1 thread1 = new Thread1(); Thread2 thread2 = new Thread2(); thread1.start(); try &#123; Thread.sleep(200); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; thread2.start(); &#125; static class Thread1 extends Thread&#123; @Override public void run() &#123; synchronized (object) &#123; try &#123; object.wait(); &#125; catch (InterruptedException e) &#123; &#125; System.out.println("线程"+Thread.currentThread().getName()+"获取到了锁"); &#125; &#125; &#125; static class Thread2 extends Thread&#123; @Override public void run() &#123; synchronized (object) &#123; object.notify(); System.out.println("线程"+Thread.currentThread().getName()+"调用了object.notify()"); &#125; System.out.println("线程"+Thread.currentThread().getName()+"释放了锁"); &#125; &#125;&#125; 无论运行多少次，运行结果必定是：123线程Thread-1调用了object.notify()线程Thread-1释放了锁线程Thread-0获取到了锁 ConditionCondition是在java 1.5中才出现的，它用来替代传统的Object的wait()、notify()实现线程间的协作，相比使用Object的wait()、notify()，使用Condition1的await()、signal()这种方式实现线程间协作更加安全和高效。因此通常来说比较推荐使用Condition，在阻塞队列那一篇博文中就讲述到了，阻塞队列实际上是使用了Condition来模拟线程间协作。 Condition是个接口，基本的方法就是await()和signal()方法； Condition依赖于Lock接口，生成一个Condition的基本代码是lock.newCondition()； 调用Condition的await()和signal()方法，都必须在lock保护之内，就是说必须在lock.lock()和lock.unlock之间才可以使用。 Conditon中的await()对应Object的wait()； Condition中的signal()对应Object的notify()； Condition中的signalAll()对应Object的notifyAll()。 生产者-消费者模型的实现使用Object的wait()和notify()实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class Test &#123; private int queueSize = 10; private PriorityQueue&lt;Integer&gt; queue = new PriorityQueue&lt;Integer&gt;(queueSize); public static void main(String[] args) &#123; Test test = new Test(); Producer producer = test.new Producer(); Consumer consumer = test.new Consumer(); producer.start(); consumer.start(); &#125; class Consumer extends Thread&#123; @Override public void run() &#123; consume(); &#125; private void consume() &#123; while(true)&#123; synchronized (queue) &#123; while(queue.size() == 0)&#123; try &#123; System.out.println("队列空，等待数据"); queue.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); queue.notify(); &#125; &#125; queue.poll(); //每次移走队首元素 queue.notify(); System.out.println("从队列取走一个元素，队列剩余"+queue.size()+"个元素"); &#125; &#125; &#125; &#125; class Producer extends Thread&#123; @Override public void run() &#123; produce(); &#125; private void produce() &#123; while(true)&#123; synchronized (queue) &#123; while(queue.size() == queueSize)&#123; try &#123; System.out.println("队列满，等待有空余空间"); queue.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); queue.notify(); &#125; &#125; queue.offer(1); //每次插入一个元素 queue.notify(); System.out.println("向队列取中插入一个元素，队列剩余空间："+(queueSize-queue.size())); &#125; &#125; &#125; &#125;&#125; 使用Condition实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public class Test &#123; private int queueSize = 10; private PriorityQueue&lt;Integer&gt; queue = new PriorityQueue&lt;Integer&gt;(queueSize); private Lock lock = new ReentrantLock(); private Condition notFull = lock.newCondition(); private Condition notEmpty = lock.newCondition(); public static void main(String[] args) &#123; Test test = new Test(); Producer producer = test.new Producer(); Consumer consumer = test.new Consumer(); producer.start(); consumer.start(); &#125; class Consumer extends Thread&#123; @Override public void run() &#123; consume(); &#125; private void consume() &#123; while(true)&#123; lock.lock(); try &#123; while(queue.size() == 0)&#123; try &#123; System.out.println("队列空，等待数据"); notEmpty.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; queue.poll(); //每次移走队首元素 notFull.signal(); System.out.println("从队列取走一个元素，队列剩余"+queue.size()+"个元素"); &#125; finally&#123; lock.unlock(); &#125; &#125; &#125; &#125; class Producer extends Thread&#123; @Override public void run() &#123; produce(); &#125; private void produce() &#123; while(true)&#123; lock.lock(); try &#123; while(queue.size() == queueSize)&#123; try &#123; System.out.println("队列满，等待有空余空间"); notFull.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; queue.offer(1); //每次插入一个元素 notEmpty.signal(); System.out.println("向队列取中插入一个元素，队列剩余空间："+(queueSize-queue.size())); &#125; finally&#123; lock.unlock(); &#125; &#125; &#125; &#125;&#125; 参考资料 《Java编程思想》 http://blog.csdn.net/ns_code/article/details/17225469 http://blog.csdn.net/ghsau/article/details/7481142]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里巴巴Java开发手册中容易踩的坑]]></title>
    <url>%2Falibaba-java-prochip.html</url>
    <content type="text"><![CDATA[阿里巴巴Java开发手册地址：阿里巴巴Java开发手册（纪念版）.pdf 开始看的时候还是终极版，不知道什么时候又出到了纪念版，听说之前还有个完美版，感觉词穷了，期待下一版本狗年限定版。撇开了，很实用的规范内容，值得看。 记录下个人需要重点学习的地方，以及平时容易忽略的问题。 编码规范命名风格各层命名规约Service/DAO 层方法命名规约 获取单个对象的方法用 get 做前缀。 获取多个对象的方法用 list 做前缀。 获取统计值的方法用 count 做前缀。 插入的方法用 save/insert 做前缀。 删除的方法用 remove/delete 做前缀。 修改的方法用 update 做前缀。 领域模型命名规约 数据对象：xxxDO，xxx 即为数据表名。 数据传输对象：xxxDTO，xxx 为业务领域相关的名称。 展示对象：xxxVO，xxx 一般为网页名称。 POJO 是 DO/DTO/BO/VO 的统称，禁止命名成 xxxPOJO。 常量定义 不允许任何魔法值（即未经定义的常量）直接出现在代码中。 将包或者工程内部的共享变量，放在相应的constant 下，例如，一个模块下的常量：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091/** * 常量 * @date 2016年11月15日 下午1:23:52 */public class Constant &#123; /** 超级管理员ID */ public static final int SUPER_ADMIN = 1; /** * 菜单类型 * * @date 2016年11月15日 下午1:24:29 */ public enum MenuType &#123; /** * 目录 */ CATALOG(0), /** * 菜单 */ MENU(1), /** * 按钮 */ BUTTON(2); private int value; private MenuType(int value) &#123; this.value = value; &#125; public int getValue() &#123; return value; &#125; &#125; /** * 定时任务状态 * */ public enum ScheduleStatus &#123; /** * 正常 */ NORMAL(0), /** * 暂停 */ PAUSE(1); private int value; private ScheduleStatus(int value) &#123; this.value = value; &#125; public int getValue() &#123; return value; &#125; &#125; /** * 云服务商 */ public enum CloudService &#123; /** * 七牛云 */ QINIU(1), /** * 阿里云 */ ALIYUN(2), /** * 腾讯云 */ QCLOUD(3); private int value; private CloudService(int value) &#123; this.value = value; &#125; public int getValue() &#123; return value; &#125; &#125;&#125; OOP归约equals【强制】Object 的 equals 方法容易抛空指针异常，应使用常量或确定有值的对象来调用 equals。 正例：”test”.equals(object); 反例：object.equals(“test”); 说明：推荐使用 java.util.Objects#equals（JDK7 引入的工具类）。 【强制】所有的相同类型的包装类对象之间值的比较，全部使用 equals 方法比较。 说明：对于 Integer var = ? 在-128 至 127 范围内的赋值，Integer 对象是在IntegerCache.cache 产生，会复用已有对象，这个区间内的 Integer 值可以直接使用==进行 判断，但是这个区间之外的所有数据，都会在堆上产生，并不会复用已有对象，这是一个大坑， 推荐使用 equals 方法进行判断。 关于基本数据类型与包装数据类型的使用标准如下： 【强制】所有的 POJO 类属性必须使用包装数据类型。 【强制】RPC 方法的返回值和参数必须使用包装数据类型。 【推荐】所有的局部变量使用基本数据类型。 说明：POJO 类属性没有初值是提醒使用者在需要使用时，必须自己显式地进行赋值，任何 NPE 问题，或者入库检查，都由使用者来保证。 正例：数据库的查询结果可能是 null，因为自动拆箱，用基本数据类型接收有 NPE 风险。 反例：比如显示成交总额涨跌情况，即正负 x%，x 为基本数据类型，调用的 RPC 服务，调用 不成功时，返回的是默认值，页面显示为 0%，这是不合理的，应该显示成中划线。所以包装 数据类型的 null 值，能够表示额外的信息，如：远程调用失败，异常退出。 【强制】POJO 类必须写 toString 方法。使用 IDE 的中工具：source&gt; generate toString 时，如果继承了另一个 POJO 类，注意在前面加一下 super.toString。 说明：在方法执行抛出异常时，可以直接调用 POJO 的 toString()方法打印其属性值，便于排 查问题。 【推荐】使用索引访问用 String 的 split 方法得到的数组时，需做最后一个分隔符后有无 内容的检查，否则会有抛 IndexOutOfBoundsException 的风险。 说明： 1234String str = "a,b,c,,"; String[] ary = str.split(","); // 预期大于 3，结果是 3System.out.println(ary.length); 【推荐】final 可以声明类、成员变量、方法、以及本地变量，下列情况使用 final 关键字： 不允许被继承的类，如：String 类。 不允许修改引用的域对象，如：POJO 类的域变量。 不允许被重写的方法，如：POJO 类的 setter 方法。 不允许运行过程中重新赋值的局部变量。 避免上下文重复使用一个变量，使用 final 描述可以强制重新定义一个变量，方便更好 地进行重构。 【推荐】类成员与方法访问控制从严： 如果不允许外部直接通过 new 来创建对象，那么构造方法必须是 private。 工具类不允许有 public 或 default 构造方法。 类非 static 成员变量并且与子类共享，必须是 protected。 类非 static 成员变量并且仅在本类使用，必须是 private。 类 static 成员变量如果仅在本类使用，必须是 private。 若是 static 成员变量，必须考虑是否为 final。 类成员方法只供类内部调用，必须是 private。 类成员方法只对继承类公开，那么限制为 protected。 说明：任何类、方法、参数、变量，严控访问范围。过于宽泛的访问范围，不利于模块解耦。 思考：如果是一个 private 的方法，想删除就删除，可是一个 public 的 service 方法，或者 一个 public 的成员变量，删除一下，不得手心冒点汗吗？变量像自己的小孩，尽量在自己的 视线内，变量作用域太大，无限制的到处跑，那么你会担心的。 集合处理【强制】关于 hashCode 和 equals 的处理，遵循如下规则： 只要重写 equals，就必须重写 hashCode。 因为 Set 存储的是不重复的对象，依据 hashCode 和 equals 进行判断，所以 Set 存储的 对象必须重写这两个方法。 如果自定义对象做为 Map 的键，那么必须重写 hashCode 和 equals。 说明：String 重写了 hashCode 和 equals 方法，所以我们可以非常愉快地使用 String 对象 作为 key 来使用。 没有特需要求，使用编辑器自动生成的就好，这个对Hash表相关的数据结构的存储和读取有着很大的影响，重写的好，可以减少Hash碰撞。 【强制】使用集合转数组的方法，必须使用集合的 toArray(T[] array)，传入的是类型完全 一样的数组，大小就是 list.size()。 说明：使用 toArray 带参方法，入参分配的数组空间不够大时，toArray 方法内部将重新分配 内存空间，并返回新数组地址；如果数组元素大于实际所需，下标为[ list.size() ]的数组 元素将被置为 null，其它数组元素保持原值，因此最好将方法入参数组大小定义与集合元素 个数一致。 反例：直接使用 toArray 无参方法存在问题，此方法返回值只能是 Object[]类，若强转其它 类型数组将出现 ClassCastException 错误。 正例： 12345List&lt;String&gt; list = new ArrayList&lt;String&gt;(2); list.add("guan"); list.add("bao"); String[] array = new String[list.size()]; array = list.toArray(array); 【强制】使用工具类 Arrays.asList()把数组转换成集合时，不能使用其修改集合相关的方 法，它的 add/remove/clear 方法会抛出 UnsupportedOperationException 异常。 说明：asList 的返回对象是一个 Arrays 内部类，并没有实现集合的修改方法。Arrays.asList 体现的是适配器模式，只是转换接口，后台的数据仍是数组。12String[] str = new String[] &#123; &quot;you&quot;, &quot;wu&quot; &#125;; List list = Arrays.asList(str); 第一种情况：list.add(“yangguanbao”); 运行时异常。 第二种情况：str[0] = “gujin”; 那么 list.get(0)也会随之修改。 【强制】泛型通配符&lt;? extends T&gt;来接收返回的数据，此写法的泛型集合不能使用 add 方 法，而&lt;? super T&gt;不能使用 get 方法，做为接口调用赋值时易出错。 【强制】不要在 foreach 循环里进行元素的 remove/add 操作。remove 元素请使用 Iterator 方式，如果并发操作，需要对 Iterator 对象加锁。 正例： 1234567Iterator&lt;String&gt; iterator = list.iterator(); while (iterator.hasNext()) &#123; String item = iterator.next(); if (删除元素的条件) &#123; iterator.remove(); &#125; &#125; 【强制】 在 JDK7 版本及以上，Comparator 要满足如下三个条件，不然 Arrays.sort， Collections.sort 会报 IllegalArgumentException 异常。 说明：三个条件如下 x，y 的比较结果和 y，x 的比较结果相反。 x&gt;y，y&gt;z，则 x&gt;z。 x=y，则 x，z 比较结果和 y，z 比较结果相同。 反例：下例中没有处理相等的情况，实际使用中可能会出现异常： 123456new Comparator&lt;Student&gt;() &#123; @Override public int compare(Student o1, Student o2) &#123; return o1.getId() &gt; o2.getId() ? 1 : -1; &#125; &#125;; 【推荐】使用 entrySet 遍历 Map 类集合 KV，而不是 keySet 方式进行遍历。 说明：keySet 其实是遍历了 2 次，一次是转为 Iterator 对象，另一次是从 hashMap 中取出 key 所对应的 value。而 entrySet 只是遍历了一次就把 key 和 value 都放到了 entry 中，效 率更高。如果是 JDK8，使用 Map.foreach 方法。 正例：values()返回的是 V 值集合，是一个 list 集合对象；keySet()返回的是 K 值集合，是 一个 Set 集合对象；entrySet()返回的是 K-V 值组合集合。 【推荐】高度注意 Map 类集合 K/V 能不能存储 null 值的情况，如下表格： 集合类 Key Value Super 说明 Hashtable 不允许为 null 不允许为 null Dictionary 线程安全 ConcurrentHashMap 不允许为 null 不允许为 null AbstractMap 锁分段技术（JDK8:CAS） TreeMap 不允许为 null 允许为 null AbstractMap 线程不安全 HashMap 允许为 null 允许为 null AbstractMap 线程不安全 反例： 由于 HashMap 的干扰，很多人认为 ConcurrentHashMap 是可以置入 null 值，而事实上， 存储 null 值时会抛出 NPE 异常。 【参考】合理利用好集合的有序性(sort)和稳定性(order)，避免集合的无序性(unsort)和 不稳定性(unorder)带来的负面影响。 说明：有序性是指遍历的结果是按某种比较规则依次排列的。稳定性指集合每次遍历的元素次 序是一定的。如：ArrayList 是 order/unsort；HashMap 是 unorder/unsort；TreeSet 是 order/sort。 【参考】利用 Set 元素唯一的特性，可以快速对一个集合进行去重操作，避免使用 List 的 contains 方法进行遍历、对比、去重操作。 并发处理【强制】获取单例对象需要保证线程安全，其中的方法也要保证线程安全。 说明：资源驱动类、工具类、单例工厂类都需要注意。 【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样 的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 说明：Executors 返回的线程池对象的弊端如下： FixedThreadPool 和 SingleThreadPool: 允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。 CachedThreadPool 和 ScheduledThreadPool: 允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。 【强制】高并发时，同步调用应该去考量锁的性能损耗。能用无锁数据结构，就不要用锁；能 锁区块，就不要锁整个方法体；能用对象锁，就不要用类锁。 【强制】对多个资源、数据库表、对象同时加锁时，需要保持一致的加锁顺序，否则可能会造 成死锁。 说明：线程一需要对表 A、B、C 依次全部加锁后才可以进行更新操作，那么线程二的加锁顺序 也必须是 A、B、C，否则可能出现死锁。 【推荐】使用 CountDownLatch 进行异步转同步操作，每个线程退出前必须调用 countDown 方法，线程执行代码注意 catch 异常，确保 countDown 方法被执行到，避免主线程无法执行 至 await 方法，直到超时才返回结果。 说明：注意，子线程抛出异常堆栈，不能在主线程 try-catch 到。 【推荐】在并发场景下，通过双重检查锁（double-checked locking）实现延迟初始化的优 化问题隐患(可参考 The “Double-Checked Locking is Broken” Declaration)，推荐解 决方案中较为简单一种（适用于 JDK5 及以上版本），将目标属性声明为 volatile 型。 【参考】volatile 解决多线程内存不可见问题。对于一写多读，是可以解决变量同步问题， 但是如果多写，同样无法解决线程安全问题。如果是 count++操作，使用如下类实现： AtomicInteger count = new AtomicInteger(); count.addAndGet(1); 如果是 JDK8，推 荐使用 LongAdder 对象，比 AtomicLong 性能更好（减少乐观锁的重试次数）。 【参考】ThreadLocal 无法解决共享对象的更新问题，ThreadLocal 对象建议使用 static 修饰。这个变量是针对一个线程内所有操作共享的，所以设置为静态变量，所有此类实例共享 此静态变量 ，也就是说在类第一次被使用时装载，只分配一块存储空间，所有此类的对象(只 要是这个线程内定义的)都可以操控这个变量。 控制语句【强制】在 if/else/for/while/do 语句中必须使用大括号。即使只有一行代码，避免采用 单行的编码方式：1if (condition) statements; 超过 3 层的 if-else 的逻辑判断代码可以使用卫语句、策略模式、状态模式等来实现 【参考】下列情形，需要进行参数校验： 调用频次低的方法。 执行时间开销很大的方法。此情形中，参数校验时间几乎可以忽略不计，但如果因为参 数错误导致中间执行回退，或者错误，那得不偿失。 需要极高稳定性和可用性的方法。 对外提供的开放接口，不管是 RPC/API/HTTP 接口。 敏感权限入口。 【参考】下列情形，不需要进行参数校验： 极有可能被循环调用的方法。但在方法说明里必须注明外部参数检查要求。 底层调用频度比较高的方法。毕竟是像纯净水过滤的最后一道，参数错误不太可能到底 层才会暴露问题。一般 DAO 层与 Service 层都在同一个应用中，部署在同一台服务器中，所 以 DAO 的参数校验，可以省略。 被声明成 private 只会被自己代码所调用的方法，如果能够确定调用方法的代码传入参 数已经做过检查或者肯定不会有问题，此时可以不校验参数。 注释归约【参考】特殊注释标记，请注明标记人与标记时间。注意及时处理这些标记，通过标记扫描， 经常清理此类标记。线上故障有时候就是来源于这些标记处的代码。 待办事宜（TODO）:（ 标记人，标记时间，[预计处理时间]） 表示需要实现，但目前还未实现的功能。这实际上是一个 Javadoc 的标签，目前的 Javadoc 还没有实现，但已经被广泛使用。只能应用于类，接口和方法（因为它是一个 Javadoc 标签）。 错误，不能工作（FIXME）:（标记人，标记时间，[预计处理时间]） 在注释中用 FIXME 标记某代码是错误的，而且不能工作，需要及时纠正的情况。 【推荐】方法的返回值可以为 null，不强制返回空集合，或者空对象等，必须添加注释充分 说明什么情况下会返回 null 值。调用方需要进行 null 判断防止 NPE 问题。 说明：本手册明确防止 NPE 是调用者的责任。即使被调用方法返回空集合或者空对象，对调用者来说，也并非高枕无忧，必须考虑到远程调用失败、序列化失败、运行时异常等场景返回 null 的情况。 【推荐】防止 NPE，是程序员的基本修养，注意 NPE 产生的场景： 返回类型为基本数据类型，return 包装数据类型的对象时，自动拆箱有可能产生 NPE。 反例：public int f() { return Integer 对象}， 如果为 null，自动解箱抛 NPE。 数据库的查询结果可能为 null。 集合里的元素即使 isNotEmpty，取出的数据元素也可能为 null。 远程调用返回对象时，一律要求进行空指针判断，防止 NPE。 对于 Session 中获取的数据，建议 NPE 检查，避免空指针。 级联调用 obj.getA().getB().getC()；一连串调用，易产生 NPE。 正例：使用 JDK8 的 Optional 类来防止 NPE 问题。 【推荐】定义时区分 unchecked / checked 异常，避免直接抛出 new RuntimeException()， 更不允许抛出 Exception 或者 Throwable，应使用有业务含义的自定义异常。推荐业界已定义 过的自定义异常，如：DAOException / ServiceException 等。 【参考】避免出现重复的代码（Don’t Repeat Yourself），即 DRY 原则。 说明：随意复制和粘贴代码，必然会导致代码的重复，在以后需要修改时，需要修改所有的副 本，容易遗漏。必要时抽取共性方法，或者抽象公共类，甚至是组件化。 正例：一个类中有多个 public 方法，都需要进行数行相同的参数校验操作，这个时候请抽取 日志规约【强制】应用中不可直接使用日志系统（Log4j、Logback）中的 API，而应依赖使用日志框架 SLF4J 中的 API，使用门面模式的日志框架，有利于维护和各个类的日志处理方式统一。123import org.slf4j.Logger; import org.slf4j.LoggerFactory;private static final Logger logger = LoggerFactory.getLogger(Abc.class); 【强制】对 trace/debug/info 级别的日志输出，必须使用条件输出形式或者使用占位符的方 式。 说明：logger.debug(“Processing trade with id: “ + id + “ and symbol: “ + symbol); 如果日志级别是 warn，上述日志不会打印，但是会执行字符串拼接操作，如果 symbol 是对象， 会执行 toString()方法，浪费了系统资源，执行了上述操作，最终日志却没有打印。 正例：（条件） 123if (logger.isDebugEnabled()) &#123; logger.debug("Processing trade with id: " + id + " and symbol: " + symbol); &#125; 正例：（占位符） 1logger.debug("Processing trade with id: &#123;&#125; and symbol : &#123;&#125; ", id, symbol); 【强制】避免重复打印日志，浪费磁盘空间，务必在 log4j.xml 中设置 additivity=false 【强制】异常信息应该包括两类信息：案发现场信息和异常堆栈信息。如果不处理，那么通过 关键字 throws 往上抛出。 正例：1logger.error(各类参数或者对象 toString + "_" + e.getMessage(), e); 【参考】可以使用 warn 日志级别来记录用户输入参数错误的情况，避免用户投诉时，无所适 从。注意日志输出的级别，error 级别只记录系统逻辑出错、异常等重要的错误信息。如非必 要，请不要在此场景打出 error 级别。 单元测试【强制】好的单元测试必须遵守AIR 原则。 说明：单元测试在线上运行时，感觉像空气（AIR）一样并不存在，但在测试质量的保障上， 却是非常关键的。好的单元测试宏观上来说，具有自动化、独立性、可重复执行的特点。 A：Automatic（自动化） I：Independent（独立性） R：Repeatable（可重复） 【强制】单元测试应该是全自动执行的，并且非交互式的。测试框架通常是定期执行的，执行 过程必须完全自动化才有意义。输出结果需要人工检查的测试不是一个好的单元测试。单元测 试中不准使用 System.out来进行人肉验证，必须使用 assert 来验证。 【推荐】单元测试的基本目标：语句覆盖率达到 70%；核心模块的语句覆盖率和分支覆盖率都 要达到 100% 说明：在工程规约的应用分层中提到的 DAO 层，Manager 层，可重用度高的 Service，都应该 进行单元测试。 【推荐】编写单元测试代码遵守 BCDE 原则，以保证被测试模块的交付质量。 B：Border，边界值测试，包括循环边界、特殊取值、特殊时间点、数据顺序等。 C：Correct，正确的输入，并得到预期的结果。 D：Design，与设计文档相结合，来编写单元测试。 E：Error，强制错误信息输入（如：非法数据、异常流程、非业务允许输入等），并得 到预期的结果。 【推荐】对于数据库相关的查询，更新，删除等操作，不能假设数据库里的数据是存在的， 或者直接操作数据库把数据插入进去，请使用程序插入或者导入数据的方式来准备数据。 反例：删除某一行数据的单元测试，在数据库中，先直接手动增加一行作为删除目标，但是这 一行新增数据并不符合业务插入规则，导致测试结果异常。 【推荐】和数据库相关的单元测试，可以设定自动回滚机制，不给数据库造成脏数据。或者 对单元测试产生的数据有明确的前后缀标识。 正例：在 RDC 内部单元测试中，使用 RDC_UNITTEST的前缀标识数据。 【推荐】对于不可测的代码建议做必要的重构，使代码变得可测，避免为了达到测试要求而 书写不规范测试代码。 【参考】为了更方便地进行单元测试，业务代码应避免以下情况： 构造方法中做的事情过多。 存在过多的全局变量和静态方法。 存在过多的外部依赖。 存在过多的条件语句。 说明：多层条件语句建议使用卫语句、策略模式、状态模式等方式重构。 【参考】不要对单元测试存在如下误解： 那是测试同学干的事情。本文是开发手册，凡是本文内容都是与开发同学强相关的。 单元测试代码是多余的。汽车的整体功能与各单元部件的测试正常与否是强相关的。 单元测试代码不需要维护。一年半载后，那么单元测试几乎处于废弃状态。 单元测试与线上故障没有辩证关系。好的单元测试能够最大限度地规避线上故障。 安全规约【强制】隶属于用户个人的页面或者功能必须进行权限控制校验。 说明：防止没有做水平权限校验就可随意访问、修改、删除别人的数据，比如查看他人的私信 内容、修改他人的订单。 【强制】用户敏感数据禁止直接展示，必须对展示数据进行脱敏。 说明：查看个人手机号码会显示成:158****9119，隐藏中间 4 位，防止隐私泄露。 【强制】用户请求传入的任何参数必须做有效性验证。 说明：忽略参数校验可能导致的问题： page size 过大导致内存溢出 恶意 order by 导致数据库慢查询 任意重定向  SQL 注入 反序列化注入 正则输入源串拒绝服务 ReDoS 说明：Java 代码用正则来验证客户端的输入，有些正则写法验证普通用户输入没有问题， 但是如果攻击人员使用的是特殊构造的字符串来验证，有可能导致死循环的结果。 【强制】在使用平台资源，譬如短信、邮件、电话、下单、支付，必须实现正确的防重放限制， 如数量限制、疲劳度控制、验证码校验，避免被滥刷、资损。 说明：如注册时发送验证码到手机，如果没有限制次数和频率，那么可以利用此功能骚扰到其 它用户，并造成短信平台资源浪费。 【推荐】发贴、评论、发送即时消息等用户生成内容的场景必须实现防刷、文本内容违禁词过 滤等风控策略。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BeanUtils的复制]]></title>
    <url>%2Fspring-beanutils.html</url>
    <content type="text"><![CDATA[有一个子类继承了父类的属性，但是有很多属性值需要复制，单纯的靠set 或者构造函数肯定很不美观，出于“懒”的目的，了解到spring beans里面提供了BeanUtils工具类，看下copyProperties方法满足需要，是用反射做的。 方法源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * Copy the property values of the given source bean into the given target bean. * &lt;p&gt;Note: The source and target classes do not have to match or even be derived * from each other, as long as the properties match. Any bean properties that the * source bean exposes but the target bean does not will silently be ignored. * @param source the source bean * @param target the target bean * @param editable the class (or interface) to restrict property setting to * @param ignoreProperties array of property names to ignore * @throws BeansException if the copying failed * @see BeanWrapper */ private static void copyProperties(Object source, Object target, Class&lt;?&gt; editable, String... ignoreProperties) throws BeansException &#123; Assert.notNull(source, "Source must not be null"); Assert.notNull(target, "Target must not be null"); Class&lt;?&gt; actualEditable = target.getClass(); if (editable != null) &#123; if (!editable.isInstance(target)) &#123; throw new IllegalArgumentException("Target class [" + target.getClass().getName() + "] not assignable to Editable class [" + editable.getName() + "]"); &#125; actualEditable = editable; &#125; //获取targetCLass所有属性及属性的它set,get的方法，描述属性 PropertyDescriptor[] targetPds = getPropertyDescriptors(actualEditable); List&lt;String&gt; ignoreList = (ignoreProperties != null ? Arrays.asList(ignoreProperties) : null); //遍历每个属性 for (PropertyDescriptor targetPd : targetPds) &#123; //根据 这个属性 获取目标类的set方法 Method writeMethod = targetPd.getWriteMethod(); //检测 if (writeMethod != null &amp;&amp; (ignoreList == null || !ignoreList.contains(targetPd.getName()))) &#123; // 获取 源类 的相应的描述属性 PropertyDescriptor sourcePd = getPropertyDescriptor(source.getClass(), targetPd.getName()); if (sourcePd != null) &#123; // 获取源类的get方法 Method readMethod = sourcePd.getReadMethod(); //检测方法，然后获取值，写入 if (readMethod != null &amp;&amp; ClassUtils.isAssignable(writeMethod.getParameterTypes()[0], readMethod.getReturnType())) &#123; try &#123; if (!Modifier.isPublic(readMethod.getDeclaringClass().getModifiers())) &#123; readMethod.setAccessible(true); &#125; Object value = readMethod.invoke(source); if (!Modifier.isPublic(writeMethod.getDeclaringClass().getModifiers())) &#123; writeMethod.setAccessible(true); &#125; writeMethod.invoke(target, value); &#125; catch (Throwable ex) &#123; throw new FatalBeanException( "Could not copy property '" + targetPd.getName() + "' from source to target", ex); &#125; &#125; &#125; &#125; &#125; &#125; 方法前面的文档告诉了我们：将源Bean复制到指定的Bean中，两个类不需要有关联，也不必是派生关系，只需要属性匹配即可。 学习代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193package com.devframe.util;import org.junit.Test;import org.springframework.beans.BeanUtils;import java.util.Date;/** * @author Zhang Kai * @version 1.0 * @since &lt;pre&gt;2017/12/1 14:13&lt;/pre&gt; */public class TestBeans &#123; @Test public void test1() &#123; try &#123; //首先设置一个学生，将它的基本属性复制给大学生，很方便的操作，不用set Student student = new Student("wuwii", new Date(1994 - 1990, 2 -1, 19), "WuHan", "123456"); UniversityStudent universityStudent = new UniversityStudent(); BeanUtils.copyProperties(student, universityStudent); System.out.println(universityStudent); //源和目标没有关联，部分属性也可以复制，有些属性没有也行。 String[] ignoreProperties = &#123;"name"&#125;; Adult_ adult = new Adult_(); BeanUtils.copyProperties(student, adult, ignoreProperties); System.out.printf("adule： %s%n", adult); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; //还有一些其他的实用方法 //建立一个字符串Date String date = "2008-8-8"; &#125;&#125;/** * 学生实体 * @author Zhang Kai */class Student &#123; /** * 姓名 */ private String name; /** * 出生年月 */ private Date birthDate; /** * 住址 */ private String address; /** * 身份证号 */ private String IDNumber; public Student() &#123; &#125; public Student(String name, Date birthDate, String address, String IDNumber) &#123; this.name = name; this.birthDate = birthDate; this.address = address; this.IDNumber = IDNumber; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; // copyProperties是调用的set方法 /*public void setName(String name) &#123; this.name = "keen"; &#125;*/ public Date getBirthDate() &#123; return birthDate; &#125; public void setBirthDate(Date birthDate) &#123; this.birthDate = birthDate; &#125; public String getAddress() &#123; return address; &#125; public void setAddress(String address) &#123; this.address = address; &#125; public String getIDNumber() &#123; return IDNumber; &#125; public void setIDNumber(String IDNumber) &#123; this.IDNumber = IDNumber; &#125; @Override public String toString() &#123; return "Student&#123;" + "name='" + name + '\'' + ", birthDate=" + birthDate + ", address='" + address + '\'' + ", IDNumber='" + IDNumber + '\'' + '&#125;'; &#125;&#125;/** * 大学生继承学生&lt;/br&gt; * @author Zhang Kai */class UniversityStudent extends Student &#123; /** * 专业 */ private String major; public String getMajor() &#123; return major; &#125; public void setMajor(String major) &#123; this.major = major; &#125; @Override public String toString() &#123; return super.toString() + " UniversityStudent&#123;" + "major='" + major + '\'' + '&#125;'; &#125;&#125;/** * 成年人 * @author Zhang Kai */class Adult_ &#123; /** * 姓名 */ private String name; /** * 出生年月 */ private Date birthDate; public Adult_() &#123; &#125; public Adult_(String name, Date birthDate) &#123; this.name = name; this.birthDate = birthDate; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Date getBirthDate() &#123; return birthDate; &#125; public void setBirthDate(Date birthDate) &#123; this.birthDate = birthDate; &#125; @Override public String toString() &#123; return "Adult_&#123;" + "name='" + name + '\'' + ", birthDate=" + birthDate + '&#125;'; &#125;&#125; 打印结果：12Student&#123;name=&apos;wuwii&apos;, birthDate=Fri Feb 19 00:00:00 CST 1904, address=&apos;WuHan&apos;, IDNumber=&apos;123456&apos;&#125; UniversityStudent&#123;major=&apos;null&apos;&#125;adule： Adule_&#123;name=&apos;null&apos;, birthDate=Fri Feb 19 00:00:00 CST 1904&#125; 出如反射机制的性能问题，如果有要求的话，还是建议使用构造函数吧，或者更换设计。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20171203]]></title>
    <url>%2Fomelette.html</url>
    <content type="text"><![CDATA[周末宅了下，肚子就饿得不行呀，动下手做点吃的，第一次做坑的不行啊。 这么多，傻眼了，糊了糊了。。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[事务的特性和@Transactional注解的使用]]></title>
    <url>%2Fjava-transactional.html</url>
    <content type="text"><![CDATA[@Transactional如何工作实现了EntityManager接口的持久化上下文代理并不是声明式事务管理的唯一部分，事实上包含三个组成部分： 事务的切面 事务管理器 EntityManager Proxy本身 事务切面事务的切面是一个“around（环绕）”切面，在注解的业务方法前后都可以被调用。实现切面的具体类是TransactionInterceptor。 事务的切面的主要职责：在’before’时，切面提供一个调用点，来决定被调用业务方法应该在正在进行事务的范围内运行，还是开始一个新的独立事务。在’after’时，切面需要确定事务被提交，回滚或者继续运行。在’before’时，事务切面自身不包含任何决策逻辑，是否开始新事务的决策委派给事务管理器完成。 新的Entity Manager是否应该被创建？ 是否应该开始新的事务？ 这些需要事务切面’before’逻辑被调用时决定。事务管理器的决策基于以下两点： 事务是否正在进行； 事务方法的propagation属性（比如REQUIRES_NEW总要开始新事务）。 事务管理器如果事务管理器确定要创建新事务，那么将： 创建一个新的entity managerentity manager绑定到当前线程从数据库连接池中获取连接将连接绑定到当前线程使用ThreadLocal变量将entity manager和数据库连接都绑定到当前线程。 事务运行时他们存储在线程中，当它们不再被使用时，事务管理器决定是否将他们清除。 程序的任何部分如果需要当前的entity manager和数据库连接都可以从线程中获取。 EntityManager proxy当业务方法调用entityManager.persist()时，这不是由entity manager直接调用的。而是业务方法调用代理，代理从线程获取当前的entity manager事务管理器将entity manager绑定到线程。 spring 中配置JPA事务在spring 的配置文件中配置jpa的事务：123456&lt;!-- Jpa 事务管理器 --&gt; &lt;bean id="transactionManager" class="org.springframework.orm.jpa.JpaTransactionManager"&gt; &lt;property name="entityManagerFactory" ref="entityManagerFactory" /&gt; &lt;/bean&gt; &lt;!-- 打开事务注解 --&gt; &lt;tx:annotation-driven transaction-manager="transactionManager"/&gt; 当然可以使用aop配置事务：12345678910111213141516171819&lt;!-- Jpa 事务管理器 --&gt; &lt;bean id="transactionManager" class="org.springframework.orm.jpa.JpaTransactionManager"&gt; &lt;property name="entityManagerFactory" ref="entityManagerFactory" /&gt; &lt;/bean&gt;&lt;!-- 声明式事务配置 --&gt; &lt;tx:advice id="txAdvice" transaction-manager="transactionManager"&gt; &lt;tx:attributes&gt; &lt;tx:method name="get*" propagation="NOT_SUPPORTED" read-only="true" /&gt; &lt;tx:method name="count*" propagation="NOT_SUPPORTED" read-only="true" /&gt; &lt;tx:method name="find*" propagation="NOT_SUPPORTED" read-only="true" /&gt; &lt;tx:method name="query*" propagation="NOT_SUPPORTED" read-only="true" /&gt; &lt;tx:method name="*" propagation="REQUIRED" rollback-for="Exception" /&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 只对业务逻辑层实施事务--&gt; &lt;aop:config&gt; &lt;aop:pointcut id="txPointcut" expression="execution(* com.devframe.service.impl.*.*(..))" /&gt; &lt;aop:advisor advice-ref="txAdvice" pointcut-ref="txPointcut"/&gt; &lt;/aop:config&gt; spring中事务的几个特性补充下，数据库中的事务的四大特性： 原子性（Atomicity）：原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，这和前面两篇博客介绍事务的功能是一样的概念，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。 一致性（Consistency）：一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。 隔离性（Isolation）：隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。 持久性（Durability）：持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。 事务隔离级别隔离级别是指若干个并发的事务之间的隔离程度。TransactionDefinition 接口中定义了五个表示隔离级别的常量： TransactionDefinition.ISOLATION_DEFAULT：这是默认值，表示使用底层数据库的默认隔离级别。对大部分数据库而言，通常这值就是TransactionDefinition.ISOLATION_READ_COMMITTED。 TransactionDefinition.ISOLATION_READ_UNCOMMITTED：该隔离级别表示一个事务可以读取另一个事务修改但还没有提交的数据。该级别不能防止脏读，不可重复读和幻读，因此很少使用该隔离级别。比如PostgreSQL实际上并没有此级别。 TransactionDefinition.ISOLATION_READ_COMMITTED：该隔离级别表示一个事务只能读取另一个事务已经提交的数据。该级别可以防止脏读，这也是大多数情况下的推荐值。 TransactionDefinition.ISOLATION_REPEATABLE_READ：该隔离级别表示一个事务在整个过程中可以多次重复执行某个查询，并且每次返回的记录都相同。该级别可以防止脏读和不可重复读。 TransactionDefinition.ISOLATION_SERIALIZABLE：所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。 补充下数据库中，如果不考虑事务的隔离性，会发生的几种问题： 脏读：脏读是指在一个事务处理过程里读取了另一个未提交的事务中的数据。当一个事务正在多次修改某个数据，而在这个事务中这多次的修改都还未提交，这时一个并发的事务来访问该数据，就会造成两个事务得到的数据不一致。 不可重复读：不可重复读是指在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了。例如事务T1在读取某一数据，而事务T2立马修改了这个数据并且提交事务给数据库，事务T1再次读取该数据就得到了不同的结果，发送了不可重复读。不可重复读和脏读的区别是，脏读是某一事务读取了另一个事务未提交的脏数据，而不可重复读则是读取了前一事务提交的数据。在某些情况下，不可重复读并不是问题，比如我们多次查询某个数据当然以最后查询得到的结果为主。但在另一些情况下就有可能发生问题，例如对于同一个数据A和B依次查询就可能不同，A和B就可能打起来了…… 虚读(幻读)：幻读是事务非独立执行时发生的一种现象。例如事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务T2中添加的，就好像产生幻觉一样，这就是发生了幻读。幻读和不可重复读都是读取了另一条已经提交的事务（这点就脏读不同），所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体（比如数据的个数）。 事务传播行为所谓事务的传播行为是指，如果在开始当前事务之前，一个事务上下文已经存在，此时有若干选项可以指定一个事务性方法的执行行为。在TransactionDefinition定义中包括了如下几个表示传播行为的常量： TransactionDefinition.PROPAGATION_REQUIRED：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。这是默认值。 TransactionDefinition.PROPAGATION_REQUIRES_NEW：创建一个新的事务，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。 TransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。 TransactionDefinition.PROPAGATION_MANDATORY：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。 TransactionDefinition.PROPAGATION_NESTED：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED。 选择默认的，即PROPAGATION_REQUIRED，事务具有传播机制，多个事务，对于已经存在的事务，下一个事务会加入当前事务。 事务超时所谓事务超时，就是指一个事务所允许执行的最长时间，如果超过该时间限制但事务还没有完成，则自动回滚事务。在 TransactionDefinition 中以 int 的值来表示超时时间，其单位是秒。 默认设置为底层事务系统的超时值，如果底层数据库事务系统没有设置超时值，那么就是none，没有超时限制。 事务只读属性只读事务用于客户代码只读但不修改数据的情形，只读事务用于特定情景下的优化，比如使用Hibernate的时候。 默认为读写事务。 “只读事务”并不是一个强制选项，它只是一个“暗示”，提示数据库驱动程序和数据库系统，这个事务并不包含更改数据的操作，那么JDBC驱动程序和数据库就有可能根据这种情况对该事务进行一些特定的优化，比方说不安排相应的数据库锁，以减轻事务对数据库的压力，毕竟事务也是要消耗数据库的资源的。但是你非要在“只读事务”里面修改数据，也并非不可以，只不过对于数据一致性的保护不像“读写事务”那样保险而已。因此，“只读事务”仅仅是一个性能优化的推荐配置而已，并非强制你要这样做不可。 spring事务回滚规则指示spring事务管理器回滚一个事务的推荐方法是在当前事务的上下文内抛出异常。spring事务管理器会捕捉任何未处理的异常，然后依据规则决定是否回滚抛出异常的事务。 默认配置下，spring只有在抛出的异常为运行时unchecked异常时才回滚该事务，也就是抛出的异常为RuntimeException的子类(Errors也会导致事务回滚)，而抛出checked异常则不会导致事务回滚。可以明确的配置在抛出那些异常时回滚事务，包括checked异常。也可以明确定义那些异常抛出时不回滚事务。还可以编程性的通过setRollbackOnly()方法来指示一个事务必须回滚，在调用完setRollbackOnly()后你所能执行的唯一操作就是回滚。 @Transactional注解属性 属性 类型 描述 value String 可选的限定描述符，指定使用的事务管理器 propagation enum: Propagation 可选的事务传播行为设置 isolation enum: Isolation 可选的事务隔离级别设置 readOnly boolean 读写或只读事务，默认读写 timeout int (in seconds granularity) 事务超时时间设置 rollbackFor Class对象数组，必须继承自Throwable 导致事务回滚的异常类数组 rollbackForClassName 类名数组，必须继承自Throwable 导致事务回滚的异常类名字数组 noRollbackFor Class对象数组，必须继承自Throwable 不会导致事务回滚的异常类数组 noRollbackForClassName 类名数组，必须继承自Throwable 不会导致事务回滚的异常类名字数组 使用方法 @Transactional 可以作用于接口、接口方法、类以及类方法上。当作用于类上时，该类的所有 public 方法将都具有该类型的事务属性，同时，我们也可以在方法级别使用该标注来覆盖类级别的定义。 虽然 @Transactional 注解可以作用于接口、接口方法、类以及类方法上，但是 Spring 建议不要在接口或者接口方法上使用该注解，因为这只有在使用基于接口的代理时它才会生效。另外， @Transactional 注解应该只被应用到 public 方法上，这是由 Spring AOP 的本质决定的。如果你在 protected、private 或者默认可见性的方法上使用 @Transactional 注解，这将被忽略，也不会抛出任何异常。 默认情况下，只有来自外部的方法调用才会被AOP代理捕获，也就是，类内部方法调用本类内部的其他方法并不会引起事务行为。 只要方法内部抛出rollbackFor设置的异常，就会回滚。 例如：在方法上加上1@Transactional(value="transactionManager", rollbackFor = Exception.class) 方法内部只要抛出指定的异常或者错误，就全部回滚。 补充，回滚异常是自己定义的异常类，最好按照要求继承RuntimeException。如果非常有必要在事务中捕捉异常，而且需要回滚事务，那么直接再将这个异常抛出就可以了，但是不建议这么使用。 参考文章： spring事物配置，声明式事务管理和基于@Transactional注解的使用 JPA和事务管理 Spring事务传播特性的浅析——事务方法嵌套调用的迷茫 数据库事务的四大特性以及事务的隔离级别]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[心底最柔软的爱]]></title>
    <url>%2Flove-of-soft.html</url>
    <content type="text"><![CDATA[晚上老妈又打电话给我了，其实前几天赶回去了一次，问我这边怎么样…… 记得以前总没好好吃饭，喜欢吃零食，弄得身体一直不是很好；喜欢玩游戏，不喜欢学习；很任性……总是忽略了爸妈的好，可能总是以为理所当然了。慢慢得懂了，其实爸妈的爱是理所当然的，但，是那种最笨拙的，最柔软的爱，也是要我们珍惜和回报的，因为他们不能陪我们度过一生，需要每个人才能完美。 记得给老爸买智能手机后，他说他要玩微信，但是他还不太会玩智能手机，帮他下好几个常用的软件，而且让我调成手写输入法，虽然慢慢的，一个一个字的划着输入，看得到他是真的高兴。老妈很少用手机的，虽然后来也给她买了个手机，回到家的时候也教她用，但是老妈真的很不喜欢玩手机耶。 其实老爸的斗地主很厉害的，但是没时间玩，现在有手机了，可以经常玩了；喜欢看新闻，现在看天气，很准的，总算不用多年前的12121了。 即使在现在长大成人了，爸妈还是总是来问衣服够不够穿；是的，在父母的眼里，孩子不管多大，永远都是小孩，做父母的总会把孩子成长的每个细节都记在心里；可能年轻人总是笨手笨脚的，还真的有点不会照顾后自己，才让父母还是如此操心的吧。 其实，都懂，长大了，我会好好的。尽管你们爱的笨拙，触动最柔软的部分，我也是会流泪的。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《嘉年华》的一点感想]]></title>
    <url>%2Fangels-wear-white.html</url>
    <content type="text"><![CDATA[看了嘉年华，这次没去电影院，主要是周末一直有事情，是通过网上非正规渠道看的，网址就不暴露了，私聊也不给。 感觉今年也贡献了好多张电影票了，实在是现在电影看得爆米花形式的，我只想去上厕所…… 这个电影还是没打算去电影院看，一个人去看电影好无聊呀；它是一个以女性的口吻来贯穿的。通过这个“幼女性侵”去讲述这个当前社会下这类人的生活状况。给人很大的震撼。 电影中小文和新新，经历这个恶魔的桥段，她们在什么都不懂的情况下，身边的人却对她们的排斥，父母的异样，政府和社会的妥协，让社会底层的人只能忍气吞声，最终她们渐渐的脱离了这个社会，让她们感觉到世界都塌下了。在单纯的年龄里，她们呢其实和正常的孩子们是一样的生活，学习，正式这种不平等的眼光，小文只能不断的渴求着成长，渴望着用化妆品和衣服等等来装饰着自己，让自己变得更加成熟，让自己能够战胜内心中的黑暗和恐惧。 看到电影里的让人更加痛心疾首的不是女孩子们的遭遇，而是男人的懦弱，自私自利，有各种形态的人利用女性，殴打女性。无可厚非，虽然现在各种强调男女平等，总是有各种调查显示好像女性地位还要高些，但是现实中，女性在当今社会上地位还是很不平等。就拿经常被提起的，离婚的女性，其实 承受了很大的社会压力，就像小文妈的样子，同样不被社会所接纳，像是融合了所有离婚女人的不美好。因为社会上的一部分人，甚至说是那种传统思想吧，总是把一个女人和她的身体联系在一起，理解成，一个女人的价值就是她的身体。 真的很可笑了，现在越来越发掘是男性的问题了，女人不应该承受这些，老一辈的三从四德，至今可能还在影响着我们这一辈的人。当然社会总是光明的，律师，让她们看到了希望，最终逃过一劫的刘会长受到了法律的制裁。提升女性的权力和安全，在整个社会中接受，理性对待她们。我想，这起码也是社会文明的一大进步。 “现在大家特别喜欢把脏和女孩子放在一起说，但这是为什么？在我眼里没有女孩是脏的。” 最后，穿着白裙子的小米，骑着电动车，未来将是一个美好的故事。 虽然世俗的偏见却让她们举步维艰，可是那又如何，快乐最重要，活出你们的态度。 美好的事情，需要所有的人努力才能改变。这部电影将会是个开始，因为它发出的声音，重新激发了人们的认知。]]></content>
      <categories>
        <category>随随便便</category>
      </categories>
      <tags>
        <tag>电影</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[以后的生活]]></title>
    <url>%2Flater-after.html</url>
    <content type="text"><![CDATA[晚上和室友吃完饭后，大晚上出门散散步，走在平时居住的小区的路上。看着为数不多的居民楼还亮着灯光，左手和右手边的房子样式差异很大，左手边是风格别异的别墅区，门前院子还亮着灯，细眼望去，里面种着各样的植物，有花草，还有蔬菜，有的院子里停着车，和急得慌的狗，想出来咬我，等下辈子吧。 其实，小区寂静的寂寞，只是冬天的夜晚来的太早了，人们都早早的上床睡觉了吧。 想到这里，也许，未来可能在这里住一辈子是什么样子的。我大概也会在这么一个小区里有一间自己的房子，会和一个人相爱，结婚，生活在这里，如果好的话，父母也可以接过来一起住，还可能养一只猫。我会把一切布置成喜欢的样子，摆上喜欢的物品，把房间打扫得干干净净、舒舒服服的。晚饭后，一家人，在小区里散散步，走出小区外，没有灯光的地方，来到漆黑的地方，一起仰望夜空中的繁星和月亮；回到家还能逗弄猫咪；有一天还会有孩子，整天调皮的打滚，一家人很开心幸福的生活在一起，在那座房子里。这样大概就是一辈子。 毕业已经有半年久了，其实自己还是很迷惑，想要什么样的生活，未来将在何处。 安静极了，出了汽车发动机的轰鸣声和狗叫声，已经没有半点声音。上楼，准备洗洗睡吧，突然发现今晚的月光其实很不错的，只是武汉现在晚上的环境不是很好，星星都看不到了，其实今晚的月光很亮的，看了下，今天农历初十，这么长时间，没认真看过天空中的月亮了，突然感觉到风有点暖。 在夜晚的舒适的空气中，心里渐渐平下来，想起来，如果这样度过一生，我会有些后悔的。舒适平淡的一生，一眼就能望穿的一生，还远远不能成为我活下去的理由，我还有很多地方没去过，很多事情没做。 将来肯定在我想做的事情，去想去的地方，不该为了贪图舒适浪费自己的人生。到时，未来终究是什么样子，究竟要做什么，怎么做，能否做成，都还没法预见。但尽力去做了，我就不会后悔。 路漫漫，其修远兮；吾将上下而求索。 抬头再望一望天空中的月亮。可以看到它笑得如此的皎洁。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集成algolia搜索]]></title>
    <url>%2Falgolia.html</url>
    <content type="text"><![CDATA[使用第三方algolia搜索服务Local Search一直都是Loading状态，太影响体验了，只好换个搜索，可以选择algolia和Swiftype，两者都是收费的，但是可以使用免费版本，可能搜索的准确性降低，提交的网页有上限。 下面弄下algolia搜索服务步骤 首先说下我的next主题是5.1.1版本，低于5.1.0不支持。 注册前往algolia官网进行注册，注册一个新账户。 可以使用 GitHub 或者 Google 账户直接登录，注册后的 14 天内拥有所有功能（包括收费类别的）。之后若未续费会自动降级为免费账户，免费账户 总共有 10,000 条记录，每月有 100,000 的可以操作数。注册完成后，创建一个新的 Index，这个 Index，取一个名字， 将在后面使用。 本地安装 Hexo Algolia 扩展在站点根目录执行：1npm install --save hexo-algolia 这个扩展的功能是搜集站点的内容并通过 API 发送给 Algolia。 获取key在 Algolia 服务站点上找到需要使用的一些配置的值，包括 ApplicationID、Search API Key、 Admin API Key。注意，Admin API Key 需要保密保存。 编辑 站点配置文件，新增以下配置： 123456algolia: applicationID: 'applicationID' apiKey: 'apiKey' adminApiKey: 'adminApiKey' indexName: 'indexName' chunkSize: 5000 替换除了 chunkSize 以外的其他字段为在 Algolia 获取到的值。 更新Index在站点根目录下执行 hexo algolia 来更新 Index：1hexo algolia 中间更新Index的时候出现了点小岔子：123$ hexo algoliaERROR [Algolia] Please set an `HEXO_ALGOLIA_INDEXING_KEY` environment variable to enable content indexing.ERROR &gt;&gt; Read https://npmjs.com/hexo-algolia#api-key for more informations. 这个时候不要去百度，直接去它给的网页中，就可以找到解决办法。 A separate API Key must be provided as an environment variable named HEXO_ALGOLIA_INDEXING_KEY. Create it with these limited write access permissions: Add records, Delete records, List indices, Delete index.1export HEXO_ALGOLIA_INDEXING_KEY=… 为了安全，需要将API Key重新设置上面给的那几个权限，并且在本地设置环境变量。 重新更新Index，可以完成。 12345INFO [Algolia] Identified 114 pages and posts to index.INFO [Algolia] Indexing chunk 1 of 3 (50 items each)INFO [Algolia] Indexing chunk 2 of 3 (50 items each)INFO [Algolia] Indexing chunk 3 of 3 (50 items each)INFO [Algolia] Indexing done. 如上面提示，表示成功。已经提交了114篇文章或网页到index了。 集成到主题中更改主题配置文件，找到 Algolia Search 配置部分：123456789# Algolia Searchalgolia_search: enable: false hits: per_page: 10 labels: input_placeholder: Search for Posts hits_empty: "We didn't find any results for the search: $&#123;query&#125;" hits_stats: "$&#123;hits&#125; results found in $&#123;time&#125; ms" 将 enable 改为 true 即可，根据需要你可以调整 labels 中的文本。 重新发布12hexo cleanhexo g -d 查看效果：]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发容器CopyOnWriteArrayList]]></title>
    <url>%2Fjava-copyonwrite.html</url>
    <content type="text"><![CDATA[Copy-On-Write简称COW，是一种用于程序设计中的优化策略。其基本思路是，从一开始大家都在共享同一个内容，当某个人想要修改这个内容的时候，才会真正把内容Copy出去形成一个新的内容然后再改，这是一种延时懒惰策略。从JDK1.5开始Java并发包里提供了两个使用CopyOnWrite机制实现的并发容器,它们是CopyOnWriteArrayList和CopyOnWriteArraySet。CopyOnWrite容器非常有用，可以在非常多的并发场景中使用到。 什么是CopyOnWrite容器CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。 CopyOnWriteArrayList如何做到线程安全的CopyOnWriteArrayList使用了一种叫写时复制的方法，当有新元素添加到CopyOnWriteArrayList时，先从原有的数组中拷贝一份出来，然后在新的数组做写操作，写完之后，再将原来的数组引用指向到新数组。 12345678910111213141516171819public boolean add(E e) &#123; //1、先加锁 final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; //2、拷贝数组 Object[] newElements = Arrays.copyOf(elements, len + 1); //3、将元素加入到新数组中 newElements[len] = e; //4、将array引用指向到新数组 setArray(newElements); return true; &#125; finally &#123; //5、解锁 lock.unlock(); &#125;&#125; 可以看出来CopyOnWriteArrayList的整个add操作都是在锁的保护下进行的。 当有新元素加入的时候，如下图，创建新数组，并往新数组中加入一个新元素,这个时候，array这个引用仍然是指向原数组的。 图片来自水印 当元素在新数组添加成功后，将array这个引用指向新数组。 图片来自水印 读取操作：123public E get(int index) &#123; return get(getArray(), index);&#125; 但是它的读操作并没有同步，因此读取它的数据的时候不一定是最新的数据。 总结 注意内存的消耗，每次进行写入操作的时候，都会复制一个副本，如果这些对象占用的内存比较大，比如说200M左右，那么再写入100M数据进去，内存就会占用300M，那么这个时候很有可能造成频繁的Yong GC和Full GC。针对内存占用问题，可以通过压缩容器中的元素的方法来减少大对象的内存消耗，比如，如果元素全是10进制的数字，可以考虑把它压缩成36进制或64进制。或者不使用CopyOnWrite容器，而使用其他的并发容器，如ConcurrentHashMap。 不能用于实时读的场景，像拷贝数组、新增元素都需要时间，所以调用一个set操作后，读取到数据可能还是旧的,虽然CopyOnWriteArrayList 能做到最终一致性,但是还是没法满足实时性要求； CopyOnWriteArrayList 合适读多写少的场景，不过这类慎用因为谁也没法保证CopyOnWriteArrayList 到底要放置多少数据，万一数据稍微有点多，每次add/set都要重新复制数组，这个代价实在太高昂了。在高性能的互联网应用中，这种操作分分钟引起故障。 设计思想：并发时候，可以开辟新的地址，来解决并发问题。 参考文章： 线程安全的CopyOnWriteArrayList介绍 Java并发编程：并发容器之CopyOnWriteArrayList（转载）]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20171125]]></title>
    <url>%2Ffrightened.html</url>
    <content type="text"><![CDATA[不经意间，人开始善感起来了。 是人活了这么多年，还是这么怂吗？ 不曾想过，每次做事都这么犹豫。 可能就是在这样的面前，才敢放低姿态。 不管什么事情，努力才是对自己的结果。 世界上最好的安慰并不是告诉对方“一切都会好起来的”，而是苦着脸说“哭个屁，你看，我比你还惨”。 嘿，你好吗？我很好。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程中ThreadLocal]]></title>
    <url>%2Fjava-threadlocal.html</url>
    <content type="text"><![CDATA[没写完，头痛，到凌晨了，先占个坑，先睡个觉，明天再补。 ThreadLocal，很多地方叫做线程本地变量，也有些地方叫做线程本地存储。ThreadLocal为变量在每个线程中都创建了一个副本，那么每个线程可以访问自己内部的副本变量。 但是要注意，虽然ThreadLocal能够解决上面说的问题，但是由于在每个线程中都创建了副本，所以要考虑它对资源的消耗，比如内存的占用会比不使用ThreadLocal要大。 实现原理拥有方法下面看下几个怎么设计实现ThreadLocal的方法： get123456789101112131415161718192021/** * Returns the value in the current thread's copy of this * thread-local variable. If the variable has no value for the * current thread, it is first initialized to the value returned * by an invocation of the &#123;@link #initialValue&#125; method. * * @return the current thread's value of this thread-local */ public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125; 获取当前线程； 然后通过getMap 获取Map； 获取到Map的键值对； 传入this 当前ThreadLocal获取当前的键值对； 根据获取到的entry 返回值，为null 的话调用setInitialValue方法；getMap12345678910/** * Get the map associated with a ThreadLocal. Overridden in * InheritableThreadLocal. * * @param t the current thread * @return the map */ ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals; &#125; 返回线程中的threadLocals变量，继续看threadLocals的实现； threadLocals123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ ThreadLocal.ThreadLocalMap threadLocals = null; 它是ThreadLocal中的静态内部类ThreadLocalMap： ThreadLocalMapEntry123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; ThreadLocalMap的Entry继承了WeakReference，并且使用ThreadLocal作为键值。 setInitialValue12345678910111213141516/** * Variant of set() to establish initialValue. Used instead * of set() in case user has overridden the set() method. * * @return the initial value */ private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value; &#125; 如果map不为空，就设置键值对，为空，再创建Map，看一下createMap的实现; createMap12345678910/** * Create the map associated with a ThreadLocal. Overridden in * InheritableThreadLocal. * * @param t the current thread * @param firstValue value for the initial entry of the map */ void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue); &#125; 这样为当前线程创建副本变量就完毕了。 怎么创建副本变量首先，在每个线程Thread内部有一个ThreadLocal.ThreadLocalMap类型的成员变量threadLocals，这个threadLocals就是用来存储实际的变量副本的，键值为当前ThreadLocal变量，value为变量副本（即T类型的变量）。 初始时，在Thread里面，threadLocals为空，当通过ThreadLocal变量调用get()方法或者set()方法，就会对Thread类中的threadLocals进行初始化，并且以当前ThreadLocal变量为键值，以ThreadLocal要保存的副本变量为value，存到threadLocals。 然后在当前线程里面，如果要使用副本变量，就可以通过get方法在threadLocals里面查找。 使用场景 各种连接池获取连接（如，数据库连接，redis连接）； session管理。 学习代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.wuwii.test;import org.junit.Test;/** * @author Zhang Kai * @version 1.0 * @since &lt;pre&gt;2017/11/24 20:32&lt;/pre&gt; */public class TestThreadLocal &#123; /** * 声明一个ThreadLocal变量 */ private ThreadLocal&lt;String&gt; local1 = new ThreadLocal&lt;&gt;(); /** * 为ThreadLocal赋值 */ private void setValue() &#123; local1.set(Thread.currentThread().getName()); &#125; @Test public void test1() &#123; Thread thread1 = new Thread(() -&gt; &#123; /* * 每次调用get方法前，必须要set，不然会抛出NPE */ setValue(); System.out.printf("线程一的localValue为: %s%n", local1.get()); &#125;); new Thread(() -&gt; &#123; //先给线程二的threadLocal赋值，然后运行线程一，最后打印线程二的threadLocal setValue(); try &#123; /* * 在线程二中添加运行线程一，证明了每个线程保存的ThreadLocal的副本变量是不同的 */ thread1.start(); thread1.join(); // 运行完线程一，再输出线程二 System.out.printf("线程二的localValue为: %s%n", local1.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125;&#125; 输出结果：12线程一的localValue为: Thread-0线程二的localValue为: Thread-1 可以看出，线程二并没有被影响。 参考博客：Java并发编程：深入剖析ThreadLocal]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用一生的时光去守护你]]></title>
    <url>%2Fa-living-time.html</url>
    <content type="text"><![CDATA[今天听电台上逛到了这篇文章，首先想到的应该是爸妈那一代人，是我们比较熟悉的，那缝纫机，我家里现在还能用了；我小时候学习骑车的时候，用的就是当初爸妈结婚的时候自行车；还有当时的小彩电，被我拿来打游戏机了……现在想起来，惭愧的很，没能好好珍惜，那是属于父母的美好记忆的一部分。当然都过去好久了，我的记忆力还是不错的，虽然大多数东西已经不存在了，但是能一直存在我的记忆里，我想爸妈也是一直记得的，而且现在家庭幸福，就足够了。 文章来自网上，百度标题就有，读起来可以细细品尝，喝杯水，别是一番风味。 记录到博客（图片都是偷的…… 五六十年代的爱情，没有绚烂的色彩，却有着耐人寻味的真情。 那个时候，总有做不完的农活，苦中作乐就是甜蜜的爱情。 在当时，为心爱的女人戴上一朵红花，是爱情的见证，更是一种矢志不渝的承诺。 结婚前不需贵重的礼品，一支钢笔就是一个深刻的纪念。 那时候结婚，还需要组织上开个介绍信。接过结婚证书的时候，开心到说不出话来。 那时候的爱情，总是有众人的见证。 到了七十年代，爱情故事也随着时代而发生改变。 在那个特殊的年代，爱情是被禁止的羞涩。 “恋爱”“结婚”，是资产阶级思想的自由化产物，“男女关系”是绝对要划清界限的个人守则。 那个时代的人们单纯，生怕别人误会自己有不正当男女关系，生怕别人误会老家来的表哥是自己的汉子。 那时候，连牵个小手都得偷偷摸摸的，一根小小的竹竿连接着他们青涩的爱情。 那时候的爱情，也是政治。身穿军装、手捧毛主席语录照相，是那个年代最独特的记忆。 80年代，有了一种独特的恋爱方式，叫做联谊。说说笑笑，感情自然而然地发生。 在没有电话、电脑的年代，写信寄照片是唯一联系情感的方式。 那时候的约会很简单，坐趟公交车到郊外走走，到湖边划划小船。 只要两个人在一起，在公园的长椅上坐上一个下午也不会觉得无聊。 骑着自行车，载着心爱的那个她，真希望时光就停留在这一刻。 带上礼物，和心爱的人穿戴整齐，一起回家里看看爸妈。 一台缝纫机，一辆自行车，一台收音机，加上母亲准备的花棉被，就是全部的嫁妆。 那个年代，爱情有着纯粹的颜色，神圣不容亵渎。 那个年代，车马很慢，书信很远，一生只够爱一人。 30年前的我爱你，不是嘴上说说， 而是用一生的时光去守护你！ “两姓联姻，一堂缔约，良缘永结，匹配同称。看此日桃花灼灼，宜室宜家，卜他年瓜瓞绵绵，尔昌尔炽。谨以白头之约，书向鸿笺，好将红叶之盟，载明鸳谱。此证。” 张爱玲说过：“于千万人之中遇见你所要遇见的人,于千万年之中,时间的无涯的荒野里,没有早一步,也没有晚一步,刚巧赶上了,没有别的话可说,唯有轻轻地问一声:“原来你也在这里 ”]]></content>
      <categories>
        <category>分享</category>
      </categories>
      <tags>
        <tag>故事</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Easyui异步ComboTree加载到指定子节点展开]]></title>
    <url>%2Feasyui-combotree.html</url>
    <content type="text"><![CDATA[Easyui异步ComboTree加载到指定子节点展开，其实以为这个功能会很简单，做起来出了一些问题，现在做完了，也还是存在一些隐患，记录，等找到最好的解决办法： 前端代码业务其实是一个很普通的省市县的级联查询，但是，我们不是那个一级一级的方式选择的，是直接加载一棵树，在到树下一级一级的选到想要的位置。 主要就是加载异步树，还有就是去加载到当前指定的子节点上，并且打开每一级的父节点：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;测试玩&lt;/title&gt; &lt;link rel="stylesheet" href="../../theme/default/easyui.css"/&gt; &lt;link rel="stylesheet" type="text/css" href="../../theme/icon.css"/&gt; &lt;link rel="stylesheet" type="text/css" href="../../css/app.css"/&gt; &lt;link rel="stylesheet" type="text/css" href="../../css/main.css"/&gt; &lt;link rel="stylesheet" type="text/css" href="../../css/icon.css"/&gt; &lt;script type="text/javascript" src="../../js/jquery.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="../../js/jquery.easyui.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="../../js/easyui-lang-zh_CN.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;input id="tree"/&gt;&lt;!--测试使用打开到指定的子节点--&gt;&lt;a id="expand"&gt;指定打开&lt;/a&gt;&lt;script type="text/javascript"&gt; /** * 后台服务url自己修改成配置文件的 */ var baseUrl = "http://192.168.19.207:8081/devframe-server/"; /** * 记录级联信息 */ var selectNode = &#123; province: null, city: null, county: null, town: null &#125; /** * 根据type判断级联 */ var nodeType = &#123; province: 'province', city: 'city', county: 'county', town: 'town' &#125; $(document).ready(function () &#123; initComboTree(); &#125;) /** * 初始化ComboTree */ function initComboTree() &#123; //第一次加载成功需要选中高亮第一个节点 var isHighlight = true; $("#tree").combotree(&#123; method: "post", url: baseUrl + 'dictionary/asyncdata/canton', panelWidth: '170', onClick: function (node) &#123; getNodeMessage(node); &#125;, onBeforeExpand: function (node, param) &#123; $(this).tree('options').url = baseUrl + 'dictionary/asyncdata/canton?id=' + node.id; &#125;, onLoadSuccess: function () &#123; if (!isHighlight) return; $("#tree li:eq(0)").find("div").addClass("tree-node-selected"); var n = $(this).tree("getSelected"); if (n != null) $(this).tree("select", n.target); isHighlight = false; &#125;, loadFilter: function (data) &#123; data = data.data; //不要问为什么有这么一步，因为懒，不想改服务 for (var i = 0; i &lt; data.length; i++) &#123; if ('data' in data[i]) &#123; data[i].text = data[i].data; &#125; &#125; return data; &#125;, formatter: function (node) &#123; if (!node.children || node.children.length == 0) return node.text; return node.text + '&lt;span style="color:blue"&gt;(' + node.children.length + ')&lt;/span&gt;'; &#125;, //屏蔽浏览器默认的右键事件，改为和左键点击事件一样的了 onContextMenu: function (e, node) &#123; e.preventDefault(); $(this).tree('select', node.target); &#125; &#125;); &#125; /** * 编辑状态中的树，需要展开到指定节点 * @param id 需要展开的Id */ function editComboTree(id) &#123; $.ajax(&#123; type: 'post', url: baseUrl + 'dictionary/expandto/' + id, success: function (response) &#123; if (response == null || response.statusCode == 400) &#123; return; &#125; $("#tree").combotree('loadData', response); $("#tree").combotree('setValue', id); &#125;, error: function (e) &#123; //TODO error &#125; &#125;) &#125; /** * 点击树，获取级联的信息 * @param node 节点 */ function getNodeMessage(node) &#123; var remark = node.type; if (remark == null || remark == "") &#123; return; &#125; else if (remark == nodeType.province) &#123; selectNode.province = node.text; &#125; else if (remark == nodeType.city) &#123; selectNode.city = node.text; &#125; else if (remark == nodeType.county) &#123; selectNode.county = node.text; &#125; else if (remark == nodeType.town) &#123; selectNode.town = node.text; &#125; //查找父级节点，没有则退出 var parent = getParentNode(node); if (parent != null) &#123; getNodeMessage(parent) &#125; &#125; /** * 根据节点获取父节点 * @param node 节点 * @returns &#123;*&#125; 父节点 */ function getParentNode(node) &#123; var tree = $('#tree').combotree('tree'); return tree.tree('getParent', node.target); &#125; //测试的，打开到指定的子节点，点击事件 $("#expand").on('click', function (e) &#123; editComboTree('431000000000'); &#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 服务端代码服务端有点差，就不贴代码了，说下解决思路。 持久层框架：JPA 数据库：PostgreSQL加载异步树的服务主要是利用了SQL，对，使用原生SQL查的。这里还有一个问题，就是easyui的ComboTree加载异步树的时候，需要判断当前查询出来的节点下面还有没有子节点，就是我们平常看到树的前面有一个尖三角符号，用来表示是否能展开。ComboTree同时继承了Combo和Tree两个的特点，其实，就是把数据绑定到tree上，tree的节点（node）有一个属性是state，用来控制树的该节点的展开与否，它有两个值：open和closed，所以查询的时候干脆就直接的查出了这个属性，SQL有些特别： condition参数是接到WHERE后面的查询条件。123456AtomicReference&lt;String&gt; sql = new AtomicReference&lt;&gt;(&quot;SELECT T.*,CASE WHEN T1.\&quot;COUNT\&quot;=0 OR &quot; + &quot;T1.\&quot;COUNT\&quot; IS NULL THEN &apos;open&apos; WHEN T1.\&quot;COUNT\&quot;&gt;0 THEN &apos;closed&apos; END AS \&quot;STATE\&quot; &quot; + &quot;FROM(SELECT * FROM \&quot;DEV_DICTIONARY\&quot; WHERE &quot; + condition.get() + &quot; ORDER BY \&quot;PARENTID\&quot;) T LEFT JOIN (SELECT \&quot;PARENTID\&quot;, COUNT(\&quot;PARENTID\&quot;) \&quot;COUNT\&quot; FROM \&quot;DEV_DICTIONARY\&quot; &quot; + &quot;WHERE \&quot;PARENTID\&quot; IN (SELECT \&quot;ID\&quot; FROM \&quot;DEV_DICTIONARY\&quot; WHERE &quot; + condition.get() + &quot;) &quot; + &quot;GROUP BY \&quot;PARENTID\&quot;) T1 ON T.\&quot;ID\&quot; = T1.\&quot;PARENTID\&quot;&quot;); 这样太难看了，最后娶一个实例：123456789101112131415161718192021222324252627282930313233343536373839SELECT T.*, CASE WHEN T1."COUNT"=0 OR T1."COUNT" IS NULL THEN 'open' WHEN T1."COUNT"&gt;0 THEN 'closed' END AS "STATE" FROM (SELECT * FROM "DEV_DICTIONARY" WHERE "TYPE"='canton' AND "PARENTID" is null ORDER BY "PARENTID" ) T LEFT JOIN ( SELECT "PARENTID", COUNT("PARENTID") "COUNT" FROM "DEV_DICTIONARY" WHERE "PARENTID" IN ( SELECT "ID" FROM "DEV_DICTIONARY" WHERE "TYPE"='canton' AND "PARENTID" is null ) GROUP BY "PARENTID" ) T1 ON T."ID" = T1."PARENTID" 这样查询出来的就多了一列state，按照是否有子集，设置它是closed 还是open。 当然还需要到实体类上去映射好这个属性字段。12@Column(name = &quot;\&quot;STATE\&quot;&quot;)private String state; 加载到指定节点加载到指定节点，并展开到该节点。这个就用脑图说下思路吧。暂时我感觉我的做法不是很好，我看能不能减少复杂度，期待以后能解决，看到的朋友如果有好的解决办法，请与我联系，万分感谢。 其实我们需要找到的数据就是这样的一组数据：首先找到同级的，再去找父的，父的又去找自己的同级，再去找自己的上一级。。。直到找到root节点，完毕。 我是分步做的，应该有更少步骤或者一条SQL完成的，下去研究，估计有点难。 展示下结果吧异步树： 展示到指定节点效果: 还要注意一点，就是请求服务使用get会好些，get比post快，但是要加上时间戳，避免去读取浏览器缓存数据。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Web前端</tag>
        <tag>easyui</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《小王子》读后感]]></title>
    <url>%2Fprincekin.html</url>
    <content type="text"><![CDATA[从前呀，有一位小王子，他住在同自己差不多大的星球上，他想要一位朋友。 平时比较忙，如果说读小说的话时间太长了，还有很多专业的书没看，弄得半年都过去了《飘》都没看完，说句老实话，我是个不喜欢读书的人/。。 然而他却放佛面对意见很严肃的事情，第二次从容迫不及待的对我说：“请为了画只羊。” 这句话应该很经典，这也是故事中羊的由来，故事中的我从未划过羊，内心其实是很害怕的，其实看得多才知道，为什么会有羊这个片段，说到底就是年少的单纯吧，让羊去啃那个面包树；但是也有可能是追求善良吧，个人理解。 忘记一位朋友，这真使人悲哀。并非每个人都有过一位朋友。 这段话真是揪心啊，与朋友一起是一个很快乐的事情，但是想忘记一个人真的很痛苦吧，也许有一天，会慢慢淡忘一个人。但是在当前岁月下，好好珍惜身边的每一个爱你和你爱的人。现在，买得起充电五分钟的手机，但是通话两小时的人可不好找。 猴面包树在长大以前也是很小的。 小王子在知道羊吃小灌木的时候，他很开心，它们可以吃猴面包树了，但是猴面包树已经长得很大，羊可吃不了，只有在它小的时候，才能警惕它。孩子们，要当心那些猴面包树呀！猴面包树是人们都不想要的东西，想放弃的东西，但是，人们是自私的，想放下，却不想放下，但是自己又不甘放下那段执念，明知结果不好，确实还是贪婪的霸占着这一片不属于你的土地，最好确是还是一步一步越陷越深。所以要在开始有这种心理的时候就要把它铲除掉，找到自己的玫瑰，将它种下，在心中发芽，这样心中才能充满美好。 你知道，当感到十分愁闷的时候，人们都会想看太阳落山。 小王子一天能看四十三次日出，那是多么忧郁的生活啊，也许唯一的快乐就是看日落，人总是在不知不觉中，感到愁闷，而且是非常糟糕的那种，人为什么会那么难过了。可能是有一种人，就像我吧，总是喜欢把悲伤隐藏的深一点，再深一点，习惯性了都，当然各种事情都有暴露的，比如说，悲伤的时候想看日落，哈哈。说不定高兴的时候就想看日出了。 对别人提出的要求必须是他们能够办到的。权力首先应当以理性为基础。 小王子来到一个星球上，住的只有一个国王，他统治着一切，但是他并没有拥有一切，。虽然他拥有着至高无上的权力，但是天真地想让自己统治一切，发出不合理的命令来强人所难。所以在现实社会中，首先要求别人做事的时候，一定要考虑到他人感受为前提，虽然你可能是BOSS，但是优秀员工都有随时踢开SB 老板的权力。扯远了，永远不要忘了，不能提出不合理的要求。 虚荣心极强的人眼中，所有的人都是他们的崇拜者。 这个怎么说了，虚荣，当今社会，每个人都可能会犯的毛病了，可能不经意间，就出现了，只不过没发现，觉得理所当然，当然只是自己觉得，哈哈。我说我长得好帅，万人迷，当然这个不是虚荣，只是小小的吹牛皮。很无聊的，不说了。 “你为什么要喝酒？”“为了忘记。”“忘记什么？”“忘记我的惭愧。”“你惭愧什么？”“我惭愧我喝酒”…… 有时候，就是陷入自己设下的思维怪圈中，怎么才能跳出来？亲爱的，面对现实的一切，不要自我麻痹。 对我而言，假如我有一条围巾，我会用它围我的脖子，而且我可以带走它。我有一朵花，我就会摘下我的花朵，而且我可以将它带走。但你却无法摘下满天的星星啊。 每次看到这段话的时候我都很触动。商人很富有，霸占了所有的星星，拥有一切，但是他却并没有获得他们。星星是多么的耀眼，那么的迷人，但我宁愿有一条可以围在脖子上的围巾，还有一个带走的花。 规定倒的地方没改变，这就是倒霉的地方！这颗星球一年比一年转得快，当规定却没改。 哎，初看点灯人，觉得是个很可爱得人儿，他做着自己口中所说的讨厌的工作，却忠于职守，而且，是那种一成不变的，星球越转越快，但却口令没变，导致每一分钟都要点灯，灭灯，小王子让他改下，他却喜欢一劳永逸。看到这里不又想到现实生活中，可以说一部分人的代表吧，这里说明下，我没有黑的意思，做的同一份工作很多年，但却没有一点上升的意思，但是他们真的很刻苦用心。这个大概就是忠于职守和用心不是同一个概念了，世界上没有绝对的事情，但是有肯定的事情，随着时代进步，一定能占尽先机的。 星星发亮是为了让每一个人有一天都能找到属于自己的星星。 如果你爱上了某个星球的一朵花。那么，只要在夜晚仰望星空，就会觉得漫天的繁星就像一朵朵盛开的花。 当在一个地方存在某种特殊意义的时候，不管是什么它将都是独一无二的美丽，即便漫长黑夜里，也可以通过光亮寻找到它的位置。玫瑰是简单而且性格敏感的代表，看到它的故事片段，人心都觉得好暖。玫瑰消失后，这段话很感动，也许就是“心中有了想念的人，你便不觉得孤独”的含义，无牵无挂心中空空如也才最是寂寞。对于狐狸来说，也是不会寂寞的。当然也是遗憾的。你要走便走，不要回头，我不会留。 狐狸说：“对我来说，你只是一个小男孩，就像其他成千上万个小男孩一样没有什么两样。我不需要你。你也不需要我。对你来说，我也只是一只狐狸，和其他成千上万的狐狸没有什么不同。但是，如果你驯养了我，我们就会彼此需要。对我来说，你就是我的世界里独一无二的了；我对你来说，也是你的世界里的唯一了。”一旦你驯服了什么，就要对她负责，永远的负责。 狐狸告诉了让小王子懂得了生活的本质和爱情的真谛。“一个人被驯服,是冒着流泪的危险的”，“只有用心才能看得清。实质性的东西，用眼睛是看不见的。”用心去看才看得清楚，小王子知道需要珍惜他的玫瑰；爱就是责任。 总之故事的结尾是伤心的。从头到尾是一个以爱情的伤痛为背景的线索，以一份纯真的爱情，爱得真切，深入骨髓得疼痛结束。 爱是一种责任，爱也是一种短暂易逝的美好。用心去爱你身边的每一个人，爱可以是亲情、友情……别整天就知道爱情才是爱，每一个真切对你好的人，不要让他们攒满失望离开，毕竟一生中遇到这么可爱的人真的不多，走一个少一个。 Growing up is not the problem.Forgetting is. 一切仅代表个人观点哈，勿喷]]></content>
      <categories>
        <category>随随便便</category>
      </categories>
      <tags>
        <tag>小王子</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的蛋碎了一个]]></title>
    <url>%2F20171120.html</url>
    <content type="text"><![CDATA[真的。。 看到这个蛋，随口喊出那句话，被自己蠢哭了。 支付宝刮了一张卡，感觉到马云爸爸深深的恶意。 用穷逼会员咋的，]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Redis完成分布式锁]]></title>
    <url>%2Fredis-lock.html</url>
    <content type="text"><![CDATA[实现原理 分布式的CAP理论告诉我们“任何一个分布式系统都无法同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance），最多只能同时满足两项。”所以，很多系统在设计之初就要对这三者做出取舍。在互联网领域的绝大多数的场景中，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证“最终一致性”，只要这个最终时间是在用户可以接受的范围内即可。 为了保证数据的最终一致性，需要很多的技术方案来支持，比如分布式事务、分布式锁等。 使用Redis实现锁的原因 Redis有很高的性能； Redis命令对此支持较好，实现起来比较方便。 主要利用到的命令SETNX SETNX key val当且仅当key不存在时，set一个key为val的字符串，返回1；若key存在，则什么都不做，返回0。 expireexpire key timeout为key设置一个超时时间，单位为second，超过这个时间锁会自动释放，避免死锁。 deletedelete key删除key 实现思想 获取锁的时候，使用setnx加锁，并使用expire命令为锁添加一个超时时间，超过该时间则自动释放锁，保证key一致，通过此在释放锁的时候进行判断。 获取锁的时候还设置一个获取的超时时间，若超过这个时间则放弃获取锁。 释放锁的时候，当前时间小于超时时间，则执行delete进行锁释放。 代码结构123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224package com.devframe.util;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import redis.clients.jedis.Jedis;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;/** * &lt;b&gt;redis分布式锁的实现&lt;/b&gt;&lt;/br&gt; * 还有一些失败机制没处理，以后在使用测试阶段，完善。 * * @author Zhang Kai * @version 1.0 * @since &lt;pre&gt;2017/11/20 9:22&lt;/pre&gt; */public class RedisLock implements Lock &#123; private final static Logger logger = LoggerFactory.getLogger(RedisLock.class); /** * redis连接 */ private final Jedis jedis; /** * 锁定资源名，锁key，保证唯一。 */ private final String lockName; /** * 资源上锁的最长时间，超时自动解锁单位秒，&lt;/br&gt; * 建议设置成死的，如果设置不当容易影响效率，严重造成死锁。 */ private final int expireTime = Integer.valueOf(PropertyUtil.get("redisLock.expireTime")); /** * 线程获取不到锁，休眠的时间，单位ms * 避免系统资源浪费 */ private final long sleepTime = Long.valueOf(PropertyUtil.get("redisLock.sleepTime")); /** * 当前锁超时的时间戳，单位毫秒 */ private long expireTimeOut = 0; /** * 获取锁状态，锁中断状态&lt;/br&gt; * 值为false的时候中断获取锁&lt;/br&gt; */ private boolean interrupted = true; /** * 构造方法 * * @param jedis redis连接 * @param lockName 上锁key，唯一标识 */ public RedisLock(Jedis jedis, String lockName) &#123; if (lockName == null) &#123; throw new NullPointerException("lockName is required"); &#125; this.jedis = jedis; // 重命名的前缀，可以不加，也可以自定义，保证唯一即可。 this.lockName = "lock" + lockName; &#125; /** * 获取锁。如果锁已被其他线程获取，则进行等待，直到拿到锁为止。 */ @Override public void lock() &#123; while (true) &#123; this.lockCheck(); long id = jedis.setnx(lockName, lockName); if (id == 0L) &#123; try &#123; /** * 没有获取到锁则进行等待睡眠时间，再去重新获取锁&lt;/br&gt; * 这里使用随机时间可能会好一点,可以防止饥饿进程的出现,即,当同时到达多个进程, * 只会有一个进程获得锁,其他的都用同样的频率进行尝试,后面有来了一些进行, * 也以同样的频率申请锁,这将可能导致前面来的锁得不到满足. * 使用随机的等待时间可以一定程度上保证公平性 */ Thread.sleep(this.sleepTime); &#125; catch (InterruptedException e) &#123; logger.error("Thread is interrupted", e); &#125; &#125; else &#123; expireTimeOut = System.currentTimeMillis() + expireTimeOut * 1000 + 1; //设置redis中key的过期时间 jedis.expire(this.lockName, expireTime); break; &#125; &#125; &#125; /** * 中断锁获取 * * @throws InterruptedException 中断异常 */ @Override public void lockInterruptibly() throws InterruptedException &#123; this.interrupted = false; &#125; /** * 它表示用来尝试获取锁，会立即返回，如果获取成功，则返回true，如果获取失败（即锁已被其他线程获取），则返回false，&lt;/br&gt; * 也就说这个方法无论如何都会立即返回。在拿不到锁时不会一直在那等待。 * * @return boolean */ @Override public boolean tryLock() &#123; this.lockCheck(); //尝试获取锁 long id = jedis.setnx(lockName, lockName); //返回结果为0 则已经存在key，已经存在锁。 if (id == 0L) &#123; return false; &#125; else &#123; expireTimeOut = System.currentTimeMillis() + expireTimeOut * 1000 + 1; //设置redis中key的过期时间 jedis.expire(this.lockName, expireTime); return true; &#125; &#125; /** * 它表示用来尝试获取锁，如果获取成功，则返回true，如果获取失败（即锁已被其他线程获取），则返回false，&lt;/br&gt; * 这个方法在拿不到锁时会等待一定的时间，在时间期限之内如果还拿不到锁，就返回false。&lt;/br&gt; * 如果如果一开始拿到锁或者在等待期间内拿到了锁，则返回true。&lt;/br&gt; * * @param time 等待时间 * @param unit 时间单位 * @return boolean * @throws InterruptedException 中断异常 */ @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; if (time == 0) &#123; return false; &#125; if (unit == null) &#123; throw new NullPointerException("TimeUnit is required."); &#125; long now = System.currentTimeMillis(); long timeOutAt = now + calcSeconds(time, unit); while (true) &#123; this.lockCheck(); long id = jedis.setnx(this.lockName, this.lockName); // id = 0 表示加锁失败 if (id == 0) &#123; // 获取锁超时 if (System.currentTimeMillis() &gt; timeOutAt) &#123; return false; &#125; // 休眠一段时间，线程再继续获取锁。 Thread.sleep(this.sleepTime); &#125; else &#123; //获取锁成功，设置锁过期时间戳 expireTimeOut = System.currentTimeMillis() + expireTimeOut * 1000 + 1; jedis.expireAt(this.lockName, expireTimeOut); return true; &#125; &#125; &#125; /** * &lt;b&gt;释放锁&lt;b/&gt; * 当前时间小于过期时间，则锁未超时，删除锁，&lt;/br&gt; * 过了超时时间，redis已经删除了该key。 */ @Override public void unlock() &#123; if (System.currentTimeMillis() &lt; expireTimeOut) &#123; jedis.del(lockName); &#125; &#125; @Override public Condition newCondition() &#123; //TODO 涉及到 Condition 例外一个重要内容，以后再实现这个方法 throw new UnsupportedOperationException("did not supported."); &#125; /** * 检查当前线程资源redis连接和锁的状态 */ private void lockCheck() &#123; if (jedis == null) &#123; throw new NullPointerException("Jedis is required."); &#125; if (!interrupted) &#123; throw new RuntimeException("Thread is interrupted."); &#125; &#125; /** * TimeUnit单位时间转换成毫秒 * * @param time 时间 * @param unit 时间单位 * @return long */ private long calcSeconds(long time, TimeUnit unit) &#123; if (unit == TimeUnit.DAYS) &#123; return time * 24 * 60 * 60 * 1000; &#125; if (unit == TimeUnit.HOURS) &#123; return time * 60 * 60 * 1000; &#125; if (unit == TimeUnit.MINUTES) &#123; return time * 60 * 1000; &#125; if (unit == TimeUnit.SECONDS) &#123; return time * 1000; &#125; if (unit == TimeUnit.MILLISECONDS) &#123; return time; &#125; else &#123; //后面的不实现了，基本上用不到。 throw new UnsupportedOperationException("cannot be resolved."); &#125; &#125;&#125; 配置12345# redis lock# sredisLock.expireTime=1# msredisLock.sleepTime=100 测试测试就选用最经典的秒杀系统吧，使用分布式锁可以控制资源。 下面模拟500人秒杀100件商品。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package com.devframe.util;import org.junit.Test;import redis.clients.jedis.Jedis;/** * @author Zhang Kai * @version 1.0 * @since &lt;pre&gt;2017/11/20 14:12&lt;/pre&gt; */public class RedisLockTest &#123; /** * 100件物品 */ public static int goodsNum = 100; /** * 500人 */ private static int personNum = 500; /** * 不加锁的情况 */ @Test public void test() &#123; for (int i = 0; i &lt; personNum; i++) &#123; new Thread(() -&gt; &#123; if (goodsNum &gt; 0) &#123; System.out.println(Thread.currentThread().getName() + "获取了锁"); System.out.println("商品剩余：" + --goodsNum); &#125; &#125;).start(); &#125; &#125; /** * 加上分布锁 * @param args */ public static void main(String[] args) &#123; for (int i = 0; i &lt; personNum; i++) &#123; new Thread(() -&gt; &#123; Jedis jedis = RedisUtil.getJedis(); //初始化锁，key保持一致 Lock lock = new RedisLock(jedis, "aa"); try &#123; lock.lock(); if (goodsNum &gt; 0) &#123; System.out.println(Thread.currentThread().getName() + "获取了锁"); System.out.println("商品剩余：" + --goodsNum); &#125; &#125; finally &#123; //释放锁，并且释放redis连接 lock.unlock(); RedisUtil.returnResource(jedis); &#125; &#125;).start(); &#125; &#125;&#125; 不加锁的部分结果：12345678910111213Thread-100获取了锁商品剩余：-3Thread-99获取了锁商品剩余：5商品剩余：6Thread-98获取了锁商品剩余：-5商品剩余：7商品剩余：-4商品剩余：0商品剩余：1Thread-105获取了锁商品剩余：-6 上锁的结果：123456789101112Thread-8获取了锁商品剩余：5Thread-238获取了锁商品剩余：4Thread-72获取了锁商品剩余：3Thread-137获取了锁商品剩余：2Thread-402获取了锁商品剩余：1Thread-337获取了锁商品剩余：0 总结 并发量大的时候，需要考虑锁时间； 考虑失败情况，上锁了，但是设置超时时间失败（redis崩溃等各种情况），锁一致都没有释放，导致死锁的情况发生，现在需要做的是，把key的value设置成超时的时间，每次上锁失败都去检查一次，超时的就覆盖，可以避免死锁。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[volatile关键字解析]]></title>
    <url>%2Fjava-volatile.html</url>
    <content type="text"><![CDATA[内存模型的相关概念大家都知道，计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。 也就是，当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。举个简单的例子，比如下面的这段代码：1i = i + 1; 当线程执行这个语句时，会先从主存当中读取i的值，然后复制一份到高速缓存当中，然后CPU执行指令对i进行加1操作，然后将数据写入高速缓存，最后将高速缓存中i最新的值刷新到主存当中。 这个代码在单线程中运行是没有任何问题的，但是在多线程中运行就会有问题了。在多核CPU中，每条线程可能运行于不同的CPU中，因此每个线程运行时有自己的高速缓存（对单核CPU来说，其实也会出现这种问题，只不过是以线程调度的形式来分别执行的）。本文我们以多核CPU为例。 比如同时有2个线程执行这段代码，假如初始时i的值为0，那么我们希望两个线程执行完之后i的值变为2。但是事实会是这样吗？ 可能存在下面一种情况：初始时，两个线程分别读取i的值存入各自所在的CPU的高速缓存当中，然后线程1进行加1操作，然后把i的最新值1写入到内存。此时线程2的高速缓存当中i的值还是0，进行加1操作之后，i的值为1，然后线程2把i的值写入内存。 最终结果i的值是1，而不是2。这就是著名的缓存一致性问题。通常称这种被多个线程访问的变量为共享变量。 也就是说，如果一个变量在多个CPU中都存在缓存（一般在多线程编程时才会出现），那么就可能存在缓存不一致的问题。 为了解决缓存不一致性问题，通常来说有以下2种解决方法： 通过在总线加LOCK#锁的方式； 通过缓存一致性协议。 这2种方式都是硬件层面上提供的方式。 在早期的CPU当中，是通过在总线上加LOCK#锁的形式来解决缓存不一致的问题。因为CPU和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他CPU对其他部件访问（如内存），从而使得只能有一个CPU能使用这个变量的内存。比如上面例子中 如果一个线程在执行 i = i +1，如果在执行这段代码的过程中，在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。 但是上面的方式会有一个问题，由于在锁住总线期间，其他CPU无法访问内存，导致效率低下。 所以就出现了缓存一致性协议。最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。 并发编程中的三个概念在并发编程中，我们通常会遇到以下三个问题：原子性问题，可见性问题，有序性问题。我们先看具体看一下这三个概念： 原子性原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 一个很经典的例子就是银行账户转账问题： 比如从账户A向账户B转1000元，那么必然包括2个操作：从账户A减去1000元，往账户B加上1000元。 试想一下，如果这2个操作不具备原子性，会造成什么样的后果。假如从账户A减去1000元之后，操作突然中止。然后又从B取出了500元，取出500元之后，再执行 往账户B加上1000元 的操作。这样就会导致账户A虽然减去了1000元，但是账户B没有收到这个转过来的1000元。 所以这2个操作必须要具备原子性才能保证不出现一些意外的问题。 同样地反映到并发编程中会出现什么结果呢？举个最简单的例子，大家想一下假如为一个32位的变量赋值过程不具备原子性的话，会发生什么后果？1i = 9; 假若一个线程执行到这个语句时，我暂且假设为一个32位的变量赋值包括两个过程：为低16位赋值，为高16位赋值。那么就可能发生一种情况：当将低16位数值写入之后，突然被中断，而此时又有一个线程去读取i的值，那么读取到的就是错误的数据。 可见性可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 举个简单的例子，看下面这段代码：123456//线程1执行的代码int i = 0;i = 10; //线程2执行的代码j = i; 假若执行线程1的是CPU1，执行线程2的是CPU2。由上面的分析可知，当线程1执行 i =10这句时，会先把i的初始值加载到CPU1的高速缓存中，然后赋值为10，那么在CPU1的高速缓存当中i的值变为10了，却没有立即写入到主存当中。 此时线程2执行 j = i，它会先去主存读取i的值并加载到CPU2的缓存当中，注意此时内存当中i的值还是0，那么就会使得j的值为0，而不是10. 这就是可见性问题，线程1对变量i修改了之后，线程2没有立即看到线程1修改的值。 有序性有序性：即程序执行的顺序按照代码的先后顺序执行。举个简单的例子，看下面这段代码：1234int i = 0; boolean flag = false;i = 1; //语句1 flag = true; //语句2 上面代码定义了一个int型变量，定义了一个boolean类型变量，然后分别对两个变量进行赋值操作。从代码顺序上看，语句1是在语句2前面的，那么JVM在真正执行这段代码的时候会保证语句1一定会在语句2前面执行吗？不一定，为什么呢？这里可能会发生指令重排序（Instruction Reorder）。 下面解释一下什么是指令重排序，一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。 比如上面的代码中，语句1和语句2谁先执行对最终的程序结果并没有影响，那么就有可能在执行过程中，语句2先执行而语句1后执行。 但是要注意，虽然处理器会对指令进行重排序，但是它会保证程序最终结果会和代码顺序执行结果相同，那么它靠什么保证的呢？再看下面一个例子：1234int a = 10; //语句1int r = 2; //语句2a = a + 3; //语句3r = a*a; //语句4 这段代码有4个语句，那么可能的一个执行顺序是： 那么可不可能是这个执行顺序呢： 语句2 语句1 语句4 语句3 不可能，因为处理器在进行重排序时是会考虑指令之间的数据依赖性，如果一个指令Instruction 2必须用到Instruction 1的结果，那么处理器会保证Instruction 1会在Instruction 2之前执行。 虽然重排序不会影响单个线程内程序执行的结果，但是多线程呢？下面看一个例子：123456789//线程1:context = loadContext(); //语句1inited = true; //语句2 //线程2:while(!inited )&#123; sleep()&#125;doSomethingwithconfig(context); 上面代码中，由于语句1和语句2没有数据依赖性，因此可能会被重排序。假如发生了重排序，在线程1执行过程中先执行语句2，而此是线程2会以为初始化工作已经完成，那么就会跳出while循环，去执行doSomethingwithconfig(context)方法，而此时context并没有被初始化，就会导致程序出错。 从上面可以看出，指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。 也就是说，要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确。 Java内存模型在前面谈到了一些关于内存模型以及并发编程中可能会出现的一些问题。下面我们来看一下Java内存模型，研究一下Java内存模型为我们提供了哪些保证以及在java中提供了哪些方法和机制来让我们在进行多线程编程时能够保证程序执行的正确性。 在Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model，JMM）来屏蔽各个硬件平台和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。那么Java内存模型规定了哪些东西呢，它定义了程序中变量的访问规则，往大一点说是定义了程序执行的次序。注意，为了获得较好的执行性能，Java内存模型并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序。也就是说，在java内存模型中，也会存在缓存一致性问题和指令重排序的问题。 Java内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。 举个简单的例子：在java中，执行下面这个语句： 1i = 10; 执行线程必须先在自己的工作线程中对变量i所在的缓存行进行赋值操作，然后再写入主存当中。而不是直接将数值10写入主存当中。 那么Java语言 本身对 原子性、可见性以及有序性提供了哪些保证呢？ 原子性在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。 上面一句话虽然看起来简单，但是理解起来并不是那么容易。看下面一个例子i： 请分析以下哪些操作是原子性操作： 1234x = 10; //语句1y = x; //语句2x++; //语句3x = x + 1; //语句4 咋一看，有些朋友可能会说上面的4个语句中的操作都是原子性操作。其实只有语句1是原子性操作，其他三个语句都不是原子性操作。 语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。 语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。 同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。 所以上面4个语句只有语句1的操作具备原子性。 也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。 不过这里有一点需要注意：在32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性。但是好像在最新的JDK中，JVM已经保证对64位数据的读取和赋值也是原子性操作了。 从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。 可见性对于可见性，Java提供了volatile关键字来保证可见性。 当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。 而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。 另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。 有序性在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。 在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。 另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。 下面就来具体介绍下happens-before原则（先行发生原则）： 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作； 锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作； volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作； 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C； 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作； 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生； 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行； 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始。 这8条原则摘自《深入理解Java虚拟机》。 这8条规则中，前4条规则是比较重要的，后4条规则都是显而易见的。 下面我们来解释一下前4条规则：对于程序次序规则来说，我的理解就是一段程序代码的执行在单个线程中看起来是有序的。注意，虽然这条规则中提到“书写在前面的操作先行发生于书写在后面的操作”，这个应该是程序看起来执行的顺序是按照代码顺序执行的，因为虚拟机可能会对程序代码进行指令重排序。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，它只会对不存在数据依赖性的指令进行重排序。因此，在单个线程中，程序执行看起来是有序执行的，这一点要注意理解。事实上，这个规则是用来保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。 第二条规则也比较容易理解，也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。 第三条规则是一条比较重要的规则，也是后文将要重点讲述的内容。直观地解释就是，如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。 第四条规则实际上就是体现happens-before原则具备传递性。 深入剖析volatile关键字在前面讲述了很多东西，其实都是为讲述volatile关键字作铺垫，那么接下来我们就进入主题。 volatile关键字的两层语义一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义： 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。 禁止进行指令重排序。 先看一段代码，假如线程1先执行，线程2后执行：12345678//线程1boolean stop = false;while(!stop)&#123; doSomething();&#125; //线程2stop = true; 这段代码是很典型的一段代码，很多人在中断线程时可能都会采用这种标记办法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。 下面解释一下这段代码为何有可能导致无法中断线程。在前面已经解释过，每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。 那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。 但是用volatile修饰之后就变得不一样了： 第一：使用volatile关键字会强制将修改的值立即写入主存； 第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）； 第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。 那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存中缓存变量stop的缓存行无效，然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。 那么线程1读取到的就是最新的正确的值。 volatile保证原子性吗？从上面知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？下面看一个例子：1234567891011121314151617181920212223public class Test &#123; public volatile int inc = 0; public void increase() &#123; inc++; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 大家想一下这段程序的输出结果是多少？也许有些朋友认为是10000。但是事实上运行它会发现每次运行结果都不一致，都是一个小于10000的数字。 可能有的朋友就会有疑问，不对啊，上面是对变量inc进行自增操作，由于volatile保证了可见性，那么在每个线程中对inc自增完之后，在其他线程中都能看到修改后的值啊，所以有10个线程分别进行了1000次操作，那么最终inc的值应该是1000*10=10000。 这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。 在前面已经提到过，自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现： 假如某个时刻变量inc的值为10， 线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了； 然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。 然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。 那么两个线程分别进行了一次自增操作后，inc只增加了1。 解释到这里，可能有朋友会有疑问，不对啊，前面不是保证一个变量在修改volatile变量时，会让缓存行无效吗？然后其他线程去读就会读到新的值，对，这个没错。这个就是上面的happens-before规则中的volatile变量规则，但是要注意，线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没有进行修改，所以线程2根本就不会看到修改的值。 根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。 把上面的代码改成以下任何一种都可以达到效果： 采用synchronized： 1234567891011121314151617181920212223public class Test &#123; public int inc = 0; public synchronized void increase() &#123; inc++; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 采用Lock： 1234567891011121314151617181920212223242526272829public class Test &#123; public int inc = 0; Lock lock = new ReentrantLock(); public void increase() &#123; lock.lock(); try &#123; inc++; &#125; finally&#123; lock.unlock(); &#125; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 采用AtomicInteger： 1234567891011121314151617181920212223public class Test &#123; public AtomicInteger inc = new AtomicInteger(); public void increase() &#123; inc.getAndIncrement(); &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 在java 1.5的java.util.concurrent.atomic包下提供了一些原子操作类，即对基本数据类型的 自增（加1操作），自减（减1操作）、以及加法操作（加一个数），减法操作（减一个数）进行了封装，保证这些操作是原子性操作。atomic是利用CAS来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。 volatile能保证有序性吗？在前面提到volatile关键字能禁止指令重排序，所以volatile能在一定程度上保证有序性。 volatile关键字禁止指令重排序有两层意思： 当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行； 在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。 可能上面说的比较绕，举个简单的例子：12345678//x、y为非volatile变量//flag为volatile变量 x = 2; //语句1y = 0; //语句2flag = true; //语句3x = 4; //语句4y = -1; //语句5 由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。 并且volatile关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。 那么我们回到前面举的一个例子：123456789//线程1:context = loadContext(); //语句1inited = true; //语句2 //线程2:while(!inited )&#123; sleep()&#125;doSomethingwithconfig(context); 前面举这个例子的时候，提到有可能语句2会在语句1之前执行，那么久可能导致context还没被初始化，而线程2中就使用未初始化的context去进行操作，导致程序出错。 这里如果用volatile关键字对inited变量进行修饰，就不会出现这种问题了，因为当执行到语句2时，必定能保证context已经初始化完毕。 volatile的原理和实现机制前面讲述了源于volatile关键字的一些使用，下面我们来探讨一下volatile到底如何保证可见性和禁止指令重排序的。 下面这段话摘自《深入理解Java虚拟机》： “观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令” lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； 它会强制将对缓存的修改操作立即写入主存； 如果是写操作，它会导致其他CPU中对应的缓存行无效。 使用volatile关键字的场景synchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件： 对变量的写操作不依赖于当前值； 该变量没有包含在具有其他变量的不变式中。 实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。 事实上，我的理解就是上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行。 下面列举几个Java中使用volatile的几个场景。 状态标记量123456789volatile boolean flag = false; while(!flag)&#123; doSomething();&#125; public void setFlag() &#123; flag = true;&#125; 12345678910volatile boolean inited = false;//线程1:context = loadContext(); inited = true; //线程2:while(!inited )&#123;sleep()&#125;doSomethingwithconfig(context); double check1234567891011121314151617class Singleton&#123; private volatile static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if(instance==null) &#123; synchronized (Singleton.class) &#123; if(instance==null) instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 至于为何需要这么写请参考：《Java 中的双重检查（Double-Check）》http://blog.csdn.net/dl88250/article/details/5439024http://www.iteye.com/topic/652440 感谢文章转载Java并发编程：volatile关键字解析 最后附上自己的学习代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148package com.wuwii.test.thread;import java.util.concurrent.atomic.AtomicInteger;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;/** * @author Zhang Kai * @version 1.0 * @since &lt;pre&gt;2017/11/18 9:20&lt;/pre&gt; */public class VolatileTest &#123; private volatile int inc; private volatile int inc1; private volatile int inc2; /** * 并发中不适用int， 使用jdk1.5的原子操作类 */ private AtomicInteger inc3 = new AtomicInteger(); private Lock lock = new ReentrantLock(); /** * 自增，不保证原子性 */ private void increase() &#123; inc++; &#125; /** * 使用synchronized保证原子性 */ private synchronized void increase1() &#123; inc1++; &#125; /** * 使用Lock保证原子性 */ private void increase2() &#123; lock.lock(); try &#123; inc2++; &#125; finally&#123; lock.unlock(); &#125; &#125; /** * 使用jdk1.5的原子操作类，保证原子性 */ private void increase3() &#123; inc3.getAndIncrement(); &#125; public static void main(String[] args) &#123; //获取系统运行默认线程数，理论上只有一条主线程，需要注意的是，但是在idea上中默认多了一个monitor ctrlbreak线程。 // 可参考 http://blog.csdn.net/xiaolinzi007/article/details/44487851 int defaultActiveCount = Thread.activeCount(); int threadCount = 10; int increaseCount = 1000; final VolatileTest test = new VolatileTest(); // 创建10个线程，分别自增1000次。 for (int i = 0; i &lt; threadCount; i++) &#123; new Thread(() -&gt; &#123; for (int i1 = 0; i1 &lt; increaseCount; i1++) &#123; test.increase(); test.increase1(); test.increase2(); test.increase3(); &#125; &#125;).start(); &#125; //保证前面的线程都执行完。 while (Thread.activeCount() &gt; defaultActiveCount) &#123; Thread.yield(); &#125; // 打印最终结果，理论结果10 * 1000 = 10000。 System.out.printf("自增后inc为：%d%n", test.inc); System.out.printf("自增后inc1为：%d%n", test.inc1); System.out.printf("自增后inc2为：%d%n", test.inc2); System.out.printf("自增后inc3为：%d%n", test.inc3.get()); /** * 状态标记，利用volatile可见性属性，保持线程有序执行 * &lt;p&gt;写一个线程做完事情后将标记赋值true，线程二一直阻塞标记为true时执行&lt;p/&gt; */ new Thread(() -&gt; &#123; try &#123; Thread.sleep(3000); FlagTest.flag = true; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); new Thread(() -&gt;&#123; int i = 0; while (!FlagTest.flag) &#123; try &#123; System.out.printf("%s s后flag改为true%n", 3 - i); Thread.sleep(1000); i++; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.printf("flag为true 了"); &#125;).start(); &#125;&#125;/** * 使用volatile场景&lt;/br&gt; * 1. 状态标记量: 并发时候保证程序按照有序运行&lt;/br&gt; * 2. double check：并发中为了减少同步的开销，于是有了双重检查模式。 */class FlagTest &#123; /** * 状态标记量 */ public static volatile boolean flag = false; /** * 双重检查单例模式 */ private volatile static FlagTest instance = null; private FlagTest() &#123; &#125; /** * 双重检查double check * &lt;p&gt;并发情况下为了减少同步的开销，于是有了双重检查模式。&lt;/p&gt; * @return FlagTest */ public static FlagTest getInstance() &#123; if(instance==null) &#123; synchronized (FlagTest.class) &#123; if(instance==null)&#123; instance = new FlagTest(); &#125; &#125; &#125; return instance; &#125;&#125; 执行结果：12345678自增后inc为：9996自增后inc1为：10000自增后inc2为：10000自增后inc3为：100003 s后flag改为true2 s后flag改为true1 s后flag改为trueflag为true 刚才的inc++操作来说，这个操作其实细分为三步，读inc的值给temp，将temp+1，赋值给inc。 当线程1将inc读入内存，然后被阻塞。 线程2也将inc读入内存中，然后执行过第二步，temp+1，然后被阻塞。 线程1被唤醒，此时并没有对inc执行写操作，所以线程1不需要重新从内存读，所以执行完+1操作被赋值后重新写入主存中。 线程2被唤醒，由于inc执行了写操作，导致线程2中的inc缓存失效，所以从内存中重新读进来此时的inc值，由于已经执行过第二步了，此时将最新的temp赋值给inc，然后重新写入内存。就在刚才那一步发生了数据不一致性，此时的inc总共被加了一次。 总结 Java内存模型，原子性，可见性，有序性的理解； volatile修饰的变量具有什么样的特性：可见性，禁止重排序； 并发中的使用方法和运用场景。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20171117]]></title>
    <url>%2F20171117.html</url>
    <content type="text"><![CDATA[今天天气可真是差啊，下班后出门骑了辆小黄车，没骑到一百米，雨就下起来，只好放下，毕竟大晚上撑伞骑车不太安全，只好选择去公交车站坐公交把。 我的天，一上公交车，还没坐一站路，堵瞎了，我这人虽然每次都是慢半拍的人，喜欢慢节奏的事情，但是了，堵车我最不喜欢的事情，关键我还坐公交车上。 后来接到一个消息说她被前男友骚扰了，说实话啊，我最讨厌的就是渣男了，但是还是要注意形象，去安慰下把，我也是搞不懂状况啊，多了不写了，就是堵了半个小时下车了，准备去她学校看看吧，这路人都不让走的，车一辆接一辆的。终于换车后，堵了一会儿，接到消息说她要回家了，长吁一口气了，其实我挺害怕的，但是听到消息的第一刻就是想到江歌案，所以我才想赶过去，不想写下去了，其实女孩子追到被逼回家了的，这也太可恶了吧。 搞到很晚才回，想到去拿快递，不错，居然没关门，拿回来一看，打开快递，没看码子，拆开试穿了一下，我的妈啊，这么大，我买的衣服全发成大码了，只能去实体店换了，（牌子就不暴露了，好坑。 今天下个班，搞得好累啊，好好睡个觉，明天周六上午还要去公司培训。 晚安/。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 8 中HashMap源码分析]]></title>
    <url>%2Fjava-hashmap.html</url>
    <content type="text"><![CDATA[HashMap 文档 HashMap是基于哈希表的Map接口实现的,此实现提供所有可选的映射操作。存储的是&lt;key，value&gt;对的映射，允许多个null值和一个null键。但此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 除了HashMap是非同步以及允许使用null外，HashMap 类与 Hashtable大致相同。 此实现假定哈希函数将元素适当地分布在各桶之间，可为基本操作（get 和 put）提供稳定的性能。迭代collection 视图所需的时间与 HashMap 实例的“容量”（桶的数量）及其大小（键-值映射关系数）成比例。所以，如果迭代性能很重要，则不要将初始容量设置得太高（或将加载因子设置得太低）。 HashMap 的实例有两个参数影响其性能：初始容量 和加载因子。容量 是哈希表中桶的数量，初始容量只是哈希表在创建时的容量。加载因子 是哈希表在其容量自动增加之前可以达到多满的一种尺度。当哈希表中的条目数超出了加载因子与当前容量的乘积时，则要对该哈希表进行 rehash 操作（即重建内部数据结构），从而哈希表将具有大约两倍的桶数。 通常，默认加载因子 (0.75) 在时间和空间成本上寻求一种折衷。加载因子过高虽然减少了空间开销，但同时也增加了查询成本（在大多数 HashMap 类的操作中，包括 get 和 put 操作，都反映了这一点）。在设置初始容量时应该考虑到映射中所需的条目数及其加载因子，以便最大限度地减少 rehash 操作次数。如果初始容量大于最大条目数除以加载因子，则不会发生 rehash 操作。 注意，此实现不是同步的。 如果多个线程同时访问一个HashMap实例，而其中至少一个线程从结构上修改了列表，那么它必须保持外部同步。这通常是通过同步那些用来封装列表的 对象来实现的。但如果没有这样的对象存在，则应该使用{@link Collections#synchronizedMap Collections.synchronizedMap}来进行“包装”，该方法最好是在创建时完成，为了避免对映射进行意外的非同步操作。1Map m = Collections.synchronizedMap(new HashMap(...)); 由所有此类的“collection 视图方法”所返回的迭代器都是快速失败的：在迭代器创建之后，如果从结构上对映射进行修改，除非通过迭代器本身的remove 方法，其他任何时间任何方式的修改，迭代器都将抛出 ConcurrentModificationException。因此，面对并发的修改，迭代器很快就会完全失败，而不会在将来不确定的时间发生任意不确定行为的风险。 注意，迭代器的快速失败行为不能得到保证，一般来说，存在非同步的并发修改时，不可能作出任何坚决的保证。快速失败迭代器尽最大努力抛出 ConcurrentModificationException。因此，编写依赖于此异常的程序的做法是错误的，正确做法是：迭代器的快速失败行为应该仅用于检测程序错误。 jdk版本：jdk1.8.0_144 HashMap的数据结构HashMap实际上是一个“链表的数组”的数据结构，每个元素存放链表头结点的数组，即数组（散列桶）中的每一个元素都是链表。 解决Hash冲突 HashMap就是使用哈希表来存储的。哈希表为解决冲突，可以采用开放地址法和链地址法等来解决问题，Java中HashMap采用了链地址法（拉链法）。链地址法，简单来说，就是数组加链表的结合。在每个数组元素上都一个链表结构，当数据被Hash后，得到数组下标，把数据放在对应下标元素的链表上。 有时候计算Hash值的时候，会出现相同的情况，这样两个key就存储到相同的位置上了，这个时候会出现Hash碰撞。 HashMap的属性实现的接口和继承的类12public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable 实际上HashMap没有从AbstractMap父亲中继承任何属性，从实现的接口上看，HashMap拥有克隆和序列化的属性。 属性123456789101112131415161718192021222324252627282930313233343536373839//默认初始容量16，必须为2的幂 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 //最大容量 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //默认加载因子 static final float DEFAULT_LOAD_FACTOR = 0.75f; //使用红黑树而不是链表的阈值 static final int TREEIFY_THRESHOLD = 8; /** * The bin count threshold for untreeifying a (split) bin during a * resize operation. Should be less than TREEIFY_THRESHOLD, and at * most 6 to mesh with shrinkage detection under removal. */ static final int UNTREEIFY_THRESHOLD = 6; //table是一个Node&lt;K,V&gt;[]数组类型，而Node&lt;K,V&gt;实际上就是一个元素值为&lt;key,value&gt;对的单向链表。 //哈希表的"key-value键值对"都是存储在Node&lt;K,V&gt;数组中的。 transient Node&lt;K,V&gt;[] table; //用来指向entrySet()返回的set集合 transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; //HashMap的大小,即保存的键值对的数量 transient int size; //用来实现fail-fast机制的，记录HashMap结构化修改的次数 transient int modCount; //下次需扩容的临界值，size&gt;=threshold就会扩容 //如果table数组没有被分配，则该值为初始容量值16；或若该值为0，也表明该值为初始容量值 int threshold; //加载因子 final float loadFactor; tabletable是一个Node[]数组类型，而Node实际上就是一个单向链表，哈希桶数组。哈希表的”key-value键值对”都是存储在Node数组中的。12345678910111213141516171819202122232425262728293031323334353637383940414243//实现Map.Entry&lt;K,V&gt;接口 static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; //hash码 final K key; V value; Node&lt;K,V&gt; next; //指向链表中下一个实例 Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; //返回此映射项的哈希值:key值的哈希码与value值的哈希码按位异或的结果 public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; //用指定值替换对应于此项的值,并返回旧值 public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; //比较指定对象与此项的相等性 public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; &#125; 在HashMap中，哈希桶数组table的长度length大小必须为2的n次方，而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法。 loadFactor加载因子HashMap的初始化大小length为16（默认值），默认加载因子0.75，threshold是HashMap所能容纳的最大数据量的Node(键值对)个数。threshold = length * Load factor。也就是说，在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多。 threshold就是在此Load factor和length(数组长度)对应下允许的最大元素数目，超过这个数目就重新resize(扩容)，扩容后的HashMap容量是之前容量的两倍。默认的负载因子0.75是对空间和时间效率的一个平衡选择，建议大家不要修改，除非在时间和空间比较特殊的情况下，如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值；相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值可以大于1。 size大小HashMap中实际存在的键值对数量。 方法构造函数HashMap提供了四种方式的构造器，可以构造一个带指定初始容量和加载因子的空HashMap，构造一个带指定初始容量和默认加载因子(0.75)的空 HashMap，构造一个默认初始容量为16和默认加载因子为0.75的空HashMap，以及构造一个包含指定Map的元素的HashMap，容量与指定Map容量相同，加载因子为默认的0.75。1234567891011121314151617181920212223242526272829303132333435363738394041//找出“大于Capacity”的最小的2的幂,使Hash表的容量保持为2的次方倍 //算法的思想：通过使用逻辑运算来替代取余，这里有一个规律，就是当N为2的次方（Power of two），那么X％N==X&amp;(N-1)。 static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; //&gt;&gt;&gt; 无符号右移,高位补0 n |= n &gt;&gt;&gt; 2; //a|=b的意思就是把a和b按位或然后赋值给a n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; &#125; //构造一个带指定初始容量和加载因子的空HashMap public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); &#125; //构造一个带指定初始容量和默认加载因子(0.75)的空 HashMap public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; //构造一个具有默认初始容量 (16)和默认加载因子 (0.75)的空 HashMap public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125; //构造一个映射关系与指定 Map相同的新 HashMap,容量与指定Map容量相同，加载因子为默认的0.75 public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); &#125; 确定哈希桶数组索引位置不管增加、删除、查找键值对，定位到哈希桶数组的位置都是很关键的第一步。前面说过HashMap的数据结构是数组和链表的结合，所以我们当然希望这个HashMap里面的元素位置尽量分布均匀些，尽量使得每个位置上的元素数量只有一个，那么当我们用hash算法求得这个位置的时候，马上就可以知道对应位置的元素就是我们要的，不用遍历链表，大大优化了查询的效率。HashMap定位数组索引位置，直接决定了hash方法的离散性能。先看看源码的实现(方法一+方法二):1234567891011方法一：static final int hash(Object key) &#123; //jdk1.8 &amp; jdk1.7 int h; // h = key.hashCode() 为第一步 取hashCode值 // h ^ (h &gt;&gt;&gt; 16) 为第二步 高位参与运算 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;方法二：static int indexFor(int h, int length) &#123; //jdk1.7的源码，jdk1.8没有这个方法，但是实现原理一样的 return h &amp; (length-1); //第三步 取模运算&#125; 这里的Hash算法本质上就是三步：取key的hashCode值、高位运算、取模运算。 对于任意给定的对象，只要它的hashCode()返回值相同，那么程序调用方法一所计算得到的Hash码值总是相同的。我们首先想到的就是把hash值对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，模运算的消耗还是比较大的，在HashMap中是这样做的：调用方法二来计算该对象应该保存在table数组的哪个索引处。 这个方法非常巧妙，它通过h &amp; (table.length -1)来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化。当length总是2的n次方时，h&amp; (length-1)运算等价于对length取模，也就是h%length，但是&amp;比%具有更高的效率。 在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度、功效、质量来考虑的，这么做可以在数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。 HashMap的put方法HashMap提供了put(K key, V value)、putAll(Map&lt;? extends K, ? extends V&gt; m)这些添加键值对的方法。HashMap的put方法执行过程可以通过下图来理解， 判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容； 根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③； 判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals； 判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤； 遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可； 插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。 put方法源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103/** * 在此映射中关联指定值与指定键。如果该映射以前包含了一个该键的映射关系，则旧值被替换。 * * @param key 指定值将要关联的键 * @param value 指定键将要关联的值 * @return 与 key关联的旧值；如果 key没有任何映射关系，则返回 null。（返回 null 还可能表示该映射之前将null与 key关联。） */ public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; /** * 用于实现 Map.put()和相关的方法 * * @param hash 键的hash码 * @param key 键 * @param value 值 * @param onlyIfAbsent if true, don't change existing value * @param evict evict=false：表明该hash表处于初始化创建的过程中 * @return previous value, or null if none */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //步骤 1 ：tab为空则创建 //此处分两种情况：1.当table为null时，用默认容量16初始化table数组；2.当table非空时 if ((tab = table) == null || (n = tab.length) == 0) //旧hash表为null或旧hash表长度为0 n = (tab = resize()).length; //初始化hash表的长度（16） //步骤 2 //此处又分为两种情况：1.key的hash值对应的那个节点为空；2.key的hash值对应的那个节点不为空 if ((p = tab[i = (n - 1) &amp; hash]) == null) //该key的hash值对应的那个节点为空，即表示还没有元素被散列至此 tab[i] = newNode(hash, key, value, null); //则创建一个新的new Node&lt;&gt;(hash, key, value, next); else &#123; //该key的hash值对应的那个节点不为空，先与链表上的第一个节点p比较 Node&lt;K,V&gt; e; K k; // 步骤 3：节点key存在，直接覆盖value if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 步骤 4：判断该链为红黑树 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 步骤 5：该链为链表 的情况下进行遍历table else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //链表长度大于8转换为红黑树进行处理 TREEIFY_THRESHOLD = 8 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // key已经存在的话 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; //向后查找 &#125; &#125; //若该key对应的value已经存在，则用新的value取代旧的value if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 步骤 6：如果加入该键值对后超过最大阀值，则进行resize操作 ，就扩容 threshold： //单词解释--阈(yu)值,不念阀(fa)值！顺便学下语文咯。 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; //将指定映射的所有映射关系复制到此映射中，这些映射关系将替换此映射目前针对指定映射中所有键的所有映射关系。 public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; putMapEntries(m, true); &#125; //用于帮助实现Map.putAll()方法 和Map构造器，当evict=false时表示构造初始HashMap。 final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; int s = m.size(); //得到指定Map的大小 if (s &gt; 0) &#123; if (table == null) &#123; // pre-size float ft = ((float)s / loadFactor) + 1.0F; int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); //得到按指定Map大小计算出的HashMap所需的容量 if (t &gt; threshold) //如果容量大于阈值 threshold = tableSizeFor(t); &#125; else if (s &gt; threshold) //指定Map的大小&gt;扩容临界值,扩容 resize(); //通过迭代器，将“m”中的元素逐个添加到HashMap中 for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125; &#125; HashMap的扩容机制resize在HashMap的四种构造函数中并没有对其成员变量Node[] table进行任何初始化的工作，那么HashMap是如何构造一个默认初始容量为16的空表的？该初始化的诱发条件是在向HashMap中添加第一对时，通过put(K key, V value) -&gt; putVal(hash(key), key, value, false, true) -&gt; resize()方法。故HashMap中尤其重要的resize()方法主要实现了两个功能： 在table数组为null时，对其进行初始化，默认容量为16； 当tables数组非空，但需要调整HashMap的容量时，将hash表容量翻倍。 jdk1.8中的resize：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384//resize()方法作用有两种：1.初始化hash表的容量，为16； 2.将hash表容量翻倍 final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; //旧hash表 int oldCap = (oldTab == null) ? 0 : oldTab.length; //旧hash表容量 int oldThr = threshold; //旧hash表阈值 int newCap, newThr = 0; //新hash表容量与扩容临界值 //2.旧hash表非空，则表容量翻倍 if (oldCap &gt; 0) &#123; //如果当前的hash表长度已经达到最大值，则不在进行调整 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //更新新hash表容量：翻倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) //更新扩容临界值 newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; //1. 初始化hash表容量，设为默认值16，并且计算临界值。 else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; //设置下次扩容的临界值 threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) //创建一个初始容量为新hash表长度的newTab数组 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; //如果旧hash表非空，则按序将旧hash表中的元素重定向到新hash表 if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; //e按序指向oldTab数组中的元素，即每个链表中的头结点 if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) //如果链表只有一个头节点 newTab[e.hash &amp; (newCap - 1)] = e; // 如果节点是红黑树 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //对链表进行秩序维护：因为我们使用的是两倍扩容的方法，所以每个桶里面的元素必须要么待在原来的 //索引所对应的位置，要么在新的桶中位置偏移两倍 else &#123; Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 扩容是使用2次幂的扩展(指长度扩为原来2倍)，所以，经过rehash之后，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。 元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化： 因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，可以看看下图为16扩充为32的resize示意图： 这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。这一块就是JDK1.8新增的优化点。有一点注意区别，JDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8不会倒置。 查找HashMap提供了get(Object key)、containsKey(Object key)、containsValue(Object value)这些查找键值对的方法。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//返回指定key所映射的value；如果对于该键来说，此映射不包含任何映射关系，则返回 null public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //key的哈希值为数组下标 if (first.hash == hash &amp;&amp; //检查第一个节点 ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; //如果第一个节点不对，则向后检查 if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; //如果此映射包含对于指定键的映射关系，则返回 true。 public boolean containsKey(Object key) &#123; return getNode(hash(key), key) != null; &#125; //如果此映射将一个或多个键映射到指定值，则返回 true。 public boolean containsValue(Object value) &#123; Node&lt;K,V&gt;[] tab; V v; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; //外层循环搜索数组 for (int i = 0; i &lt; tab.length; ++i) &#123; //内层循环搜索链表 for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; if ((v = e.value) == value || (value != null &amp;&amp; value.equals(v))) return true; &#125; &#125; &#125; return false; &#125; 清空与删除HashMap提供了remove(Object key)删除键值对、clear()清除所有键值对的方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970//从此映射中移除指定键的映射关系（如果存在） public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; &#125; /** * 用于实现 Map.remove()方法和其他相关的方法 * * @param hash 键的hash值 * @param key 键 * @param value the value to match if matchValue, else ignored * @param matchValue if true only remove if value is equal * @param movable if false do not move other nodes while removing * @return the node, or null if none */ final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; //table数组非空，键的hash值所指向的数组中的元素非空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; //node指向最终的结果结点，e为链表中的遍历指针 if (p.hash == hash &amp;&amp; //检查第一个节点，如果匹配成功 ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; //如果第一个节点匹配不成功，则向后遍历链表查找 else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) //删除node结点 tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null; &#125; //从此映射中移除所有映射关系 public void clear() &#123; Node&lt;K,V&gt;[] tab; modCount++; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; size = 0; for (int i = 0; i &lt; tab.length; ++i) tab[i] = null; &#125; &#125; 总结 Java 8 中HashMap是数组+链表+红黑树； 哈希桶数组table的长度length大小必须为2的n次方，也就是我想要创建一个长度为19的HashMap，那么它需要创建的大小为32；HashMap 的 bucket 数组大小一定是2的幂，如果 new 的时候指定了容量且不是2的幂，实际容量会是最接近(大于)指定容量的2的幂，比如 new HashMap&lt;&gt;(19)，比19大且最接近的2的幂是32，实际容量就是32。 没有特殊要求，负载因子使用默认值0.75，并且它可以大于1；加载因子是表示Hsah表中元素的填满的程度。若加载因子越大，填满的元素越多，好处是，空间利用率高了，但冲突的机会加大了。反之，加载因子越小，填满的元素越少，好处是，冲突的机会减小了，但空间浪费多了。冲突的机会越大，则查找的成本越高；反之,查找的成本越小，因而,查找时间就越小. HashMap是线程不安全的，不要在并发的环境中同时操作HashMap，建议使用ConcurrentHashMap，HashTable的并发性不如ConcurrentHashMap； 扩容特别消耗性能，初始化的时候，尽量控制好HashMap的大小，避免频繁扩容； HashMap 在 new 后并不会立即分配哈希桶数组，而是第一次 put 时初始化，类似 ArrayList 在第一次 add 时分配空间。 HashMap 在 put 的元素数量大于 Capacity * LoadFactor（默认16 * 0.75） 之后会进行扩容。 Java 8在哈希碰撞的链表长度达到TREEIFY_THRESHOLD（默认8)后，会把该链表转变成树结构，提高了性能。 Java 8在 resize() 的时候，通过巧妙的设计，减少了 rehash 的性能消耗。 参考文章 Java 8系列之重新认识HashMapjdk1.8.0_45源码解读——HashMap的实现HashMap数据结构HashMap的性能提升从之链表到二叉树]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Hash碰撞冲突方法总结]]></title>
    <url>%2Fhash-crash.html</url>
    <content type="text"><![CDATA[Hash碰撞冲突我们知道，对象Hash的前提是实现equals()和hashCode()两个方法，那么HashCode()的作用就是保证对象返回唯一hash值，但当两个对象计算值一样时，这就发生了碰撞冲突。如下将介绍如何处理冲突，当然其前提是一致性hash。 解决冲突开放地址法开放地执法有一个公式:Hi=(H(key)+di) MOD m i=1,2,…,k(k&lt;=m-1)其中，m为哈希表的表长。di 是产生冲突的时候的增量序列。如果di值可能为1,2,3,…m-1，称线性探测再散列。如果di取1，则每次冲突之后，向后移动1个位置.如果di取值可能为1,-1,2,-2,4,-4,9,-9,16,-16,…kk,-kk(k&lt;=m/2)，称二次探测再散列。如果di取值可能为伪随机数列。称伪随机探测再散列。 再哈希法当发生冲突时，使用第二个、第三个、哈希函数计算地址，直到无冲突时。缺点：计算时间增加。比如上面第一次按照姓首字母进行哈希，如果产生冲突可以按照姓字母首字母第二位进行哈希，再冲突，第三位，直到不冲突为止 链地址法（拉链法）将所有关键字为同义词的记录存储在同一线性链表中。如下： 建立一个公共溢出区假设哈希函数的值域为[0,m-1],则设向量HashTable[0..m-1]为基本表，另外设立存储空间向量OverTable[0..v]用以存储发生冲突的记录。 拉链法的优缺点优点 拉链法处理冲突简单，且无堆积现象，即非同义词决不会发生冲突，因此平均查找长度较短； 由于拉链法中各链表上的结点空间是动态申请的，故它更适合于造表前无法确定表长的情况； 开放定址法为减少冲突，要求装填因子α较小，故当结点规模较大时会浪费很多空间。而拉链法中可取α≥1，且结点较大时，拉链法中增加的指针域可忽略不计，因此节省空间； 在用拉链法构造的散列表中，删除结点的操作易于实现。只要简单地删去链表上相应的结点即可。而对开放地址法构造的散列表，删除结点不能简单地将被删结 点的空间置为空，否则将截断在它之后填人散列表的同义词结点的查找路径。这是因为各种开放地址法中，空地址单元(即开放地址)都是查找失败的条件。因此在 用开放地址法处理冲突的散列表上执行删除操作，只能在被删结点上做删除标记，而不能真正删除结点。 缺点指针需要额外的空间，故当结点规模较小时，开放定址法较为节省空间，而若将节省的指针空间用来扩大散列表的规模，可使装填因子变小，这又减少了开放定址法中的冲突，从而提高平均查找速度。 文章转载 解决Hash碰撞冲突方法总结]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>哈希算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解一致性哈希算法(consistent hashing)]]></title>
    <url>%2Fconsistent-hashing.html</url>
    <content type="text"><![CDATA[一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希（DHT）实现算法，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简 单哈希算法带来的问题，使得分布式哈希（DHT）可以在P2P环境中真正得到应用。一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义： 平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。 单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。 分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。 负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。分布式集群中，对机器的添加删除在分布式集群中，对机器的添加删除，或者机器故障后自动脱离集群这些操作是分布式集群管理最基本的功能。如果采用常用的hash(object)%N算法，那么在有机器添加或者删除后，很多原有的数据就无法找到了，这样严重的违反了单调性原则。接下来主要讲解一下一致性哈希算法是如何设计的： 环形Hash空间按照常用的hash算法来将对应的key哈希到一个具有2^32次方个桶的空间中，即0~(2^32)-1的数字空间中。现在我们可以将这些数字头尾相连，想象成一个闭合的环形。如下图： 把数据通过一定的hash算法处理后映射到环上现在我们将object1、object2、object3、object4四个对象通过特定的Hash函数计算出对应的key值，然后散列到Hash环上。如下图：1234Hash(object1) = key1；Hash(object2) = key2；Hash(object3) = key3；Hash(object4) = key4； 将机器通过hash算法映射到环上在采用一致性哈希算法的分布式集群中将新的机器加入，其原理是通过使用与对象存储一样的Hash算法将机器也映射到环中（一般情况下对机器的hash计算是采用机器的IP或者机器唯一的别名作为输入值），然后以顺时针的方向计算，将所有对象存储到离自己最近的机器中。假设现在有NODE1，NODE2，NODE3三台机器，通过Hash算法得到对应的KEY值，映射到环中，其示意图如下：123Hash(NODE1) = KEY1;Hash(NODE2) = KEY2;Hash(NODE3) = KEY3; 通过上图可以看出对象与机器处于同一哈希空间中，这样按顺时针转动object1存储到了NODE1中，object3存储到了NODE2中，object2、object4存储到了NODE3中。在这样的部署环境中，hash环是不会变更的，因此，通过算出对象的hash值就能快速的定位到对应的机器中，这样就能找到对象真正的存储位置了。 机器的删除与添加普通hash求余算法最为不妥的地方就是在有机器的添加或者删除之后会照成大量的对象存储位置失效，这样就大大的不满足单调性了。下面来分析一下一致性哈希算法是如何处理的。 节点（机器）的删除以上面的分布为例，如果NODE2出现故障被删除了，那么按照顺时针迁移的方法，object3将会被迁移到NODE3中，这样仅仅是object3的映射位置发生了变化，其它的对象没有任何的改动。如下图： 节点（机器）的添加 如果往集群中添加一个新的节点NODE4，通过对应的哈希算法得到KEY4，并映射到环中，如下图： 通过按顺时针迁移的规则，那么object2被迁移到了NODE4中，其它对象还保持这原有的存储位置。通过对节点的添加和删除的分析，一致性哈希算法在保持了单调性的同时，还是数据的迁移达到了最小，这样的算法对分布式集群来说是非常合适的，避免了大量数据迁移，减小了服务器的的压力。 平衡性根据上面的图解分析，一致性哈希算法满足了单调性和负载均衡的特性以及一般hash算法的分散性，但这还并不能当做其被广泛应用的原由，因为还缺少了平衡性。下面将分析一致性哈希算法是如何满足平衡性的。hash算法是不保证平衡的，如上面只部署了NODE1和NODE3的情况（NODE2被删除的图），object1存储到了NODE1中，而object2、object3、object4都存储到了NODE3中，这样就照成了非常不平衡的状态。在一致性哈希算法中，为了尽可能的满足平衡性，其引入了虚拟节点。 ——“虚拟节点”（ virtual node ）是实际节点（机器）在 hash 空间的复制品（ replica ），一实际个节点（机器）对应了若干个“虚拟节点”，这个对应个数也成为“复制个数”，“虚拟节点”在 hash 空间中以hash值排列。 以上面只部署了NODE1和NODE3的情况（NODE2被删除的图）为例，之前的对象在机器上的分布很不均衡，现在我们以2个副本（复制个数）为例，这样整个hash环中就存在了4个虚拟节点，最后对象映射的关系图如下： 根据上图可知对象的映射关系：object1-&gt;NODE1-1，object2-&gt;NODE1-2，object3-&gt;NODE3-2，object4-&gt;NODE3-1。通过虚拟节点的引入，对象的分布就比较均衡了。那么在实际操作中，正真的对象查询是如何工作的呢？对象从hash到虚拟节点到实际节点的转换如下图： 虚拟节点的hash计算可以采用对应节点的IP地址加数字后缀的方式。例如假设NODE1的IP地址为192.168.1.100。引入“虚拟节点”前，计算 cache A 的 hash 值：Hash(“192.168.1.100”);引入“虚拟节点”后，计算“虚拟节”点NODE1-1和NODE1-2的hash值：Hash(“192.168.1.100#1”); // NODE1-1Hash(“192.168.1.100#2”); // NODE1-2 文章转载 每天进步一点点——五分钟理解一致性哈希算法(consistent hashing)]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>哈希算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 8 Optional类的分析与使用]]></title>
    <url>%2Fjava-optional.html</url>
    <content type="text"><![CDATA[Optional 类 是jdk 1.8后新添加的特性，阿里巴巴的代码规范也明确说明了使用 Optional 来防止NPE。 Optional 类是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。Optional 是个容器：它可以保存类型T的值，或者仅仅保存null。Optional提供很多有用的方法，这样我们就不用显式进行空值检测。Optional 类的引入很好的解决空指针异常。 它拥有的方法： 属性123456789101112// @since 1.8public final class Optional&lt;T&gt; &#123; /** * Common instance for &#123;@code empty()&#125;. */ private static final Optional&lt;?&gt; EMPTY = new Optional&lt;&gt;(); /** * If non-null, the value; if null, indicates no value is present */ private final T value;&#125; value 属性就是存储数据的地方。如果为null，表示没有值的存在，取值的时候如果没有默认值，会抛出空指针。 方法构造方法它拥有两个构造方法： 12345678910111213141516171819/** * Constructs an empty instance. * * @implNote Generally only one empty instance, &#123;@link Optional#EMPTY&#125;, * should exist per VM. */private Optional() &#123; this.value = null;&#125;/** * Constructs an instance with the value present. * * @param value the non-null value to be present * @throws NullPointerException if value is null */private Optional(T value) &#123; this.value = Objects.requireNonNull(value);&#125; 第一个构造一个空的Optional； 第二个构造一个值为value的Optional，值为null会抛出NPE； of 为非null的值创建一个Optional。 of方法通过工厂方法创建Optional类。需要注意的是，创建对象时传入的参数不能为null。如果传入参数为null，则抛出NullPointerException。源码：123public static &lt;T&gt; Optional&lt;T&gt; of(T value) &#123; return new Optional&lt;&gt;(value);&#125; 可以看出它最后调用的是第二个有参的构造函数，所以它传入的参数也为null会抛出空指针。 123Optional&lt;String&gt; spring = Optional.of("SPRING");Optional&lt;String&gt; emptyStr = Optional.of("");Optional&lt;String&gt; nullValue = Optional.of(null); 最后个创建Optional实例会抛出空指针异常。 ofNullable123456789101112/** * Returns an &#123;@code Optional&#125; describing the specified value, if non-null, * otherwise returns an empty &#123;@code Optional&#125;. * * @param &lt;T&gt; the class of the value * @param value the possibly-null value to describe * @return an &#123;@code Optional&#125; with a present value if the specified value * is non-null, otherwise an empty &#123;@code Optional&#125; */public static &lt;T&gt; Optional&lt;T&gt; ofNullable(T value) &#123; return value == null ? empty() : of(value);&#125; 为指定的值创建一个Optional，如果指定的值为null，则返回一个空的Optional。相比较of 方法，能够接受 null 参数。 isPresent判断值是否存在。值不为null，返回true。123public boolean isPresent() &#123; return value != null;&#125; get取出存在Optional 中的值，为Null 抛出NoSuchElementException异常123456 public T get() &#123; if (value == null) &#123; throw new NoSuchElementException("No value present"); &#125; return value;&#125; ifPresent123456789101112/** * If a value is present, invoke the specified consumer with the value, * otherwise do nothing. * * @param consumer block to be executed if a value is present * @throws NullPointerException if value is present and &#123;@code consumer&#125; is * null */public void ifPresent(Consumer&lt;? super T&gt; consumer) &#123; if (value != null) consumer.accept(value);&#125; 对传入的值使用Consumer接口的accept方法进行处理，123456/** * Performs this operation on the given argument. * * @param t the input argument */void accept(T t); 实际上就是可以使用函数式编程了，使用lambda表达式方法了，前提是1spring.ifPresent(a -&gt; System.out.println(a.indexOf(&quot;I&quot;))); 结果为 3。 orElse如果有值则将其返回，否则返回指定的其它值。 12System.out.printf("有值的Optional: %s，没值的Optional：%s%n", spring.orElse("summer"), nullValue.orElse("summer")); 打印结果：1有值的Optional: SPRING，没值的Optional：summer orElseGetorElseGet与orElse方法类似，区别在于得到的默认值。orElse方法将传入的字符串作为默认值，orElseGet方法可以接受Supplier接口的实现用来生成默认值，由于参数是接口形式，直接使用lambda表达式，更方便。能接收函数式返回处理的数据。123System.out.printf("有值的Optional: %s，没值的Optional：%s%n", spring.orElseGet(() -&gt; "summer"), nullValue.orElseGet(() -&gt; "summer")); 输出：1有值的Optional: SPRING，没值的Optional：summer orElseThrow如果有值则将其返回，否则抛出supplier接口创建的异常。在上面的 orElseGet 方法中，传入的是Supplier接口的实现，在orElseThrow中传入一个Throwable ，如果值不存在来抛出传入的指定类型异常，源码：1234567public &lt;X extends Throwable&gt; T orElseThrow(Supplier&lt;? extends X&gt; exceptionSupplier) throws X &#123; if (value != null) &#123; return value; &#125; else &#123; throw exceptionSupplier.get(); &#125;&#125; 使用方法：12345678910111213141516171819202122 //orElseThrow System.out.printf("orElseThrow有值的Optional: %s，没值的Optional：%s%n", spring.orElseThrow(OptionalThrowable::new), nullValue.orElseThrow(OptionalThrowable::new));/** * 自定义的Optional异常类 */class OptionalThrowable extends Throwable &#123; public OptionalThrowable() &#123; &#125; public OptionalThrowable(String message) &#123; super(message); &#125; @Override public String getMessage() &#123; //return super.getMessage(); return "这个Optional 是空值"; &#125;&#125; 结果符合预期错误抛出结果：1234有值的Optional: SPRING，没值的Optional：summerException in thread &quot;main&quot; com.wuwii.utils.OptionalThrowable: 这个Optional 是空值 at java.util.Optional.orElseThrow(Optional.java:290) at com.wuwii.utils.OptionalTest.main(OptionalTest.java:28) map 如果有值，则对其执行调用mapping函数得到返回值。如果返回值不为null，则创建包含mapping返回值的Optional作为map方法返回值，否则返回空Optional。 map就是stream中的方法一样的，是用来操作的，用来对Optional实例的值执行一系列操作，所以我们可以灵活的使用Function包的方法和lamdba表达式。 123//map Optional&lt;String&gt; castedOptional = spring.map(String::toLowerCase); System.out.printf("转换过后的值：%s%n", castedOptional.orElseGet(null)); 输出结果：1转换过后的值：spring 可以看出转换成小写的了。 flatMap 如果有值，为其执行mapping函数返回Optional类型返回值，否则返回空Optional。flatMap与map（Funtion）方法类似，区别在于flatMap中的mapper返回值必须是Optional。调用结束时，flatMap不会对结果用Optional封装。 123//flatMap Optional&lt;String&gt; upperOptional = castedOptional.flatMap(a -&gt; Optional.of(a.toUpperCase())); System.out.printf("将上面小写的castedOptional 转换成大写：%s%n", upperOptional.orElseGet(null)); 输出结果：1将上面小写的castedOptional 转换成大写：SPRING filter 如果有值并且满足断言条件返回包含该值的Optional，否则返回空Optional。 过滤，对于filter函数我们应该传入实现了Predicate接口的lambda表达式。 12345/filter //过滤掉长度不大于10的，SPRING长度小于10，故此被过滤了 Optional&lt;String&gt; filterOptional = upperOptional.filter(a -&gt; a.length() &gt; 10); System.out.printf("过滤掉长度不大于10的 ：%s%n", filterOptional.orElse("Default value")); &#125; 输出结果：1过滤掉长度不大于10的结果 ：Default value 学习的所有代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package com.wuwii.utils;import java.util.Optional;/** * 学习Optional * @author: Zhang Kai * @since : 2017/11/12 20:40 */public class OptionalTest &#123; public static void main(String[] args) &#123; //of Optional&lt;String&gt; spring = Optional.of("SPRING"); Optional&lt;String&gt; emptyStr = Optional.of(""); //会抛出异常NPE //Optional&lt;String&gt; nullValue1 = Optional.of(null); //不会抛异常，做了判断 Optional&lt;String&gt; nullValue = Optional.ofNullable(null); //ifPresent spring.ifPresent(a -&gt; System.out.println(a.indexOf("I"))); //orElse System.out.printf("orElse有值的Optional: %s，没值的Optional：%s%n", spring.orElse("summer"), nullValue.orElse("summer")); //orElseGet System.out.printf("orElseGet有值的Optional: %s，没值的Optional：%s%n", spring.orElseGet(() -&gt; "summer"), nullValue.orElseGet(() -&gt; "summer")); //orElseThrow // 这段代码会抛出异常，为了下面能运行，先注释。 /*try &#123; System.out.printf("orElseThrow有值的Optional: %s，没值的Optional：%s%n", spring.orElseThrow(OptionalThrowable::new), nullValue.orElseThrow(OptionalThrowable::new)); &#125; catch (OptionalThrowable optionalThrowable) &#123; optionalThrowable.printStackTrace(); &#125;*/ //map Optional&lt;String&gt; castedOptional = spring.map(String::toLowerCase); System.out.printf("转换成小写的值：%s%n", castedOptional.orElseGet(null)); //flatMap Optional&lt;String&gt; upperOptional = castedOptional.flatMap(a -&gt; Optional.of(a.toUpperCase())); System.out.printf("将上面小写的castedOptional 转换成大写：%s%n", upperOptional.orElseGet(null)); //filter //过滤掉长度不大于10的，SPRING长度小于10，故此被过滤了 Optional&lt;String&gt; filterOptional = upperOptional.filter(a -&gt; a.length() &gt; 10); System.out.printf("过滤掉长度不大于10的结果 ：%s%n", filterOptional.orElse("Default value")); &#125;&#125;/** * 自定义的Optional异常类 */class OptionalThrowable extends Throwable &#123; public OptionalThrowable() &#123; &#125; public OptionalThrowable(String message) &#123; super(message); &#125; @Override public String getMessage() &#123; //return super.getMessage(); return "这个Optional 是空值"; &#125;&#125;]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[歌词-《清白之年》]]></title>
    <url>%2Finnocence-year.html</url>
    <content type="text"><![CDATA[热爱美丽又遗憾的世界，愿你出走半生，归来仍是少年。一直有人，再让我幻想。。 清白之年词 : 朴树 故事开始以前 最初的那些春天阳光洒在杨树上 风吹来 闪银光 街道平静而温暖钟走得好慢 那是我还不识人生之味的年代 我情窦还不开 你的衬衣如雪 盼着杨树叶落下 眼睛不眨 心里像有一些话我们先不讲 等待着那将要盛装出场的未来 人随风飘荡 天各自一方 在风尘中遗忘的清白脸庞 此生多勉强 此身越重洋 轻描时光漫长低唱语焉不详 数不清的流年 似是而非的脸把你的故事对我讲就让我笑出泪光是不是生活太艰难还是活色生香 我们都遍体鳞伤 也慢慢坏了心肠 你得到你想要的吗换来的是铁石心肠 可曾还有什么人再让你幻想 大风吹来了我们随风飘荡 在风尘中遗忘的清白脸庞 此生多寒凉 此身越重洋 轻描时光漫长低唱语焉不详 大风吹来了我们随风飘荡 在风尘中熄灭的清澈目光 我想回头望 把故事从头讲时光迟暮不返人生已不再来]]></content>
      <categories>
        <category>那些很美的句子</category>
      </categories>
      <tags>
        <tag>歌词</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20171111]]></title>
    <url>%2F20171111.html</url>
    <content type="text"><![CDATA[想到凌晨，双十一，还是忍不住买买买，很舒心，最好的就是这个时候能给父母多买点东西，平时说缺什么他们都不让，这个时候多买点，还买了一个电饭煲，还不错。 看到5系列博朗剃须刀，好想买呀，对于我这种毛发密集型的，每天都要剃须刀；说说而已，但是还是好贵，以后再说。 半夜久久不能入睡，我想我是刚刚聊天失眠了，等消息，还不如看个电影，又翻出以前很爱看的《猫的感恩》，深夜3点才能睡着。。 早上一起来快9点啦，，经理还发消息问什么时候才能过来，尬。当然迟到了，他们已经在开会了，。 一上午就没心思听进去了，犹豫了半天才评论了一个说说，我这个人就是这样的，一点东西也算是个惊喜吧。 下午一个人去磨山骑车玩玩，东湖的风景还是很好的。为什么出去还这么累啊，我看是今天黄道吉日不好吧，双十一，单身狗不宜出门。 晚上回来随便写点，洗洗睡吧，生活大抵就是这么无聊咯，我的青春，呼喊了也没回应，只能自己努力创造了。加油。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[成长]]></title>
    <url>%2Fgrow-up.html</url>
    <content type="text"><![CDATA[多想多说话，也只有我知道，是因为我害怕，我怕别人听出来，过得不好，我怕问我过得怎么样的时候，可能会你难过，我怕撑不住告诉了别人。 我知道，一个男人应该更坚强一点，所以我从来不跟别人说那些丧气，而又愤怒的话，从来不跟别人说我过得怎么样，谁问我，都能轻描淡写，一笔带过。挺好的，真的什么都挺好的。 现在虽然离梦想还有一大截，薪水也很普通，但也还能存下一笔钱，感觉有了能撑起一个家的责任和感觉了，从心底上就有了一份骄傲。 室友的关心，也会让人心里暖暖的，也还有人能说话，生活有时候不如意，但是为之奋斗的梦想还没有扔下，还知道为什么要这么做，想要的是什么，虽然现在有时候真的很难熬，但是我知道的，总会好的，不会太远；曾经遇到的事，吃过的苦，总有一天，会赶在父母老去之前，给他们更好的生活；总有一天也会遇到一个人，那一天我真的有能力能给她安稳，照顾她一辈子了。 有时候憧憬下未来，想想现在，其实也没什么大不了的，人生充满荆棘，等待去跨过，才能有理想，才能成长；其实也没什么好惧怕的，我还有梦，有家，有爱的能力就够了；其实也不难熬，只是有些事情只能自己消化，不再赶和任何人一起罢了。 其实真的没什么大不了的，人总是要学会长大的，一个人撑起一个家，一个人抵过千军万马。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JPA多表查询的解决办法]]></title>
    <url>%2Fjpa-query-muti.html</url>
    <content type="text"><![CDATA[实际业务中，多表关联查询应用实例很多，怎么使用JPA进行多表查询，可以选择不同的方法优化。记下在JPA中多表查询的有效使用方法。 使用关系映射就是使用一对多，多对一，一对一这种关系进行关联映射， 一个一对多迭代Tree的例子：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import javax.persistence.*;import java.util.List;/** * 根据组织取得实时轨迹Tree的业务类 * @author Zhang Kai * @version 1.0 * @since &lt;pre&gt;2017/11/9 15:21&lt;/pre&gt; */@Entity@Table(name = "\"DEV_ORGANIZE\"")public class OrganizeMappedEntity extends BaseEntity &#123; // 名称，为了前面取出数据的key一致性，换个名称。 @Column(name = "\"NAME\"") private String no; // 父组织外键 @Column(name = "\"PARENTID\"") private String parentid; @OneToMany(targetEntity = OrganizeMappedEntity.class, mappedBy = "parentid", cascade = &#123;CascadeType.ALL&#125;, fetch = FetchType.EAGER) private List children; public String getNo() &#123; return no; &#125; public void setNo(String no) &#123; this.no = no; &#125; public String getParentid() &#123; return parentid; &#125; public void setParentid(String parentid) &#123; this.parentid = parentid; &#125; public List getChildren() &#123; return children; &#125; public void setChildren(List children) &#123; this.children = children; &#125;&#125; 平常使用这种方法最多了，因为方便，少写代码，但是平时不一定需要查询所有，而且在数据比较多的情况下，开销比较大，就得使用下面第二种方法。 使用JPQL多表查询JPQL全称Java Presistence Query Language，Java持久化查询语言。和Hibernate的HQL语句差不多。 现在测试下，从A表和B表各取出一个字段吧。创建一个业务实体DTO：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import java.io.Serializable;//学习学习public class TestEntity implements Serializable&#123; /** * */ private static final long serialVersionUID = 1L; //A表字段No private String no; //B表字段tel private String tel; private Long num; public TestEntity(Long num) &#123; this.num = num; &#125; public Long getNum() &#123; return num; &#125; public void setNum(Long num) &#123; this.num = num; &#125; //通过构造函数注入值 public TestEntity (String no, String tel) &#123; this.no = no; this.tel = tel; &#125; public static long getSerialversionuid() &#123; return serialVersionUID; &#125; public String getNo() &#123; return no; &#125; public void setNo(String no) &#123; this.no = no; &#125; public String getTel() &#123; return tel; &#125; public void setTel(String tel) &#123; this.tel = tel; &#125; //重写写， @Override public String toString() &#123; return "TestEntity&#123;" + "no='" + no + '\'' + ", tel='" + tel + '\'' + ", num=" + num + '&#125;'; &#125;&#125; 这样可以使用业务实体类的构造函数就行绑定数据了。 Dao层查询数据库的JPQL语句：12345678910111213141516171819import com.devframe.database.BasePagingAndSortingRepository;import com.devframe.entity.DeviceEntity;import com.devframe.entity.TestEntity;import org.springframework.data.jpa.repository.Query;import org.springframework.stereotype.Repository;import java.util.List;@Repositorypublic interface DeviceDao extends PagingAndSortingRepository&lt;DeviceEntity, String&gt; &#123; /** * 只为学习。。。 * @return List&lt;TestEntity&gt; */ @Query(value = "SELECT new com.devframe.entity.TestEntity(a.no, b.tel) FROM com.devframe.entity.DeviceEntity a, com.devframe.entity.OrganizeEntity b WHERE a.orgid = b.id") List&lt;TestEntity&gt; gettest();&#125; 使用join查询出两个表相关联的所有列。 单元测试：12345678910111213141516171819202122232425import com.devframe.dao.DeviceDao;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;import javax.annotation.Resource;/** * @author Zhang Kai * @version 1.0 * @since &lt;pre&gt;2017/11/9 17:40&lt;/pre&gt; */@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &#123;"classpath:spring/applicationContext-base.xml"&#125;)public class DeviceDaoTest &#123; @Resource private DeviceDao dao; @Test public void testGettest() &#123; System.out.println(dao.gettest()); &#125;&#125; 数据有点多1TestEntity&#123;no=&apos;N57008&apos;, tel=&apos;null&apos;, num=null&#125;, TestEntity&#123;no=&apos;N33505&apos;, tel=&apos;null&apos;, num=null&#125;, TestEntity&#123;no=&apos;N88001&apos;, tel=&apos;null&apos;, num=null&#125;,省略...]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jpa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20171107]]></title>
    <url>%2F20171107.html</url>
    <content type="text"><![CDATA[今天乱的一匹，也没怎么学习，日记也没写，故事也没写。 什么都别想，管这个世界明天会怎样，卸下今天的一切，在艰难的时光里，将人生变得美好而辽阔。 最近任务有点杂乱，效率低下。回想起最近，学的东西太杂乱了 回想起最近这么几个月，学的东西太杂乱了，分布式存储，分布式缓存，hadoop，python等等，没一个弄清楚明白的，剩下的时间里，先把python放下，把Java中这么几个重要的东西仔细研究一下，只要掌握一门，以后工作就好了。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017年，仅剩60天不到了]]></title>
    <url>%2F2017left.html</url>
    <content type="text"><![CDATA[猛然发现，2017，转眼就要过完了，我这个人从来不喜欢记什么节日，自己的生日有时候都要老爸老妈操心的，我也不太喜欢倒计时，最特别的就是高考倒计时吧。当人从出生的那一刻起，就过上了讨厌的倒计时的生活。 感觉今年过得很没意思，怎么说了。年初，就去实习公司上班，不为别的只为那个开门红，红包。开始工作的时候，大都是热情满满，感觉怎么样怎么样的好，可是期望满满，后来失望就慢慢多了，感觉工作并没有那么顺心，领导开始只注意项目了，不关心员工死活了，渐渐的我就是失去的热情。有点颓废。 也是刚好，项目的事情没那么多，可以好好写下论文了，大概三月中旬我就开始着手自己毕业设计，直接想了一个以前准备做的OA系统，其实这个还是挺难的，因为最后做得有点失败，后面说。整整四月份都在做这个项目，中间遇到过很多问题，大多数都解决了（有的敷衍了），也有一万行代码了吧（虽然质量很差），没仔细统计过，就是公司上班没什么事，一天到晚写毕业设计一个月，直到五月初才开始写论文。然后就是毕业设计熬过去。然后就是答辩了，so easy，毕竟全篇都是自己完成的，只不过我是小组最后一个答辩，弄完都快晚上八点了。 六月份到公司重新报道吧，没什么可说的，开始接到一个很坑的项目，直接导致我想离开的原因。 七月份就是做那个苦逼的项目，室友封闭一个月，我一个人生活了一个多月，感觉习惯了孤独。 还有一件事情就是，也是我想直接留在武汉的原因吧，说多都是套路，自私点，好点发展。 八月份中旬，经经理推荐，来到了新的公司，虽然是做农业的，不是真正的互联网公司，但是在武汉待遇还很好，经理待人也不错，就是很少加班，但是IT行业不学习的话，感觉人就要倒退了，所以呀，每天至少得在公司蹭一个小时的网，来学习学习。部门的员工很和谐，感觉很轻松，让我工作动力十足，相信可以成长很快的。 在新公司已经两个月了，学习了不少，这个博客笔记也是进入到这个公司才开始正式写的，希望能够陪伴着我进步。 最后的梦想就是，当然是快点成为技术大牛，拿高薪。工作方向的话，主Java开发，物联网，互联网，再就是大数据，补算法，python，人工智能。说起以后工作的城市，人生路还长，现在才刚开始，自己努力了，总有个地方能给你安稳的地方。说起工作城市，还不是面向工资，主要是武汉工资确实太低了，但真的很喜欢武汉的这个城市。不知道明年继续在武汉，有机会税前过万吗？ 说起以后的希望实现财富自由的期望工资，标准是超一线年薪30万起吧，一线20万吧，才算合格。当然是以目前的背景基础看的，程序猿的工资只会越来越高的，要坚持努力工作，学习，加油，希望三年能完成一个阶段吧。 当然最希望能遇到一个对的人，我有好多故事要跟你讲啊，想去好多地方，虽然害怕自己习惯了孤独，只要是对的人，还是等得起，不是不想去喜欢一个人，害怕自己再也付出不了真心，真的是好犹豫啊，人真是病态的厉害。 今年总结这么快就开始写了，其实没什么，好多牢骚，完全扭曲了人生观，就这样，加油，努力，现在每天只好自己对自己说声晚安了，我相信这种状况不会太久，希望不会太远，真的好累。 有点矫情了。。。 晚安！ 20171125 感觉还剩一个月的时候，人完成沉静不下来了，哎，一晚上写了一篇博客，写到凌晨最后不知道写的什么。(continue:]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[做个温柔的人]]></title>
    <url>%2Ftobe-gentle.html</url>
    <content type="text"><![CDATA[要有在迷茫沮丧的时期，不对自己下结论的能力；在苦楚绝望的时期，不对世界下结论的操守。你要相信，一切都是暂时的，我们唯一需要做的，就是静静地好给世界看。 最近感觉生活过的一团糟，书看不下去，博客也写不下去，我想我是个脾气有点爆的人，感觉生活就是很失望一般。 你是那么会安慰人，非得逞强去安慰别人，是什么让人这样，真是不撞南墙不回头，把南墙装得头破血流，也回不了头，只能往前走。这段时间真想对曾经自己的说声对不起，自己真的是很难过， 你是那么会安慰人，生活就是这样，一边安慰着鄙人，一边悄悄自愈着，自己糟糕，安慰别人却头头是道。 你是那么会安慰人，可能是曾经期望太高，导致现在一点一点的失望，失望到，似乎看到那个结局。继续安慰别人，下去就是忍受孤独吧。 然后不知不觉中，顾虑似乎多了不少，身上的包袱就沉重了许多，有些事情，虽然基本已经跟自己无关，但是还不愿意卸下，会上去悉心照顾下她人的感受，可是安慰完这个世界后，感觉没人会安慰自己了，也没人能够懂得自己现在的感受。 可能你也不懂得如何安慰别人，习惯一个人在外面打拼久了，什么都是自己一个人，没事什么都可以撑得下，已经习惯用坚强来安慰自己。 可能你也不懂得如何安慰别人，还是努力把自己最好的一面留给别人，不要去祈求来的安慰，只会是同情，还不如自己吞下所有的难过。 世界上有种傻子，在最难过的时候，还在想着怎么安慰别人，虽然没有关系，也不用在意。 自己一直不知道，有多少人和我一般笨拙，安慰人的话没说几句就词穷了。 所以现在多了一种安慰方式：沉默。 现在知道了。我确实不会安慰人。 只求往后的日子里，希望自己能想明白事情，再去做吧，这样就不会出现这么多的问题，即辜负了别人，也辜负了自己。 往后的日子里做个温柔的人，无惧黑暗与严寒，只会把温暖带给世界，然后花点时间温暖自己，变得更加优秀。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java多线程中Lock]]></title>
    <url>%2Fjava-lock.html</url>
    <content type="text"><![CDATA[如果一个代码块被synchronized修饰了，当一个线程获取了对应的锁，并执行该代码块时，其他线程便只能一直等待，等待获取锁的线程释放锁，而这里获取锁的线程释放锁只会有两种情况： 获取锁的线程执行完了该代码块，然后线程释放对锁的占有； 线程执行发生异常，此时JVM会让线程自动释放锁。 那么如果这个获取锁的线程由于要等待IO或者其他原因（比如调用sleep方法）被阻塞了，但是又没有释放锁，其他线程便只能干巴巴地等待，试想一下，这多么影响程序执行效率。 因此就需要有一种机制可以不让等待的线程一直无期限地等待下去（比如只等待一定的时间或者能够响应中断），通过Lock就可以办到。 再举个例子：当有多个线程读写文件时，读操作和写操作会发生冲突现象，写操作和写操作会发生冲突现象，但是读操作和读操作不会发生冲突现象。 但是采用synchronized关键字来实现同步的话，就会导致一个问题： 如果多个线程都只是进行读操作，所以当一个线程在进行读操作时，其他线程只能等待无法进行读操作。 因此就需要一种机制来使得多个线程都只是进行读操作时，线程之间不会发生冲突，通过Lock就可以办到。 另外，通过Lock可以知道线程有没有成功获取到锁。这个是synchronized无法办到的。 总结一下，也就是说Lock提供了比synchronized更多的功能。但是要注意以下几点： Lock不是Java语言内置的，synchronized是Java语言的关键字，因此是内置特性。Lock是一个类，通过这个类可以实现同步访问； Lock和synchronized有一点非常大的不同，采用synchronized不需要用户去手动释放锁，当synchronized方法或者synchronized代码块执行完之后，系统会自动让线程释放对锁的占用；而Lock则必须要用户去手动释放锁，如果没有主动释放锁，就有可能导致出现死锁现象。 java.util.concurrent.locks包下常用的类java.util.concurrent.locks包中常用的类和接口。 Lock接口123456789@since 1.5public interface Lock &#123; void lock(); void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition();&#125; 下面来逐个讲述Lock接口中每个方法的使用，lock()、tryLock()、tryLock(long time, TimeUnit unit)和lockInterruptibly()是用来获取锁的。unLock()方法是用来释放锁的。newCondition()这个方法暂且不在此讲述，会在后面的线程协作一文中讲述。 在Lock中声明了四个方法来获取锁，那么这四个方法有何区别呢？ lock 首先lock()方法是平常使用得最多的一个方法，就是用来获取锁。如果锁已被其他线程获取，则进行等待。 由于在前面讲到如果采用Lock，必须主动去释放锁，并且在发生异常时，不会自动释放锁。因此一般来说，使用Lock必须在try{}catch{}块中进行，并且将释放锁的操作放在finally块中进行，以保证锁一定被被释放，防止死锁的发生。通常使用Lock来进行同步的话，是以下面这种形式去使用的：123456789Lock lock = ...;lock.lock();try&#123; //处理任务&#125;catch(Exception ex)&#123; &#125;finally&#123; lock.unlock(); //释放锁&#125; tryLocktryLock()方法是有返回值的，它表示用来尝试获取锁，如果获取成功，则返回true，如果获取失败（即锁已被其他线程获取），则返回false，也就说这个方法无论如何都会立即返回。在拿不到锁时不会一直在那等待。 tryLock(long time, TimeUnit unit)方法和tryLock()方法是类似的，只不过区别在于这个方法在拿不到锁时会等待一定的时间，在时间期限之内如果还拿不到锁，就返回false。如果如果一开始拿到锁或者在等待期间内拿到了锁，则返回true。 所以，一般情况下通过tryLock来获取锁时是这样使用的：123456789101112Lock lock = ...;if(lock.tryLock()) &#123; try&#123; //处理任务 &#125;catch(Exception ex)&#123; &#125;finally&#123; lock.unlock(); //释放锁 &#125; &#125;else &#123; //如果不能获取锁，则直接做其他事情&#125; lockInterruptiblylockInterruptibly()方法比较特殊，当通过这个方法去获取锁时，如果线程正在等待获取锁，则这个线程能够响应中断，即中断线程的等待状态。也就使说，当两个线程同时通过lock.lockInterruptibly()想获取某个锁时，假若此时线程A获取到了锁，而线程B只有在等待，那么对线程B调用threadB.interrupt()方法能够中断线程B的等待过程。 由于lockInterruptibly()的声明中抛出了异常，所以lock.lockInterruptibly()必须放在try块中或者在调用lockInterruptibly()的方法外声明抛出InterruptedException。 因此lockInterruptibly()一般的使用形式如下：123456789public void method() throws InterruptedException &#123; lock.lockInterruptibly(); try &#123; //..... &#125; finally &#123; lock.unlock(); &#125; &#125; ReentrantLock类ReentrantLock，意思是“可重入锁”。ReentrantLock是唯一实现了Lock接口的类，并且ReentrantLock提供了更多的方法。下面通过一些实例看具体看一下如何使用ReentrantLock。 例子1，lock()的正确使用方法:12345678910111213141516171819202122232425262728293031323334public class Test &#123; private ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;(); public static void main(String[] args) &#123; final Test test = new Test(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); &#125; public void insert(Thread thread) &#123; Lock lock = new ReentrantLock(); //注意这个地方 lock.lock(); try &#123; System.out.println(thread.getName()+"得到了锁"); for(int i=0;i&lt;5;i++) &#123; arrayList.add(i); &#125; &#125; catch (Exception e) &#123; // TODO: handle exception &#125;finally &#123; System.out.println(thread.getName()+"释放了锁"); lock.unlock(); &#125; &#125;&#125; 输出结果是什么:1234Thread-0得到了锁Thread-1得到了锁Thread-0释放了锁Thread-1释放了锁 也许有朋友会问，怎么会输出这个结果？第二个线程怎么会在第一个线程释放锁之前得到了锁？原因在于，在insert方法中的lock变量是局部变量，每个线程执行该方法时都会保存一个副本，那么理所当然每个线程执行到lock.lock()处获取的是不同的锁，所以就不会发生冲突。 知道了原因改起来就比较容易了，只需要将lock声明为类的属性即可。12345678910111213141516171819202122232425262728293031323334public class Test &#123; private ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;(); private Lock lock = new ReentrantLock(); //注意这个地方 public static void main(String[] args) &#123; final Test test = new Test(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); &#125; public void insert(Thread thread) &#123; lock.lock(); try &#123; System.out.println(thread.getName()+"得到了锁"); for(int i=0;i&lt;5;i++) &#123; arrayList.add(i); &#125; &#125; catch (Exception e) &#123; // TODO: handle exception &#125;finally &#123; System.out.println(thread.getName()+"释放了锁"); lock.unlock(); &#125; &#125;&#125; 例子2，tryLock()的使用方法12345678910111213141516171819202122232425262728293031323334353637public class Test &#123; private ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;(); private Lock lock = new ReentrantLock(); //注意这个地方 public static void main(String[] args) &#123; final Test test = new Test(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; test.insert(Thread.currentThread()); &#125;; &#125;.start(); &#125; public void insert(Thread thread) &#123; if(lock.tryLock()) &#123; try &#123; System.out.println(thread.getName()+"得到了锁"); for(int i=0;i&lt;5;i++) &#123; arrayList.add(i); &#125; &#125; catch (Exception e) &#123; // TODO: handle exception &#125;finally &#123; System.out.println(thread.getName()+"释放了锁"); lock.unlock(); &#125; &#125; else &#123; System.out.println(thread.getName()+"获取锁失败"); &#125; &#125;&#125; 输出结果：123Thread-0得到了锁Thread-1获取锁失败Thread-0释放了锁 例子3，lockInterruptibly()响应中断的使用方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class Test &#123; private Lock lock = new ReentrantLock(); public static void main(String[] args) &#123; Test test = new Test(); MyThread thread1 = new MyThread(test); MyThread thread2 = new MyThread(test); thread1.start(); thread2.start(); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; thread2.interrupt(); &#125; public void insert(Thread thread) throws InterruptedException&#123; lock.lockInterruptibly(); //注意，如果需要正确中断等待锁的线程，必须将获取锁放在外面，然后将InterruptedException抛出 try &#123; System.out.println(thread.getName()+"得到了锁"); long startTime = System.currentTimeMillis(); for( ; ;) &#123; if(System.currentTimeMillis() - startTime &gt;= Integer.MAX_VALUE) break; //插入数据 &#125; &#125; finally &#123; System.out.println(Thread.currentThread().getName()+"执行finally"); lock.unlock(); System.out.println(thread.getName()+"释放了锁"); &#125; &#125;&#125; class MyThread extends Thread &#123; private Test test = null; public MyThread(Test test) &#123; this.test = test; &#125; @Override public void run() &#123; try &#123; test.insert(Thread.currentThread()); &#125; catch (InterruptedException e) &#123; System.out.println(Thread.currentThread().getName()+"被中断"); &#125; &#125;&#125; 运行之后，发现thread2能够被正确中断。 ReadWriteLockReadWriteLock也是一个接口，在它里面只定义了两个方法：123456789101112131415public interface ReadWriteLock &#123; /** * Returns the lock used for reading. * * @return the lock used for reading. */ Lock readLock(); /** * Returns the lock used for writing. * * @return the lock used for writing. */ Lock writeLock();&#125; 一个用来获取读锁，一个用来获取写锁。也就是说将文件的读写操作分开，分成2个锁来分配给线程，从而使得多个线程可以同时进行读操作。下面的ReentrantReadWriteLock实现了ReadWriteLock接口。 ReentrantReadWriteLockReentrantReadWriteLock里面提供了很多丰富的方法，不过最主要的有两个方法：readLock()和writeLock()用来获取读锁和写锁。 下面通过几个例子来看一下ReentrantReadWriteLock具体用法。 假如有多个线程要同时进行读操作的话，先看一下synchronized达到的效果： synchronized12345678910111213141516171819202122232425262728public class Test &#123; private ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); public static void main(String[] args) &#123; final Test test = new Test(); new Thread()&#123; public void run() &#123; test.get(Thread.currentThread()); &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; test.get(Thread.currentThread()); &#125;; &#125;.start(); &#125; public synchronized void get(Thread thread) &#123; long start = System.currentTimeMillis(); while(System.currentTimeMillis() - start &lt;= 1) &#123; System.out.println(thread.getName()+"正在进行读操作"); &#125; System.out.println(thread.getName()+"读操作完毕"); &#125;&#125; 这段程序的输出结果会是，直到thread1执行完读操作之后，才会打印thread2执行读操作的信息。 改成用读写锁12345678910111213141516171819202122232425262728293031323334public class Test &#123; private ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); public static void main(String[] args) &#123; final Test test = new Test(); new Thread()&#123; public void run() &#123; test.get(Thread.currentThread()); &#125;; &#125;.start(); new Thread()&#123; public void run() &#123; test.get(Thread.currentThread()); &#125;; &#125;.start(); &#125; public void get(Thread thread) &#123; rwl.readLock().lock(); try &#123; long start = System.currentTimeMillis(); while(System.currentTimeMillis() - start &lt;= 1) &#123; System.out.println(thread.getName()+"正在进行读操作"); &#125; System.out.println(thread.getName()+"读操作完毕"); &#125; finally &#123; rwl.readLock().unlock(); &#125; &#125;&#125; 结果：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849Thread-0正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0正在进行读操作Thread-1正在进行读操作Thread-0读操作完毕Thread-1读操作完毕 说明thread1和thread2在同时进行读操作。 这样就大大提升了读操作的效率。 不过要注意的是，如果有一个线程已经占用了读锁，则此时其他线程如果要申请写锁，则申请写锁的线程会一直等待释放读锁。 如果有一个线程已经占用了写锁，则此时其他线程如果申请写锁或者读锁，则申请的线程会一直等待释放写锁。 关于ReentrantReadWriteLock类中的其他方法感兴趣的朋友可以自行查阅API文档。 Lock和synchronized的选择总结来说，Lock和synchronized有以下几点不同： 1）Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现； 2）synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁； 3）Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断； 4）通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。 5）Lock可以提高多个线程进行读操作的效率。 在性能上来说，如果竞争资源不激烈，两者的性能是差不多的，而当竞争资源非常激烈时（即有大量线程同时竞争），此时Lock的性能要远远优于synchronized。所以说，在具体使用时要根据适当情况选择。 锁的相关概念介绍可重入锁如果锁具备可重入性，则称作为可重入锁。像synchronized和ReentrantLock都是可重入锁，可重入性在我看来实际上表明了锁的分配机制：基于线程的分配，而不是基于方法调用的分配。举个简单的例子，当一个线程执行到某个synchronized方法时，比如说method1，而在method1中会调用另外一个synchronized方法method2，此时线程不必重新去申请锁，而是可以直接执行方法method2。 看下面这段代码就明白了：123456789class MyClass &#123; public synchronized void method1() &#123; method2(); &#125; public synchronized void method2() &#123; &#125;&#125; 上述代码中的两个方法method1和method2都用synchronized修饰了，假如某一时刻，线程A执行到了method1，此时线程A获取了这个对象的锁，而由于method2也是synchronized方法，假如synchronized不具备可重入性，此时线程A需要重新申请锁。但是这就会造成一个问题，因为线程A已经持有了该对象的锁，而又在申请获取该对象的锁，这样就会线程A一直等待永远不会获取到的锁。 而由于synchronized和Lock都具备可重入性，所以不会发生上述现象。 可中断锁可中断锁：顾名思义，就是可以相应中断的锁。 在Java中，synchronized就不是可中断锁，而Lock是可中断锁。 如果某一线程A正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程B不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，这种就是可中断锁。 在前面演示lockInterruptibly()的用法时已经体现了Lock的可中断性。 公平锁公平锁即尽量以请求锁的顺序来获取锁。比如同是有多个线程在等待一个锁，当这个锁被释放时，等待时间最久的线程（最先请求的线程）会获得该所，这种就是公平锁。 非公平锁即无法保证锁的获取是按照请求锁的顺序进行的。这样就可能导致某个或者一些线程永远获取不到锁。 在Java中，synchronized就是非公平锁，它无法保证等待的线程获取锁的顺序。 而对于ReentrantLock和ReentrantReadWriteLock，它默认情况下是非公平锁，但是可以设置为公平锁。 看一下这2个类的源代码就清楚了： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * Sync object for non-fair locks */static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; /** * Performs lock. Try immediate barge, backing up to normal * acquire on failure. */ final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125;/** * Sync object for fair locks */static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; acquire(1); &#125; /** * Fair version of tryAcquire. Don't grant access unless * recursive call or no waiters or is first. */ protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; &#125;&#125; 在ReentrantLock中定义了2个静态内部类，一个是NotFairSync，一个是FairSync，分别用来实现非公平锁和公平锁。 我们可以在创建ReentrantLock对象时，通过以下方式来设置锁的公平性：1ReentrantLock lock = new ReentrantLock(true); 如果参数为true表示为公平锁，为fasle为非公平锁。默认情况下，如果使用无参构造器，则是非公平锁。 1234567891011121314151617/** * Creates an instance of &#123;@code ReentrantLock&#125;. * This is equivalent to using &#123;@code ReentrantLock(false)&#125;. */public ReentrantLock() &#123; sync = new NonfairSync();&#125;/** * Creates an instance of &#123;@code ReentrantLock&#125; with the * given fairness policy. * * @param fair &#123;@code true&#125; if this lock should use a fair ordering policy */public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 另外在ReentrantLock类中定义了很多方法，比如：12345678 isFair() //判断锁是否是公平锁 isLocked() //判断锁是否被任何线程获取了 isHeldByCurrentThread() //判断锁是否被当前线程获取了 hasQueuedThreads() //判断是否有线程在等待该锁 在ReentrantReadWriteLock中也有类似的方法，同样也可以设置为公平锁和非公平锁。不过要记住，ReentrantReadWriteLock并未实现Lock接口，它实现的是ReadWriteLock接口。 读写锁读写锁将对一个资源（比如文件）的访问分成了2个锁，一个读锁和一个写锁。 正因为有了读写锁，才使得多个线程之间的读操作不会发生冲突。 ReadWriteLock就是读写锁，它是一个接口，ReentrantReadWriteLock实现了这个接口。 可以通过readLock()获取读锁，通过writeLock()获取写锁。 上面已经演示过了读写锁的使用方法，在此不再赘述。 文章转载：海子]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java多线程中synchronized]]></title>
    <url>%2Fjava-synchronized.html</url>
    <content type="text"><![CDATA[在多线程中，当多个线程同时访问同一个资源对象的时候，由于线程在处理中是不可控的，导致，执行的结果可能出现不可控的错误。 例如：两个线程thread-1和thread-2，同时要数据入库，需要判断数据字段a，不重复，所以当插入数据的时候先去检查数据库中a字段，当我们的两个线程中字段a相同的时候，出现thread1先执行查询，在thread2查询，两个线程同时都会得到a字段没重复，这个时候，数据入库，肯定会有问题的。 有线程安全的问题，这个资源叫做临界资源。 当多个线程同时访问临界资源（一个对象，对象中的属性，一个文件，一个数据库等）时，就可能会产生线程安全问题。 解决办法有两个，一个是让线程同步synchronized， 一个是lock。 synchronized关键字使用 synchronized关键字来修饰一个方法和方法块，当线程访问这个对象的synchronized修饰的方法的时候，会锁住这个方法，其他线程无法访问，等待这个线程执行完毕，其他线程才排队进来依次执行，12345678910111213141516171819202122232425262728293031323334353637383940414243package com.wuwii.test.thread;/** * @author Zhang Kai * @version 1.0 * @since &lt;pre&gt;2017/11/5 9:39&lt;/pre&gt; */public class TestThread &#123; public static void main(String[] args) &#123; ThreadData threadData = new ThreadData(); ThreadData threadData1 = new ThreadData(); new Thread(() -&gt; threadData.data1()).start(); new Thread(() -&gt; ThreadData.data2()).start(); new Thread(() -&gt; threadData.data3()).start(); new Thread(() -&gt; threadData1.data1()).start(); &#125;&#125;class ThreadData &#123; public synchronized void data1() &#123; System.out.println("begin data1"); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("end data1"); &#125; public synchronized static void data2() &#123; System.out.println("data2"); &#125; public synchronized void data3() &#123; System.out.println("begin data3"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("end data3"); &#125;&#125; 打印结果1234567begin data1data2begin data1end data1begin data3end data1end data3 总结 当一个线程正在访问一个对象的synchronized方法，那么其他线程不能访问该对象的其他synchronized方法。 如果一个线程A需要访问对象object1的synchronized方法fun1，另外一个线程B需要访问对象object2的synchronized方法fun1，即使object1和object2是同一类型），也不会产生线程安全问题，因为他们访问的是不同的对象，所以不存在互斥问题。 如果一个线程执行一个对象的非static synchronized方法，另外一个线程需要执行这个对象所属类的static synchronized方法，此时不会发生互斥现象，因为访问static synchronized方法占用的是类锁，而访问非static synchronized方法占用的是对象锁，所以不存在互斥现象。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[他人的面试经历文章]]></title>
    <url>%2Fothers-hk.html</url>
    <content type="text"><![CDATA[自己的面试经历比较少，积累下别人的面试经验，了解自己不足，加油。 开一篇文章，记录，有空就去看看。 简单而不普通的，很有感觉 经验之谈]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 8 中ArrayList源码分析]]></title>
    <url>%2Fjava-arraylist.html</url>
    <content type="text"><![CDATA[这次简单看下ArrayList的实现过程，以及它拥有的操作方法。在Java 8 中 ArrayList 的实现 较以前有很大的改变。 ArrayList 拥有的属性1234567891011121314151617181920212223242526272829303132333435363738public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123; private static final long serialVersionUID = 8683452581122892189L; /** * Default initial capacity. */ private static final int DEFAULT_CAPACITY = 10; /** * Shared empty array instance used for empty instances. */ //被用于空实例的共享空数组实例 private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; /** * Shared empty array instance used for default sized empty instances. We * distinguish this from EMPTY_ELEMENTDATA to know how much to inflate when * first element is added. */ //被用于默认大小的空实例的共享数组实例。其与EMPTY_ELEMENTDATA的区别是：当我们向数组中添加第一个元素时，知道数组该扩充多少。 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; /** * The array buffer into which the elements of the ArrayList are stored. * The capacity of the ArrayList is the length of this array buffer. Any * empty ArrayList with elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA * will be expanded to DEFAULT_CAPACITY when the first element is added. */ transient Object[] elementData; // non-private to simplify nested class access /** * The size of the ArrayList (the number of elements it contains). * * @serial */ private int size; 实现的接口看出，支持随机访问，克隆，序列化； 默认大小DEFAULT_CAPACITY 为 10 ； elementData存储数组数据的，是 Object[] 类型的数组； size 为当前 ArrayList 的实际大小。构造函数ArrayList 通过构造方法创建有三种方法：1234567891011121314151617181920212223242526272829303132333435363738/** * 构造一个指定初始容量的空列表 * @param initialCapacity ArrayList的初始容量 * @throws IllegalArgumentException 如果给定的初始容量为负值 */ public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125; &#125; // 构造一个默认初始容量为10的空列表，但是还没分配大小。 public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; /** * 构造一个包含指定collection的元素的列表，这些元素按照该collection的迭代器返回的顺序排列的 * @param c 包含用于去构造ArrayList的元素的collection * @throws NullPointerException 如果指定的collection为空 */ public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray()可能不会正确地返回一个 Object[]数组，那么使用Arrays.copyOf()方法 if (elementData.getClass() != Object[].class) //Arrays.copyOf()返回一个 Object[].class类型的，大小为size，元素为elementData[0,...,size-1] elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; 添加元素add最简单的添加方法，在 ArrayList 尾部添加一个元素，需要去扩容，这个是ArrayList 最重要的一个特点；12345public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125; 扩容下面是扩容的重要代码：12345678910111213141516171819202122232425262728293031protected transient int modCount = 0;private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity);&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125; 每当向数组中添加元素时，都要去检查添加元素后的个数是否会超出当前数组的长度，如果超出，数组将会进行扩容，都回去调用方法ensureCapacityInternal(int minCapacity)在这个方法中看到，那个if语句判断就是，我们使用默认无参的构造函数创建的ArrayList 是在这里去 给大小的，如果第一次 add 的元素长度大于默认长度的话，就是用新的长度，否则给默认大小10； 给定大小后，就去调用grow方法，进行扩容。看到int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); ArrayList 每次扩容的大小是当前容量的0.5倍，就是默认大小为10，下次扩容后大小为15，下次再扩容后为 15 1.5*；所以ArrayList每次扩容的容量只会越来越大。 modCount用于记录ArrayList的结构性变化的次数，add()、remove()、addall()、removerange()及clear()方法都会让modCount增长。 其余的add方法，addAll12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//将指定的元素(E e)添加到此列表的尾部 public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; &#125; //将指定的元素(E e)插入到列表的指定位置(index) public void add(int index, E element) &#123; rangeCheckForAdd(index); //判断参数index是否IndexOutOfBoundsException ensureCapacityInternal(size + 1); // Increments modCount!! 如果数组长度不足，将进行扩容 System.arraycopy(elementData, index, elementData, index + 1, size - index); //将源数组中从index位置开始后的size-index个元素统一后移一位 elementData[index] = element; size++; //重新指定siez 大小 &#125; /** * 按照指定collection的迭代器所返回的元素顺序，将该collection中的所有元素添加到此列表的尾部 * @throws NullPointerException if the specified collection is null */ public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount //将数组a[0,...,numNew-1]复制到数组elementData[size,...,size+numNew-1] System.arraycopy(a, 0, elementData, size, numNew); size += numNew; //重新指定size 大小 return numNew != 0; &#125; /** * 从指定的位置开始，将指定collection中的所有元素插入到此列表中，新元素的顺序为指定collection的迭代器所返回的元素顺序 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; * @throws NullPointerException if the specified collection is null */ public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; rangeCheckForAdd(index); //判断参数index是否IndexOutOfBoundsException Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount int numMoved = size - index; if (numMoved &gt; 0) //先将数组elementData[index,...,index+numMoved-1]复制到elementData[index+numMoved,...,index+2*numMoved-1] //即，将源数组中从index位置开始的后numMoved个元素统一后移numNew位 System.arraycopy(elementData, index, elementData, index + numNew, numMoved); //再将数组a[0,...,numNew-1]复制到数组elementData[index,...,index+numNew-1] System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0; &#125; remove 删除元素123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118/** * 移除此列表中指定位置上的元素 * @param index 需被移除的元素的索引 * @return the element 被移除的元素值 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */ public E remove(int index) &#123; rangeCheck(index); //判断index是否 &lt;= size modCount++; E oldValue = elementData(index); //将数组elementData中index位置之后的所有元素向前移一位 int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; //将原数组最后一个位置置为null，由GC清理 return oldValue; &#125; //移除ArrayList中首次出现的指定元素(如果存在)，ArrayList中允许存放重复的元素 public boolean remove(Object o) &#123; // 由于ArrayList中允许存放null，因此下面通过两种情况来分别处理。 if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); //私有的移除方法，跳过index参数的边界检查以及不返回任何值 return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false; &#125; //私有的删除指定位置元素的方法，跳过index参数的边界检查以及不返回任何值 private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work &#125; //清空ArrayList，将全部的元素设为null public void clear() &#123; modCount++; // clear to let GC do its work for (int i = 0; i &lt; size; i++) elementData[i] = null; size = 0; &#125; //删除ArrayList中从fromIndex（包含）到toIndex（不包含）之间所有的元素，共移除了toIndex-fromIndex个元素 protected void removeRange(int fromIndex, int toIndex) &#123; modCount++; int numMoved = size - toIndex; //需向前移动的元素的个数 System.arraycopy(elementData, toIndex, elementData, fromIndex, numMoved); // clear to let GC do its work int newSize = size - (toIndex-fromIndex); for (int i = newSize; i &lt; size; i++) &#123; elementData[i] = null; &#125; size = newSize; &#125; //删除ArrayList中包含在指定容器c中的所有元素 public boolean removeAll(Collection&lt;?&gt; c) &#123; Objects.requireNonNull(c); //检查指定的对象c是否为空 return batchRemove(c, false); &#125; //移除ArrayList中不包含在指定容器c中的所有元素，与removeAll(Collection&lt;?&gt; c)正好相反 public boolean retainAll(Collection&lt;?&gt; c) &#123; Objects.requireNonNull(c); return batchRemove(c, true); &#125; //批量删除 //complement为true 表示不同的删除， private boolean batchRemove(Collection&lt;?&gt; c, boolean complement) &#123; final Object[] elementData = this.elementData; int r = 0, w = 0; //读写双指针 boolean modified = false; try &#123; for (; r &lt; size; r++) if (c.contains(elementData[r]) == complement) //判断指定容器c中是否含有elementData[r]元素 elementData[w++] = elementData[r]; &#125; finally &#123; // Preserve behavioral compatibility with AbstractCollection, // even if c.contains() throws. if (r != size) &#123; System.arraycopy(elementData, r, elementData, w, size - r); w += size - r; &#125; if (w != size) &#123; // clear to let GC do its work for (int i = w; i &lt; size; i++) elementData[i] = null; modCount += size - w; size = w; modified = true; &#125; &#125; return modified; &#125; 修改元素 set12345678//将指定索引上的值替换为新值，并返回旧值 public E set(int index, E element) &#123; rangeCheck(index); E oldValue = elementData(index); elementData[index] = element; return oldValue; &#125; 查询1234567891011121314151617181920212223242526272829303132333435363738394041424344//判断ArrayList中是否包含Object(o) public boolean contains(Object o) &#123; return indexOf(o) &gt;= 0; &#125; //正向查找，返回ArrayList中元素Object o第一次出现的位置，如果元素不存在，则返回-1 public int indexOf(Object o) &#123; if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; //逆向查找，返回ArrayList中元素Object o最后一次出现的位置，如果元素不存在，则返回-1 public int lastIndexOf(Object o) &#123; if (o == null) &#123; for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; @SuppressWarnings("unchecked") E elementData(int index) &#123; return (E) elementData[index]; &#125; //返回指定索引处的值 public E get(int index) &#123; rangeCheck(index); return elementData(index); //实质上return (E) elementData[index] &#125; 其他方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//将底层数组的容量调整为当前列表保存的实际元素的大小的功能 public void trimToSize() &#123; modCount++; if (size &lt; elementData.length) &#123; elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125; &#125; //返回ArrayList的大小（元素个数） public int size() &#123; return size; &#125; //判断ArrayList是否为空 public boolean isEmpty() &#123; return size == 0; &#125; //返回此 ArrayList实例的浅拷贝 public Object clone() &#123; try &#123; ArrayList&lt;?&gt; v = (ArrayList&lt;?&gt;) super.clone(); v.elementData = Arrays.copyOf(elementData, size); v.modCount = 0; return v; &#125; catch (CloneNotSupportedException e) &#123; // this shouldn't happen, since we are Cloneable throw new InternalError(e); &#125; &#125; //返回一个包含ArrayList中所有元素的数组 public Object[] toArray() &#123; return Arrays.copyOf(elementData, size); &#125; //如果给定的参数数组长度足够，则将ArrayList中所有元素按序存放于参数数组中，并返回 //如果给定的参数数组长度小于ArrayList的长度，则返回一个新分配的、长度等于ArrayList长度的、包含ArrayList中所有元素的新数组 @SuppressWarnings("unchecked") public &lt;T&gt; T[] toArray(T[] a) &#123; if (a.length &lt; size) // Make a new array of a's runtime type, but my contents: return (T[]) Arrays.copyOf(elementData, size, a.getClass()); System.arraycopy(elementData, 0, a, 0, size); if (a.length &gt; size) a[size] = null; return a; &#125; 遍历方法1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.wuwii.test;import java.util.*;/** * @author Zhang Kai * @version 1.0 * @since &lt;pre&gt;2017/11/4 16:53&lt;/pre&gt; */public class TestArrayList &#123; public static void main(String[] args) &#123; List&lt;String&gt; seasons = new ArrayList();// 创建默认大小ArrayList seasons.add("spring"); //第一次赋值，才有大小 seasons.addAll(Arrays.asList("summer", "autumn", "winter")); //使用迭代器 Iterator Iterator iterator = seasons.iterator(); while (iterator.hasNext()) &#123; System.out.println(iterator.next()); &#125; //使用迭代器 ListIterator System.out.println("使用迭代器 ListIterator"); ListIterator listIterator = seasons.listIterator(); while (listIterator.hasNext()) &#123; System.out.println(listIterator.next()); &#125; System.out.println("使用迭代器 ListIterator，逆向访问"); while (listIterator.hasPrevious()) &#123; System.out.println(listIterator.nextIndex() + " : " + listIterator.previous()); &#125; //通过索引 ，随机访问 System.out.println("通过索引 ，随机访问"); for (int i = 0, len = seasons.size(); i &lt; len; i++) System.out.println(seasons.get(i)); // 使用foreach 遍历 System.out.println("使用foreach 遍历"); for (String season : seasons) System.out.println(season); //第二种写法 //@since 1.8 //@see Iterable seasons.forEach(System.out::println); &#125;&#125; Iterator与ListIterator的区别： Iterator可以应用于所有的集合，Set、List和Map和这些集合的子类型。而ListIterator只能用于List及其子类型； Iterator只能实现顺序向后遍历，ListIterator可实现顺序向后遍历和逆向（顺序向前）遍历； Iterator只能实现remove操作，ListIterator可以实现remove操作，add操作，set操作。多线程中使用ArrayList当多个线程同时修改一个ArrayList对象的时候，必须要保持外部同步操作，但是ArrayList不是同步的，非线程安全，有一种办法就是可以使用Collections.synchronizedList进行包装：1List list = Collections.synchronizedList(new ArrayList(...)); 但是在平时开发中，多线程开发中多选择使用Vector或者CopyOnWriteArrayList。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用slf4j管理log4j中遇到的问题]]></title>
    <url>%2Fslf4j-manager.html</url>
    <content type="text"><![CDATA[项目中使用SLF4J管理LOG4J日志的，突然出现问题，不能打印日志了：123SLF4J: Failed to load class &quot;org.slf4j.impl.StaticLoggerBinder&quot;.SLF4J: Defaulting to no-operation (NOP) logger implementationSLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details. 意思就是无法加载org.slf4j.impl.StaticLoggerBinder 这么类。 但是这个类在哪里半天看不懂，点进它给出的链接中，开头发现这么一段话： This warning message is reported when the org.slf4j.impl.StaticLoggerBinder class could not be loaded into memory. This happens when no appropriate SLF4J binding could be found on the class path. Placing one (and only one) of slf4j-nop.jar slf4j-simple.jar, slf4j-log4j12.jar, slf4j-jdk14.jar or logback-classic.jar on the class path should solve the problem. 这个警告信息告诉我们，org.slf4j.impl.StaticLoggerBinder无法加载到内存中，当在类路径上找不到合适的SLF4J绑定时，就会出现这种情况。在他给出的几个jar 包中选择一个可以解决问题。 所以maven 中配置为:12345678910111213141516171819202122&lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt;&lt;slf4j.version&gt;1.7.21&lt;/slf4j.version&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.slf4j/slf4j-log4j12 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.slf4j/slf4j-nop --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-nop&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; 还发现一个东西，记录下，以后注意点： SLF4J versions 1.4.0 and later requires log4j 1.2.12 or laterThe trace level was added to log4j in version 1.2.12 released on August 29, 2005. The trace level was added to the SLF4J API in version 1.4.0 on May 16th, 2007. Thus, starting with SLF4J 1.4.0, the log4j binding for SLF4J requires log4j version 1.2.12 or above.]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>log4j</tag>
        <tag>slf4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring中使用Configuration注入Bean]]></title>
    <url>%2Fspring-config.html</url>
    <content type="text"><![CDATA[在Spring容器中使用applicationContext.xml中来给对应的类注入对应的属性，来完成初始化，最典型的就是配置数据库连接池了。 123456789101112131415161718192021222324252627282930&lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;!-- 基本属性 url、user、password --&gt; &lt;property name="url" value="$&#123;connection.url&#125;" /&gt; &lt;property name="username" value="$&#123;connection.username&#125;" /&gt; &lt;property name="password" value="$&#123;connection.password&#125;" /&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name="initialSize" value="$&#123;druid.initialSize&#125;" /&gt; &lt;property name="minIdle" value="$&#123;druid.minIdle&#125;" /&gt; &lt;property name="maxActive" value="$&#123;druid.maxActive&#125;" /&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name="maxWait" value="$&#123;druid.maxWait&#125;" /&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="$&#123;druid.timeBetweenEvictionRunsMillis&#125;" /&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name="minEvictableIdleTimeMillis" value="$&#123;druid.minEvictableIdleTimeMillis&#125;" /&gt; &lt;property name="removeAbandoned" value="$&#123;druid.removeAbandoned&#125;" /&gt; &lt;!-- 超时时间；单位为秒。180秒=3分钟 --&gt; &lt;property name="removeAbandonedTimeout" value="$&#123;druid.removeAbandonedTimeoutSeconds&#125;" /&gt; &lt;property name="validationQuery" value="$&#123;druid.validationQuery&#125;" /&gt; &lt;property name="testWhileIdle" value="$&#123;druid.testWhileIdle&#125;" /&gt; &lt;property name="testOnBorrow" value="$&#123;druid.testOnBorrow&#125;" /&gt; &lt;property name="testOnReturn" value="$&#123;druid.testOnReturn&#125;" /&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 如果用Oracle，则把poolPreparedStatements配置为true，mysql可以配置为false。 --&gt; &lt;property name="poolPreparedStatements" value="$&#123;druid.poolPreparedStatements&#125;" /&gt; &lt;property name="maxPoolPreparedStatementPerConnectionSize" value="$&#123;druid.maxPoolPreparedStatementPerConnectionSize&#125;" /&gt; &lt;!-- 配置监控统计拦截的filters --&gt; &lt;property name="filters" value="$&#123;druid.filters&#125;" /&gt; &lt;/bean&gt; 配置参数就不贴出。 使用@Configuration创建BeanConfiguration 是 Spring 3.X 后提供的注解，用于取代 XML 来配置 Spring, @Configuration可理解为用spring的时候xml里面的&lt;beans&gt;标签； @Bean可理解为用spring的时候xml里面的&lt;bean&gt;标签。 这样就很好理解了。 需要注意的时配置spring 扫描的包 &lt;context:component-scan base-package=&quot;com.xxx.xxx&quot; /&gt; 不然注解不起效果（springboot不需要设置）。 读取json文件的属性注入Bean这次使用Json文件来配置bean； 首先写出实体类，和需要配置的数据； 编写实体类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101package com.devframe.util;import java.util.List;/** * @author Zhang Kai * @version 1.0 * @since &lt;pre&gt;2017/11/2 11:31&lt;/pre&gt; */public class PersonCfg &#123; private String name; private int age; private String city; private List&lt;Contact&gt; contacts; @Override public String toString() &#123; return "PersonCfg&#123;" + "name='" + name + '\'' + ", age=" + age + ", city='" + city + '\'' + ", contacts=" + contacts + ", hobby=" + hobby + '&#125;'; &#125; public List&lt;Contact&gt; getContacts() &#123; return contacts; &#125; public void setContacts(List&lt;Contact&gt; contacts) &#123; this.contacts = contacts; &#125; public List getHobby() &#123; return hobby; &#125; public void setHobby(List hobby) &#123; this.hobby = hobby; &#125; private List hobby; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getCity() &#123; return city; &#125; public void setCity(String city) &#123; this.city = city; &#125;&#125;class Contact &#123; private String phone; private String email; public String getPhone() &#123; return phone; &#125; public void setPhone(String phone) &#123; this.phone = phone; &#125; public String getEmail() &#123; return email; &#125; public void setEmail(String email) &#123; this.email = email; &#125; @Override public String toString() &#123; return "Contact&#123;" + "phone='" + phone + '\'' + ", email='" + email + '\'' + '&#125;'; &#125;&#125; 需要注入的数据创建文件命名data.json，(注意属性名对应):12345678910111213&#123; "name": "wuwii", "age": 23, "city": "WuHan", "hobby": ["骑行", "跑步","足球"], "contacts": [&#123; "phone": "18772383543", "email": "k@wuwii.com" &#125;,&#123; "phone": "12345678912", "email": "1075199251@qq.com" &#125;]&#125; 创建Beansspring 容器初始化，自动扫描，去初始化Bean，加载进Environment，后面调用的直接自动装配（Autowired）；1234567891011121314151617181920212223242526package com.devframe.util;import com.fasterxml.jackson.databind.ObjectMapper;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import java.io.File;import java.io.IOException;/** * @author Zhang Kai * @version 1.0 * @since &lt;pre&gt;2017/11/2 11:23&lt;/pre&gt; */@Configurationpublic class Configs &#123; @Value("classpath:data.json") protected File configFile; @Bean public PersonCfg readServerConfig() throws IOException &#123; return new ObjectMapper().readValue(configFile, PersonCfg.class); &#125;&#125; @Bean 注解方法的返回值，将注入到容器中，可以使用自动装配。 测试直接使用spring-test 的JUnit4 单元测试;直接装配Bean ，来输出它的属性，查看是否装配成功。12345678910111213141516171819202122232425262728293031323334353637383940414243package com.devframe.util; import org.junit.Test; import org.junit.Before; import org.junit.After;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;/** * Configs Tester. * * @author Zhang Kai * @since &lt;pre&gt;11/02/2017&lt;/pre&gt; * @version 1.0 */@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &#123;"classpath:spring/applicationContext-base.xml"&#125;)public class ConfigsTest &#123; @Autowired private PersonCfg personCfg;@Beforepublic void before() throws Exception &#123; &#125; @Afterpublic void after() throws Exception &#123; &#125; /** * * Method: 名字随便起的，不规范。* */ @Testpublic void testConfigBeans() throws Exception &#123; System.out.printf("Use '@Configuration' autowired beans : %s%n", personCfg);&#125; &#125; 测试结果：1Use '@Configuration' autowired beans : PersonCfg&#123;name='wuwii', age=23, city='WuHan', contacts=[Contact&#123;phone='18772383543', email='k@wuwii.com'&#125;, Contact&#123;phone='12345678912', email='1075199251@qq.com'&#125;], hobby=[骑行, 跑步]&#125; 读取properties 文件的属性注入Bean上面的的方法中除了测试类的方法相同而已，为了方便其余都有改动； 首先实体类，通过构造方法传入值123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117package com.devframe.util;import java.util.List;/** * @author Zhang Kai * @version 1.0 * @since &lt;pre&gt;2017/11/2 11:31&lt;/pre&gt; */public class PersonCfg &#123; private String name; private int age; private String city; private List&lt;Contact&gt; contacts; private List hobby; public PersonCfg() &#123; &#125; public PersonCfg(String name, int age, String city, List&lt;Contact&gt; contacts, List hobby) &#123; this.name = name; this.age = age; this.city = city; this.contacts = contacts; this.hobby = hobby; &#125; @Override public String toString() &#123; return "PersonCfg&#123;" + "name='" + name + '\'' + ", age=" + age + ", city='" + city + '\'' + ", contacts=" + contacts + ", hobby=" + hobby + '&#125;'; &#125; public List&lt;Contact&gt; getContacts() &#123; return contacts; &#125; public void setContacts(List&lt;Contact&gt; contacts) &#123; this.contacts = contacts; &#125; public List getHobby() &#123; return hobby; &#125; public void setHobby(List hobby) &#123; this.hobby = hobby; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getCity() &#123; return city; &#125; public void setCity(String city) &#123; this.city = city; &#125;&#125;class Contact &#123; private String phone; private String email; public Contact(String phone, String email) &#123; this.phone = phone; this.email = email; &#125; public String getPhone() &#123; return phone; &#125; public void setPhone(String phone) &#123; this.phone = phone; &#125; public String getEmail() &#123; return email; &#125; public void setEmail(String email) &#123; this.email = email; &#125; @Override public String toString() &#123; return "Contact&#123;" + "phone='" + phone + '\'' + ", email='" + email + '\'' + '&#125;'; &#125;&#125; 配置文件由于properties 文件不能写 只能写那些单一属性，数组和对象需要自己设置规则，去后台解析出来使用。创建person.properties 文件：12345name=wuwiiage=23city=WuHanhobby=football,runningcontacts=18772383543,k@wuwii.com;12345678912,1075199251@qq.com 创建Bean通过@Configuration完成spring 初始化，设置@PropertySource，读取配置文件：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.devframe.util;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.PropertySource;import org.springframework.core.env.Environment;import javax.annotation.Resource;import java.util.Arrays;import java.util.List;import java.util.stream.Collectors;/** * @author Zhang Kai * @version 1.0 * @since &lt;pre&gt;2017/11/2 11:23&lt;/pre&gt; */@Configuration@PropertySource("classpath:person.properties")public class Configs &#123; @Resource private Environment env; @Bean public PersonCfg getPersonFromProp() &#123; return new PersonCfg(env.getProperty("name"), Integer.valueOf(env.getProperty("age")), env.getProperty("city"), string2contacts(env.getProperty("contacts")), string2list(env.getProperty("hobby"))); &#125; /** * 按照预先定义规则的列表字符串 转换成列表 * @param s 预先定义规则的列表字符串 * @return java.util.List */ private List string2list (String s) &#123; return StringUtil.isNull(s) ? null : Arrays.asList(s.split(",")); &#125; /** * &lt;p&gt;按照预先定义规则&lt;/p&gt; * &lt;p&gt;将配置文件 Contact 列表的字符串 转换成 列表对象&lt;/p&gt; * @param s 读取配置文件 Contact 列表的字符串 * @return java.util.List&lt;com.devframe.util.Contact&gt; */ private List&lt;Contact&gt; string2contacts (String s) &#123; if (StringUtil.isNull(s)) return null; List&lt;String&gt; list1 = Arrays.asList(s.split(";")); return list1.stream().map(this::contactStr2contact).collect(Collectors.toList()); &#125; /** * 按照预定义规则转换成 contact对象 * @param contactStr contact类的字符串 * @return com.devframe.util.Contact */ private Contact contactStr2contact (String contactStr) &#123; String[] index = contactStr.split(","); // 传入字段数，自己控制，有点蠢了 if (index.length != 2) &#123; return null; &#125; return new Contact(index[0], index[1]); &#125;&#125; 测试最后JUnit4 测试类没变，重新测试，打印出来结果：1Use &apos;@Configuration&apos; autowired beans : PersonCfg&#123;name=&apos;wuwii&apos;, age=23, city=&apos;WuHan&apos;, contacts=[Contact&#123;phone=&apos;18772383543&apos;, email=&apos;k@wuwii.com&apos;&#125;, Contact&#123;phone=&apos;12345678912&apos;, email=&apos;1075199251@qq.com&apos;&#125;], hobby=[football, running]&#125; 成功。 补充20171103 早上来看了下源码：1234567891011121314151617181920212223242526272829303132333435363738/** * Return the property value associated with the given key, or &#123;@code null&#125; * if the key cannot be resolved. * @param key the property name to resolve * @see #getProperty(String, String) * @see #getProperty(String, Class) * @see #getRequiredProperty(String) */String getProperty(String key);/** * Return the property value associated with the given key, or * &#123;@code defaultValue&#125; if the key cannot be resolved. * @param key the property name to resolve * @param defaultValue the default value to return if no value is found * @see #getRequiredProperty(String) * @see #getProperty(String, Class) */String getProperty(String key, String defaultValue);/** * Return the property value associated with the given key, or &#123;@code null&#125; * if the key cannot be resolved. * @param key the property name to resolve * @param targetType the expected type of the property value * @see #getRequiredProperty(String, Class) */&lt;T&gt; T getProperty(String key, Class&lt;T&gt; targetType);/** * Return the property value associated with the given key, or * &#123;@code defaultValue&#125; if the key cannot be resolved. * @param key the property name to resolve * @param targetType the expected type of the property value * @param defaultValue the default value to return if no value is found * @see #getRequiredProperty(String, Class) */&lt;T&gt; T getProperty(String key, Class&lt;T&gt; targetType, T defaultValue); 在PropertyResolver接口中发现：1&lt;T&gt; T getProperty(String key, Class&lt;T&gt; targetType); 这个方法可以直接读取文件内容转换成我们的需要类型，虽然说很好，调试了半天代码不知道properties文件怎么写对象来让它转换，这个以后再看，list列表很好转，将上面的方法加载hobby属性改成这个：12env.getProperty(("age"), Integer.class)env.getProperty(("hobby"), List.class) person文件中hobby属性为： 1hobby=running,football 执行结果：1Use &apos;@Configuration&apos; autowired beans : PersonCfg&#123;name=&apos;wuwii&apos;, age=23, city=&apos;WuHan&apos;, contacts=[Contact&#123;phone=&apos;18772383543&apos;, email=&apos;k@wuwii.com&apos;&#125;, Contact&#123;phone=&apos;12345678912&apos;, email=&apos;1075199251@qq.com&apos;&#125;], hobby=[running, football]&#125; 没问题 直接使用@Value占位符注入方法一使用@Component 方式注入，需要再applicationContext.xml中引入properties文件： 12345678910111213&lt;!-- 参数占位符 --&gt;&lt;bean class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer" lazy-init="true"&gt; &lt;property name="systemPropertiesModeName" value="SYSTEM_PROPERTIES_MODE_OVERRIDE" /&gt; &lt;property name="ignoreResourceNotFound" value="false" /&gt; &lt;property name="locations"&gt; &lt;list&gt; &lt;value&gt;classpath:spring/database.properties&lt;/value&gt; &lt;value&gt;classpath:person.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt; 改下实体类，直接在属性上注入@Value，占位符符号${ }12345678910111213141516171819202122232425262728293031package com.devframe.util;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.PropertySource;import org.springframework.stereotype.Component;import java.util.List;/** * @author Zhang Kai * @version 1.0 * @since &lt;pre&gt;2017/11/2 11:31&lt;/pre&gt; */@Componentpublic class PersonCfg &#123; @Value("$&#123;name&#125;") private String name; @Value("$&#123;age&#125;") private int age; @Value("$&#123;city&#125;") private String city; //这个不会，对象属性不会写 //@Value("$&#123;contacts1&#125;") private List&lt;Contact&gt; contacts; @Value("$&#123;hobby&#125;") private List hobby;//省略代码&#125; 测试结果:1Use &apos;@Configuration&apos; autowired beans : PersonCfg&#123;name=&apos;wuwii&apos;, age=23, city=&apos;WuHan&apos;, contacts=null, hobby=[running,football]&#125; 发现数组列表也能直接注入。 方法二在配置类中设置引入配置文件，还需引入占位符，等价于XML中的&lt;context:property-placeholder/&gt;配置。12345678910111213@Configuration@PropertySource("classpath:person.properties")public class Configs &#123; private static final Logger LOGGER = LoggerFactory.getLogger(Configs.class); @Autowired private Environment env; @Bean public PropertySourcesPlaceholderConfigurer propertySourcesPlaceholderConfigurer() &#123; return new PropertySourcesPlaceholderConfigurer(); &#125; //省略&#125; 就可以在类中的属性上使用@Value占位符 注入了。 总结 还可以读取xml文件进行装配，当然也不使用配置文件，直接在Beans的@Value注解上写出需要注解的值，但是那样后期部署修改起来麻烦。 常用的应该时这么两个 比较好，properties 可能用的多点吧；因为平时使用这个外部需要修改的参数 的基本都是一些常量，不会存在这么多转换，这个只是我的测试的代码，所以有一些鬼转换。 还有我使用properties 中为什么没使用中文，因为乱码了。尴尬。这是需要注意的地方，因为电脑默认编码是gbk，但是读的时候，又没有设置编码。解决办法：在读取properties文件的工具类上，加上指定编码格式utf-8:12345URL url = PropertyUtil.class.getResource("/config.properties");FileInputStream in = new FileInputStream(url.getPath());//这段代码不是 以前的 PROP.load(in);PROP.load(new InputStreamReader(in, "utf-8"));in.close();]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中创建线程池的常用方法]]></title>
    <url>%2Fjava-create-pool.html</url>
    <content type="text"><![CDATA[创建线程池学习了Java中线程池的工作流程，现在学习一下怎么使用线程池；前面了解到构造一个线程池参数，最简单的线程池构造函数：12345678public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); &#125; 最少需要设置这么几个参数：12345corePoolSize 核心池大小，maximumPoolSize 最大线程数量，keepAliveTime 心跳时间unit 心跳时间单位，什么时候销毁多余的线程workQueue 最重要的，阻塞队列，存储等待中的任务 在前面创建过线程池：1234private static final BlockingQueue queue = new ArrayBlockingQueue(5);private static final ThreadPoolExecutor executor = new ThreadPoolExecutor(5, 10, 200, TimeUnit.MILLISECONDS, queue); 第一步创建一个固定容量的队列来存储等待执行的任务；第二步设置核心池数，最大容量数，心跳时间参数。 这个executor线程池说明了，核心池数为5，缓存队列最多存储5个任务，最大线程池数为10，当任务数量大于核心数（5）的时候，监控空闲线程，在心跳时间200 MILLISECONDS后，结束任务，直到线程池中线程数不大于核心数 5。 使用Executors来创建线程池如果没有特殊的要求，一般都是推荐用Executors工具类来创建线程池，因为它的参数都给我们配置好了，直接拿来用就好。Executors类提供的方法来创建线程池：123456Executors.newCachedThreadPool(); //创建一个缓冲池，缓冲池容量大小为Integer.MAX_VALUEExecutors.newSingleThreadExecutor(); //创建容量为1的缓冲池Executors.newFixedThreadPool(int corePoolSize); //创建固定容量大小的缓冲池，缓存队列大小为Integer.MAX_VALUEExecutors.newScheduledThreadPool(int corePoolSize) //创建一个最大容量为Integer.MAX_VALUE的缓冲池，支持定时及周期性任务执行Executors.newSingleThreadScheduledExcutor //创建一个单例线程池，定期或延时执行任务。Executors.newWorkStealingPool //创建持有足够线程的线程池来支持给定的并行级别，并通过使用多个队列，减少竞争，它需要穿一个并行级别的参数，如果不传，则被设定为默认的CPU数量。 newCachedThreadPoolnewCachedThreadPool 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。缓冲池容量大小为Integer.MAX_VALUE。12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; newSingleThreadExecutor创建容量为1的缓冲池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; newFixedThreadPool创建固定容量大小的缓冲池，缓存队列大小为Integer.MAX_VALUE:12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; 定长线程池的大小最好根据系统资源进行设置。如Runtime.getRuntime().availableProcessors()。 newScheduledThreadPool创建一个最大容量为Integer.MAX_VALUE的缓冲池，支持定时及周期性任务执行。12345678public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize); &#125;public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue()); &#125; 这里主要主要它的定时任务用法； 123456789101112131415161718192021222324252627package com.wuwii.test;import java.util.concurrent.Executors;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.TimeUnit;/** * 测试newScheduledThreadPool * @author Zhang Kai * @version 1.0 * @since &lt;pre&gt;2017/11/1 16:25&lt;/pre&gt; */public class TestPoolTwo &#123; public static void main(String[] args) &#123; ScheduledExecutorService scheduleExcutor = Executors.newScheduledThreadPool(5); //延迟两秒执行 scheduleExcutor.schedule(() -&gt; &#123; System.out.println("Delay 2 seconds."); &#125;, 2, TimeUnit.SECONDS); //延迟两秒执行，后面每隔五秒执行 scheduleExcutor.scheduleAtFixedRate(() -&gt; &#123; System.out.println("Delay 2 seconds."); &#125;, 2, 5, TimeUnit.SECONDS); &#125;&#125; 主要注意的有两点： 使用的是ScheduledExecutorService 这个接口，这个接口也是继承ExecutorService，所以也有sumit，execute方法； ScheduledExecutorService接口中有定时，延迟执行任务的方法:scheduleAtFixedRate,schedule。 newSingleThreadScheduledExcutor创建一个单例线程池，定期或延时执行任务，方法同同上面的newScheduledThreadPool： 1234public static ScheduledExecutorService newSingleThreadScheduledExecutor() &#123; return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1)); &#125; newWorkStealingPool创建一个拥有多个任务队列（以便减少连接数）的线程池：12345678910111213public static ExecutorService newWorkStealingPool() &#123; return new ForkJoinPool (Runtime.getRuntime().availableProcessors(), ForkJoinPool.defaultForkJoinWorkerThreadFactory, null, true); &#125;public static ExecutorService newWorkStealingPool(int parallelism) &#123; return new ForkJoinPool (parallelism, ForkJoinPool.defaultForkJoinWorkerThreadFactory, null, true); &#125; 默认不传入线程池大小，默认按机器CPU能力来设置。 它使用的是ForkJoinPool多线程中的任务分解机制，将大任务按照预先制定的规则将大任务分解成小任务，多线程并发。这个是java7新加入的线程池，可以使用相对少的线程来处理大量的任务。 阿里代码规范补充编码的时候发现了最新的阿里代码规范工具中，发现了这个提示了，记录， 线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 说明：Executors各个方法的弊端： newFixedThreadPool和newSingleThreadExecutor: 主要问题是堆积的请求处理队列可能会耗费非常大的内存，甚至OOM。 newCachedThreadPool和newScheduledThreadPool: 主要问题是线程数最大数是Integer.MAX_VALUE，可能会创建数量非常多的线程，甚至OOM。 Positive example 1：123456789101112131415161718192021222324252627282930313233343536 //org.apache.commons.lang3.concurrent.BasicThreadFactory ScheduledExecutorService executorService = new ScheduledThreadPoolExecutor(1, new BasicThreadFactory.Builder().namingPattern("example-schedule-pool-%d").daemon(true).build());``` Positive example 2：```java ThreadFactory namedThreadFactory = new ThreadFactoryBuilder() .setNameFormat("demo-pool-%d").build(); //Common Thread Pool ExecutorService pool = new ThreadPoolExecutor(5, 200, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy()); pool.execute(()-&gt; System.out.println(Thread.currentThread().getName())); pool.shutdown();//gracefully shutdown``` Positive example 3：```java &lt;bean id="userThreadPool" class="org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor"&gt; &lt;property name="corePoolSize" value="10" /&gt; &lt;property name="maxPoolSize" value="100" /&gt; &lt;property name="queueCapacity" value="2000" /&gt; &lt;property name="threadFactory" value= threadFactory /&gt; &lt;property name="rejectedExecutionHandler"&gt; &lt;ref local="rejectedExecutionHandler" /&gt; &lt;/property&gt; &lt;/bean&gt; //in code userThreadPool.execute(thread);]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中守护线程的总结]]></title>
    <url>%2Fuser-daemon-thread.html</url>
    <content type="text"><![CDATA[了解下Java中的守护线程，看到这篇文章很详细，记录下来。文章来自http://blog.csdn.net/shimiso/article/details/8964414 在Java中有两类线程：User Thread(用户线程)、Daemon Thread(守护线程)用个比较通俗的比如，任何一个守护线程都是整个JVM中所有非守护线程的保姆：只要当前JVM实例中尚存在任何一个非守护线程没有结束，守护线程就全部工作；只有当最后一个非守护线程结束时，守护线程随着JVM一同结束工作。Daemon的作用是为其他线程的运行提供便利服务，守护线程最典型的应用就是 GC (垃圾回收器)，它就是一个很称职的守护者。User和Daemon两者几乎没有区别，唯一的不同之处就在于虚拟机的离开：如果 User Thread已经全部退出运行了，只剩下Daemon Thread存在了，虚拟机也就退出了。 因为没有了被守护者，Daemon也就没有工作可做了，也就没有继续运行程序的必要了。 值得一提的是，守护线程并非只有虚拟机内部提供，用户在编写程序时也可以自己设置守护线程。下面的方法就是用来设置守护线程的。1234567Thread daemonTread = new Thread(); // 设定 daemonThread 为 守护线程，default false(非守护线程) daemonThread.setDaemon(true); // 验证当前线程是否为守护线程，返回 true 则为守护线程 daemonThread.isDaemon(); 这里有几点需要注意： thread.setDaemon(true)必须在thread.start()之前设置，否则会跑出一个IllegalThreadStateException异常。你不能把正在运行的常规线程设置为守护线程。 在Daemon线程中产生的新线程也是Daemon的。 不要认为所有的应用都可以分配给Daemon来进行服务，比如读写操作或者计算逻辑。 因为你不可能知道在所有的User完成之前，Daemon是否已经完成了预期的服务任务。一旦User退出了，可能大量数据还没有来得及读入或写出，计算任务也可能多次运行结果不一样。这对程序是毁灭性的。造成这个结果理由已经说过了：一旦所有User Thread离开了，虚拟机也就退出运行了。 1234567891011121314151617181920212223242526272829//完成文件输出的守护线程任务 import java.io.*; class TestRunnable implements Runnable&#123; public void run()&#123; try&#123; Thread.sleep(1000);//守护线程阻塞1秒后运行 File f=new File("daemon.txt"); FileOutputStream os=new FileOutputStream(f,true); os.write("daemon".getBytes()); &#125; catch(IOException e1)&#123; e1.printStackTrace(); &#125; catch(InterruptedException e2)&#123; e2.printStackTrace(); &#125; &#125; &#125; public class TestDemo2&#123; public static void main(String[] args) throws InterruptedException &#123; Runnable tr=new TestRunnable(); Thread thread=new Thread(tr); thread.setDaemon(true); //设置守护线程 thread.start(); //开始执行分进程 &#125; &#125; //运行结果：文件daemon.txt中没有"daemon"字符串。 看到了吧，把输入输出逻辑包装进守护线程多么的可怕，字符串并没有写入指定文件。原因也很简单，直到主线程完成，守护线程仍处于1秒的阻塞状态。这个时候主线程很快就运行完了，虚拟机退出，Daemon停止服务，输出操作自然失败了。123456789101112131415161718192021public class Test &#123; public static void main(String args) &#123; Thread t1 = new MyCommon(); Thread t2 = new Thread(new MyDaemon()); t2.setDaemon(true); //设置为守护线程 t2.start(); t1.start(); &#125; &#125; class MyCommon extends Thread &#123; public void run() &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println("线程1第" + i + "次执行！"); try &#123; Thread.sleep(7); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; 123456789101112class MyDaemon implements Runnable &#123; public void run() &#123; for (long i = 0; i &lt; 9999999L; i++) &#123; System.out.println("后台线程第" + i + "次执行！"); try &#123; Thread.sleep(7); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; 执行结果： 1234567891011121314后台线程第0次执行！ 线程1第0次执行！ 线程1第1次执行！ 后台线程第1次执行！ 后台线程第2次执行！ 线程1第2次执行！ 线程1第3次执行！ 后台线程第3次执行！ 线程1第4次执行！ 后台线程第4次执行！ 后台线程第5次执行！ 后台线程第6次执行！ 后台线程第7次执行！ Process finished with exit code 0 从上面的执行结果可以看出： 前台线程是保证执行完毕的，后台线程还没有执行完毕就退出了。 实际上：JRE判断程序是否执行结束的标准是所有的前台执线程行完毕了，而不管后台线程的状态，因此，在使用后台县城时候一定要注意这个问题。 补充说明：定义：守护线程–也称“服务线程”，在没有用户线程可服务时会自动离开。优先级：守护线程的优先级比较低，用于为系统中的其它对象和线程提供服务。设置：通过setDaemon(true)来设置线程为“守护线程”；将一个用户线程设置为守护线程的方式是在 线程对象创建 之前 用线程对象的setDaemon方法。example: 垃圾回收线程就是一个经典的守护线程，当我们的程序中不再有任何运行的Thread,程序就不会再产生垃圾，垃圾回收器也就无事可做，所以当垃圾回收线程是JVM上仅剩的线程时，垃圾回收线程会自动离开。它始终在低级别的状态中运行，用于实时监控和管理系统中的可回收资源。生命周期：守护进程（Daemon）是运行在后台的一种特殊进程。它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。也就是说守护线程不依赖于终端，但是依赖于系统，与系统“同生共死”。那Java的守护线程是什么样子的呢。当JVM中所有的线程都是守护线程的时候，JVM就可以退出了；如果还有一个或以上的非守护线程则JVM不会退出。 实际应用例子：在使用长连接的comet服务端推送技术中，消息推送线程设置为守护线程，服务于ChatServlet的servlet用户线程，在servlet的init启动消息线程，servlet一旦初始化后，一直存在服务器，servlet摧毁后,消息线程自动退出 容器收到一个Servlet请求，调度线程从线程池中选出一个工作者线程,将请求传递给该工作者线程，然后由该线程来执行Servlet的 service方法。当这个线程正在执行的时候,容器收到另外一个请求,调度线程同样从线程池中选出另一个工作者线程来服务新的请求,容器并不关心这个请求是否访问的是同一个Servlet.当容器同时收到对同一个Servlet的多个请求的时候，那么这个Servlet的service()方法将在多线程中并发执行。Servlet容器默认采用单实例多线程的方式来处理请求，这样减少产生Servlet实例的开销，提升了对请求的响应时间，对于Tomcat可以在server.xml中通过元素设置线程池中线程的数目。如图： 为什么要用守护线程？ 我们知道静态变量是ClassLoader级别的，如果Web应用程序停止，这些静态变量也会从JVM中清除。但是线程则是JVM级别的，如果你在Web 应用中启动一个线程，这个线程的生命周期并不会和Web应用程序保持同步。也就是说，即使你停止了Web应用，这个线程依旧是活跃的。正是因为这个很隐晦 的问题，所以很多有经验的开发者不太赞成在Web应用中私自启动线程。 如果我们手工使用JDK Timer（Quartz的Scheduler），在Web容器启动时启动Timer，当Web容器关闭时，除非你手工关闭这个Timer，否则Timer中的任务还会继续运行！ 下面通过一个小例子来演示这个“诡异”的现象，我们通过ServletContextListener在Web容器启动时创建一个Timer并周期性地运行一个任务：123456789101112131415161718192021222324252627//代码清单StartCycleRunTask：容器监听器 package com.baobaotao.web; import java.util.Date; import java.util.Timer; import java.util.TimerTask; import javax.servlet.ServletContextEvent; import javax.servlet.ServletContextListener; public class StartCycleRunTask implements ServletContextListener &#123; private Timer timer; public void contextDestroyed(ServletContextEvent arg0) &#123; // ②该方法在Web容器关闭时执行 System.out.println("Web应用程序启动关闭..."); &#125; public void contextInitialized(ServletContextEvent arg0) &#123; //②在Web容器启动时自动执行该方法 System.out.println("Web应用程序启动..."); timer = new Timer();//②-1:创建一个Timer，Timer内部自动创建一个背景线程 TimerTask task = new SimpleTimerTask(); timer.schedule(task, 1000L, 5000L); //②-2:注册一个5秒钟运行一次的任务 &#125; &#125; class SimpleTimerTask extends TimerTask &#123;//③任务 private int count; public void run() &#123; System.out.println((++count)+"execute task..."+(new Date())); &#125; &#125; 在web.xml中声明这个Web容器监听：1234567：&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app&gt; … &lt;listener&gt; &lt;listener-class&gt;com.baobaotao.web.StartCycleRunTask&lt;/listener-class&gt; &lt;/listener&gt; &lt;/web-app&gt; 在Tomcat中部署这个Web应用并启动后，你将看到任务每隔5秒钟执行一次。运行一段时间后，登录Tomcat管理后台，将对应的Web应用（chapter13）关闭。 转到Tomcat控制台，你将看到虽然Web应用已经关闭，但Timer任务还在我行我素地执行如故——舞台已经拆除，戏子继续表演： 我们可以通过改变清单StartCycleRunTask的代码，在contextDestroyed(ServletContextEvent arg0)中添加timer.cancel()代码，在Web容器关闭后手工停止Timer来结束任务。 Spring为JDK Timer和Quartz Scheduler所提供的TimerFactoryBean和SchedulerFactoryBean能够和Spring容器的生命周期关联，在 Spring容器启动时启动调度器，而在Spring容器关闭时，停止调度器。所以在Spring中通过这两个FactoryBean配置调度器，再从 Spring IoC中获取调度器引用进行任务调度将不会出现这种Web容器关闭而任务依然运行的问题。而如果你在程序中直接使用Timer或Scheduler，如不 进行额外的处理，将会出现这一问题。 文章转载自http://blog.csdn.net/shimiso/article/details/8964414]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中使用有返回值的线程]]></title>
    <url>%2Fjava-thread-return.html</url>
    <content type="text"><![CDATA[在创建多线程程序的时候，我们常实现Runnable接口，Runnable没有返回值，要想获得返回值，Java5提供了一个新的接口Callable，可以获取线程中的返回值，但是获取线程的返回值的时候，需要注意，我们的方法是异步的，获取返回值的时候，线程任务不一定有返回值，所以，需要判断线程是否结束，才能够去取值。 测试代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.wuwii.test;import java.util.concurrent.*;/** * @author Zhang Kai * @version 1.0 * @since &lt;pre&gt;2017/10/31 11:17&lt;/pre&gt; */public class Test &#123; private static final Integer SLEEP_MILLS = 3000; private static final Integer RUN_SLEEP_MILLS = 1000; private int afterSeconds = SLEEP_MILLS / RUN_SLEEP_MILLS; // 线程池（根据机器的核心数） private final ExecutorService fixedThreadPool = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors()); private void testCallable() throws InterruptedException &#123; Future&lt;String&gt; future = null; try &#123; /** * 在创建多线程程序的时候，我们常实现Runnable接口，Runnable没有返回值，要想获得返回值，Java5提供了一个新的接口Callable * * Callable需要实现的是call()方法，而不是run()方法，返回值的类型有Callable的类型参数指定， * Callable只能由ExecutorService.submit() 执行，正常结束后将返回一个future对象。 */ future = fixedThreadPool.submit(() -&gt; &#123; Thread.sleep(SLEEP_MILLS); return "The thread returns value."; &#125;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; if (future == null) return; for (;;) &#123; /** * 获得future对象之前可以使用isDone()方法检测future是否完成，完成后可以调用get()方法获得future的值， * 如果直接调用get()方法，get()方法将阻塞到线程结束，很浪费。 */ if (future.isDone()) &#123; try &#123; System.out.println(future.get()); break; &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125; &#125; else &#123; System.out.println("After " + afterSeconds-- + " seconds,get the future returns value."); Thread.sleep(1000); &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; new Test().testCallable(); &#125;&#125; 运行结果：1234After 3 seconds,get the future returns value.After 2 seconds,get the future returns value.After 1 seconds,get the future returns value.The thread returns value. 总结: 需要返回值的线程使用Callable 接口，实现call 方法； 获得future对象之前可以使用isDone()方法检测future是否完成，完成后可以调用get()方法获得future的值，如果直接调用get()方法，get()方法将阻塞到线程结束。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程中线程池源码分析及使用]]></title>
    <url>%2Fjava-concurrent-thread-pool.html</url>
    <content type="text"><![CDATA[当Java处理高并发的时候，线程数量特别的多的时候，而且每个线程都是执行很短的时间就结束了，频繁创建线程和销毁线程需要占用很多系统的资源和时间，会降低系统的工作效率。 参考http://www.cnblogs.com/dolphin0520/p/3932921.html 由于原文作者使用的API 是1.6 版本的，参考他的文章，做了一些修改成 jdk 1.8版本的方法，涉及到的内容比较多，可能有少许错误。 API : jdk1.8.0_144 ThreadPoolExecutor类Java中线程池主要是并发包java.util.concurrent 中 ThreadPoolExecutor这个类实现的。 构造函数我们直接调用它的时候，使用的是它的构造函数，它有四个构造函数：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class ThreadPoolExecutor extends AbstractExecutorService &#123; //省略前面的代码 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); &#125; public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler); &#125; public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), handler); &#125; public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; &#125; //省略后面的代码&#125; ThreadPoolExecutor继承了AbstractExecutorService抽象类，并提供了四个构造器，事实上，前面三个构造器都是调用的第四个构造器进行的初始化工作。所以主要研究下第四个构造器的方法。 首先了解下构造器中参数的意思： corePoolSize: 核心池的大小，这个参数跟后面讲述的线程池的实现原理有非常大的关系。在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用了prestartAllCoreThreads()或者prestartCoreThread()方法，从这2个方法的名字就可以看出，是预创建线程的意思，即在没有任务到来之前就创建corePoolSize个线程或者一个线程。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中； maximumPoolSize: 线程池最大线程数，这个参数也是一个非常重要的参数，它表示在线程池中最多能创建多少个线程； keepAliveTime:字面意思就是心跳时间，就是这个线程池中的线程数量大于corePoolSize的时候开始计时，设置空闲线程最多能存活多长时间。默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0，它的单位是参数TimeUnit unit； unit: 参数keepAliveTime的时间单位，有7种取值，在TimeUnit类中有7种静态属性： 1234567TimeUnit.DAYS; //天TimeUnit.HOURS; //小时TimeUnit.MINUTES; //分钟TimeUnit.SECONDS; //秒TimeUnit.MILLISECONDS; //毫秒TimeUnit.MICROSECONDS; //微妙TimeUnit.NANOSECONDS; //纳秒 workQueue：一个阻塞队列BlockingQueue，用来存储等待执行的任务，这个参数的选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列有以下几种选择，以后再详细学习BlockingQueue阻塞队列使用： 12345ArrayBlockingQueue; // 基于数组的阻塞队列实现LinkedBlockingQueue; // 基于链表的阻塞队列SynchronousQueue; //一种无缓冲的等待队列DelayQueue； // 队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞。PriorityBlockingQueue // 基于优先级的阻塞队列 threadFactory: 线程工厂，主要用来创建线程； handler: 表示当拒绝处理任务时的策略，有以下四种取值：1234ThreadPoolExecutor.AbortPolicy //丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy //也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy //丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy //由调用线程处理该任务 ThreadPoolExecutor方法首先ThreadPoolExecutor类自己拥有很多方法，用来获取线程池的相关属性。 12 ThreadPoolExecutor继承了AbstractExecutorService这个抽象类， 1234567891011121314151617181920212223242526public abstract class AbstractExecutorService implements ExecutorService&#123; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; &#125;; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; &#125;; public Future&lt;?&gt; submit(Runnable task) &#123;&#125;; public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; &#125;; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; &#125;; private &lt;T&gt; T doInvokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException &#123; &#125;; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException &#123; &#125;; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; &#125;; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException &#123; &#125;; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;;&#125; AbstractExecutorService实现了接口 ExecutorService中所有的方法。 12345678910111213141516171819202122public interface ExecutorService extends Executor &#123; void shutdown(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); Future&lt;?&gt; submit(Runnable task); &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; ExecutorService 接口继承了 Executor接口。 123public interface Executor &#123; void execute(Runnable command);&#125; 可以看出类ThreadPoolExecutor拥有了多少方法。 平时开发中主要使用方法：1234execute() // 线程池启动一个线程submit() // 线程池启动一个线程，有返回值shutdown() //执行完毕所有等待中的线程，再关闭线程池shutdownNow() // 直接关闭，不等待 execute()方法实际上是Executor中声明的方法，在ThreadPoolExecutor进行了具体的实现，这个方法是ThreadPoolExecutor的核心方法，通过这个方法可以向线程池提交一个任务，交由线程池去执行。 submit()方法是在ExecutorService中声明的方法，在AbstractExecutorService就已经有了具体的实现，在ThreadPoolExecutor中并没有对其进行重写，这个方法也是用来向线程池提交任务的，但是它和execute()方法不同，它能够返回任务执行的结果，去看submit()方法的实现，会发现它实际上还是调用的execute()方法，只不过它利用了Future来获取任务执行结果。 shutdown()和shutdownNow()是用来关闭线程池的。 线程池的实现线程池的状态12345678910111213141516171819202122232425262728* The runState provides the main lifecycle control, taking on values: * * RUNNING: Accept new tasks and process queued tasks * SHUTDOWN: Don't accept new tasks, but process queued tasks * STOP: Don't accept new tasks, don't process queued tasks, * and interrupt in-progress tasks * TIDYING: All tasks have terminated, workerCount is zero, * the thread transitioning to state TIDYING * will run the terminated() hook method * TERMINATED: terminated() has completed * * The numerical order among these values matters, to allow * ordered comparisons. The runState monotonically increases over * time, but need not hit each state. The transitions are: * * RUNNING -&gt; SHUTDOWN * On invocation of shutdown(), perhaps implicitly in finalize() * (RUNNING or SHUTDOWN) -&gt; STOP * On invocation of shutdownNow() * SHUTDOWN -&gt; TIDYING * When both queue and pool are empty * STOP -&gt; TIDYING * When pool is empty * TIDYING -&gt; TERMINATED * When the terminated() hook method has completed * * Threads waiting in awaitTermination() will return when the * state reaches TERMINATED. 根据上面的代码文档，，可以清楚的了解到线程池的各种状态，以及在这种状态中能做的事情，状态之间的转变。 如果调用了shutdown()方法，则线程池处于SHUTDOWN状态，此时线程池不能够接受新的任务，它会等待所有任务执行完毕； 如果调用了shutdownNow()方法，则线程池处于STOP状态，此时线程池不能接受新的任务，并且会去尝试终止正在执行的任务； 当线程池处于SHUTDOWN或STOP状态，并且所有工作线程已经销毁，任务缓存队列已经清空或执行结束后，线程池被设置为TERMINATED状态。 12345678910111213141516private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3; //29private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1; //536870911 目前最大线程容量// runState is stored in the high-order bitsprivate static final int RUNNING = -1 &lt;&lt; COUNT_BITS; // 111 00000000000000000000000000000private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; // 000 00000000000000000000000000000private static final int STOP = 1 &lt;&lt; COUNT_BITS; // 001 00000000000000000000000000000private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; // 010 00000000000000000000000000000 private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; // 100 00000000000000000000000000000// Packing and unpacking ctlprivate static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125; //最高3位， 状态private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125; //后29位 ，工作数量private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; ctl作为ThreadPoolExecutor的核心状态控制字段，包含来两个信息： 工作线程总数 workerCount 线程池状态 RUNNING、 SHUTDOWN、 STOP、 TIDYING、 TERMINATED。 COUNT_BITS 是32减去3 就是29，下面的线程池状态就是－1 到 3 分别向左移动29位。 如此，int的右侧29位，代表着线程数量，总数可以达到2的29次，29位后的3位代表线程池的状态这样，线程池增加一个线程，只需吧ctl加1即可，而我们也发现实际这个线程池的最高线程数量是2的29次减1。并不是先前我们现象的2的32次减1。这个作者在注释中也提到了，说如果后续需要增大这个值， 可以吧ctl定义成AtomicLong。 任务的执行excute属性变量了解ThreadPoolExecutor类中其他的一些比较重要成员变量：1234567891011121314151617181920212223242526272829private final BlockingQueue&lt;Runnable&gt; workQueue; //任务缓存队列，用来存放等待执行的任务private final ReentrantLock mainLock = new ReentrantLock(); //线程池的主要状态锁，对线程池状态（比如线程池大小 //、runState等）的改变都要使用这个锁private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); //用来存放工作集 private volatile long keepAliveTime; //线程存货时间 private volatile boolean allowCoreThreadTimeOut; //是否允许为核心线程设置存活时间private volatile int corePoolSize; //核心池的大小（即线程池中的线程数目大于这个参数时，提交的任务会被放进任务缓存队列）private volatile int maximumPoolSize; //线程池最大能容忍的线程数 private volatile int poolSize; //线程池中当前的线程数 private volatile RejectedExecutionHandler handler; //任务拒绝策略 private volatile ThreadFactory threadFactory; //线程工厂，用来创建线程 private int largestPoolSize; //用来记录线程池中曾经出现过的最大线程数 private long completedTaskCount; //用来记录已经执行完毕的任务个数 /** * Wait condition to support awaitTermination */private final Condition termination = mainLock.newCondition(); //线程等待时的关闭的条件/* The context to be used when executing the finalizer, or null. */private final AccessControlContext acc; // 执行任务完成后使用的内容，或者为null largestPoolSize只是一个用来起记录作用的变量，用来记录线程池中曾经有过的最大线程数目，跟线程池的容量没有任何关系。 线程池线程一般正常工作的时候最大线程数为corePoolSize，当任务数量大于corePoolSize的时候，任务就进入等待的队列中，不继续增加线程；当等待队列也放满的时候，不能再往里面装任务的时候，这个时候就需要重新开辟新的线程，来工作了，并且数量要小于maximumPoolSize；如果大于maximumPoolSize，就调用handler方法。 执行任务 execute使用AbstractExecuorService中的submit 方法，可以执行新的进程，当然submit，最终执行的是execute方法，在ThreadPoolExecutor类中实现了excute方法； 重点研究exexute 方法的实现，这个有点难，网上介绍1.6里面的源码中execute方法已经和我这个1.8版本有很大出入了，大致上应该没有偏离：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * Executes the given task sometime in the future. The task * may execute in a new thread or in an existing pooled thread. * * If the task cannot be submitted for execution, either because this * executor has been shutdown or because its capacity has been reached, * the task is handled by the current &#123;@code RejectedExecutionHandler&#125;. * * @param command the task to execute * @throws RejectedExecutionException at discretion of * &#123;@code RejectedExecutionHandler&#125;, if the task * cannot be accepted for execution * @throws NullPointerException if &#123;@code command&#125; is null */ public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn't, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command); &#125; 执行流程就是： 判断提交的任务command是否为null，若是null，则抛出空指针异常； 第二步 ct1.get()；用这个workerCountOf( ct1.get()) 计算线程池已经使用多少线程； 当使用的线程数小于核心线程数（corePoolSize），进入addWorker 方法中，这里就是开始进程的地方，进入到最重要的地方，为了这一步不要跳得太远，还是接着看execute方法，后面再看addWorker方法； 当使用的线程数不小于核心线程数（corePoolSize），新来得任务就要进入等待执行的状态；if (isRunning(c) &amp;&amp; workQueue.offer(command)) 检查线程是否在running 状态和任务是否能够成功进入等待排队 ；4.1. 进入队列后，重新检查任务，如果线程池状态不是running状态， ，将回滚任务，拒绝执行任务，这样做主要是因为任务如果还在缓存队列等待的过程中，线程池中断了，就回滚任务，为了安全。4.2. 如果线程中的线程数为0 了，创建一个空线程。 当使用的线程数不小于核心线程数（corePoolSize）的时候，并且添加进入到缓存队列失败后，就会执行else if (!addWorker(command, false))reject(command); 这段代码，意思就是直接开辟一个新的线程去行这个任务，如果执行失败，拒绝策略进行处理这个任务，当然，如果当前线程池中的线程数目达到maximumPoolSize，addWorker方法中也会采取任务拒绝策略进行处理。 addWorker 创建线程下面将是阅读addWorker的源码，研究线程池怎么添加一个任务的。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192/** * Checks if a new worker can be added with respect to current * pool state and the given bound (either core or maximum). If so, * the worker count is adjusted accordingly, and, if possible, a * new worker is created and started, running firstTask as its * first task. This method returns false if the pool is stopped or * eligible to shut down. It also returns false if the thread * factory fails to create a thread when asked. If the thread * creation fails, either due to the thread factory returning * null, or due to an exception (typically OutOfMemoryError in * Thread.start()), we roll back cleanly. * * @param firstTask the task the new thread should run first (or * null if none). Workers are created with an initial first task * (in method execute()) to bypass queuing when there are fewer * than corePoolSize threads (in which case we always start one), * or when the queue is full (in which case we must bypass queue). * Initially idle threads are usually created via * prestartCoreThread or to replace other dying workers. * * @param core if true use corePoolSize as bound, else * maximumPoolSize. (A boolean indicator is used here rather than a * value to ensure reads of fresh values after checking other pool * state). * @return true if successful */private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; //创建一个线程 if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; //当任务成功添加到线程池，去执行它，改变标志符号。 t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; 看代码注释知道了第二个参数core的意义，当它为true的时候 使用的是线程核心数中的线程，当它为false 的时候，使用的是数量是maximumPoolSize，就是当缓存中的队列也排满的时候。 因此，调用这个 addWorker方法有4种传参的方式：1234addWorker(command, true);addWorker(command, false);addWorker(null, false);addWorker(null, true); 第一个：线程数小于corePoolSize时，放一个需要处理的task进worker set。如果worker set长度超过corePoolSize，就返回false。 第二个：当队列被放满时，就尝试将这个新来的task直接放入worker set，而此时worker set 的长度限制是maximumPoolSize。如果线程池也满了的话就返回false。 第三个：放入一个空的task进set，比较的的长度限制是maximumPoolSize。这样一个task为空的worker在线程执行的时候会判断出后去任务队列里拿任务，这样就相当于世创建了一个新的线程，只是没有马上分配任务。 第四个：这个方法就是放一个null的task进set，而且是在小于corePoolSize时。实际使用中是在 prestartCoreThread() 方法。这个方法用来为线程池先启动一个worker等待在那边，如果此时set中的数量已经达到corePoolSize那就返回false，什么也不干。还有是 prestartAllCoreThreads() 方法，准备corePoolSize个worker，初始化线程池中的线程。默认情况下，创建线程池之后，线程池中是没有线程的，需要提交任务之后才会创建线程。在实际中如果需要线程池创建之后立即创建线程，可以通过以下两个方法办到：12prestartCoreThread()：初始化一个核心线程；prestartAllCoreThreads()：初始化所有核心线程 前面代码的意思就是验证线程池的状态是不是在RUNNING状态，并且判断，线程数是不是超过了maximumPoolSize，如果超过了最大线程数量，直接返回false，就回到execute 方法最后个if else()代码块中，拒绝任务。 Worker 中主要实现Worker 这个类很简单，只是继承了一个Runnable接口，然后在run()方法中去执行我们传入的firstTask 主要是其中的run 方法，它的run方法调用的是runWorker：12345678910111213141516171819202122232425262728293031323334353637383940414243final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; 注意当没有可执行的任务的时候，执行getTask()方法：1234567891011121314151617181920212223242526272829303132333435363738private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; //判断线程状态和缓存队列中的线程是否为空 decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // Are workers subject to culling? boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; //也就是说如果线程池处于STOP状态、或者任务队列已为空或者允许为核心池线程设置空闲存活时间并且线程数大于1时，允许worker退出。 if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125;&#125; 这个时候看到了，它原来去缓存队列中去取任务，来执行。 并且下面代码块做的任务，作者已经给出注释了123// Recheck while holding lock.// Back out on ThreadFactory failure or if// shut down before lock acquired. 很容易理解了这段代码。 怎么样开启线程池，并且添加一个任务就到此结束了。 任务拒绝策略当线程池的任务缓存队列已满并且线程池中的线程数目达到maximumPoolSize，如果还有任务到来就会采取任务拒绝策略，通常有以下四种策略：1234ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 任务缓存队列及排队策略workQueue，任务缓存队列，用来存放等待执行的任务；一个阻塞队列BlockingQueue，用来存储等待执行的任务，这个参数的选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列有以下几种选择：12345ArrayBlockingQueue; // 基于数组的阻塞队列实现，此队列创建时必须指定大小；LinkedBlockingQueue; // 基于链表的阻塞队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE；SynchronousQueue; //一种无缓冲的等待队列，它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务。DelayQueue； // 队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞。PriorityBlockingQueue // 基于优先级的阻塞队列 线程池关闭ThreadPoolExecutor提供了两个方法，用于线程池的关闭，分别是shutdown()和shutdownNow()，其中： shutdown()：不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务； shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务。 创建线程池并且使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.wuwii.test;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.BlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;/** * @author Zhang Kai * @version 1.0 * @since &lt;pre&gt;2017/11/1 11:08&lt;/pre&gt; */public class TestPool &#123; private static final BlockingQueue queue = new ArrayBlockingQueue(5); private static final ThreadPoolExecutor executor = new ThreadPoolExecutor(5, 10, 200, TimeUnit.MILLISECONDS, queue); public static void main(String[] args) &#123; ThreadPoolExecutor executor = TestPool.executor; for (int i = 0; i &lt; 15; i++) &#123; MyTask myTask = new MyTask(i); executor.execute(myTask); System.out.println("线程池中线程数目：" + executor.getPoolSize() + "，缓存队列中等待执行的任务数目：" + executor.getQueue().size() + "，已执行完的任务数目：" + executor.getCompletedTaskCount()); &#125; executor.shutdown(); &#125;&#125;class MyTask implements Runnable &#123; private int taskNum; public MyTask(int num) &#123; this.taskNum = num; &#125; @Override public void run() &#123; System.out.println("正在执行task " + taskNum); try &#123; Thread.currentThread().sleep(4000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("task " + taskNum + "执行完毕"); &#125;&#125; 执行结果：123456789101112131415161718192021222324252627282930313233343536373839404142434445正在执行task 0线程池中线程数目：1，缓存队列中等待执行的任务数目：0，已执行完的任务数目：0线程池中线程数目：2，缓存队列中等待执行的任务数目：0，已执行完的任务数目：0线程池中线程数目：3，缓存队列中等待执行的任务数目：0，已执行完的任务数目：0正在执行task 1线程池中线程数目：4，缓存队列中等待执行的任务数目：0，已执行完的任务数目：0正在执行task 2正在执行task 3线程池中线程数目：5，缓存队列中等待执行的任务数目：0，已执行完的任务数目：0正在执行task 4线程池中线程数目：5，缓存队列中等待执行的任务数目：1，已执行完的任务数目：0线程池中线程数目：5，缓存队列中等待执行的任务数目：2，已执行完的任务数目：0线程池中线程数目：5，缓存队列中等待执行的任务数目：3，已执行完的任务数目：0线程池中线程数目：5，缓存队列中等待执行的任务数目：4，已执行完的任务数目：0线程池中线程数目：5，缓存队列中等待执行的任务数目：5，已执行完的任务数目：0线程池中线程数目：6，缓存队列中等待执行的任务数目：5，已执行完的任务数目：0线程池中线程数目：7，缓存队列中等待执行的任务数目：5，已执行完的任务数目：0正在执行task 10线程池中线程数目：8，缓存队列中等待执行的任务数目：5，已执行完的任务数目：0正在执行task 11正在执行task 12线程池中线程数目：9，缓存队列中等待执行的任务数目：5，已执行完的任务数目：0正在执行task 13线程池中线程数目：10，缓存队列中等待执行的任务数目：5，已执行完的任务数目：0正在执行task 14task 0执行完毕task 2执行完毕task 1执行完毕正在执行task 7task 3执行完毕正在执行task 8正在执行task 6正在执行task 5task 4执行完毕task 10执行完毕task 11执行完毕task 14执行完毕task 12执行完毕task 13执行完毕正在执行task 9task 7执行完毕task 6执行完毕task 5执行完毕task 8执行完毕task 9执行完毕 从上面的结果可以看出来，当线程池中线程的数目大于5时，便将任务放入任务缓存队列里面，当任务缓存队列满了之后，便创建新的线程。如果上面程序中，将for循环中改成执行20个任务，就会抛出任务拒绝异常了。 例外创建线程的时候建议使用的时Executors类提供的方法来创建线程池：1234Executors.newCachedThreadPool(); //创建一个缓冲池，缓冲池容量大小为Integer.MAX_VALUEExecutors.newSingleThreadExecutor(); //创建容量为1的缓冲池Executors.newFixedThreadPool(int corePoolSize); //创建固定容量大小的缓冲池，缓存队列大小为Integer.MAX_VALUEExecutors.newScheduledThreadPool(int corePoolSize) //创建一个最大容量为Integer.MAX_VALUE的缓冲池，支持定时及周期性任务执行 配置线程池的大小一般需要根据任务的类型来配置线程池大小： 如果是CPU密集型任务，就需要尽量压榨CPU，参考值可以设为 NCPU+1； 如果是IO密集型任务，参考值可以设置为2*NCPU。 当然，这只是一个参考值，具体的设置还需要根据实际情况进行调整，比如可以先将线程池大小设置为参考值，再观察任务运行情况和系统负载、资源利用率来进行适当调整。 总结 当一个task被安排进来的时候，再确定不是空值后，直接判断在池中已经有工作的线程是否小于corePoolSize，小于则增加一个线程来负责这个task。 如果池中已经工作的线程大于等于corePoolSize，就向队列里存task，而不是继续增加线程。 当workQueue.offer失败时，也就是说task不能再向队列里放的时候，而此时工作线程大于等于corePoolSize，那么新进的task，就要新开一个线程来接待了。 线程池工作机制是这样： a.如果正在运行的线程数小于 corePoolSize，那就马上创建线程并运行这个任务，而不会进行排队。 b. 如果正在运行的线程数不小于 corePoolSize，那就把这个任务放入队列。 c. 如果队列满了，并且正在运行的线程数小于 maximumPoolSize，那么还是要创建线程并运行这个任务。 d.如果队列满了，并且正在运行的线程数不小于 maximumPoolSize，那么线程池就会调用handler里方法。(采用LinkedBlockingDeque就不会出现队列满情况)。 使用线程池的时候，需要注意先分配好线程池的大小，大约每个线程占用10M内存，就是空间换时间，如果控制的不好，会存在内存溢出的问题，导致机器宕机。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python的一些高级特性]]></title>
    <url>%2Fpython-features.html</url>
    <content type="text"><![CDATA[切片定义一个 seasions 列表 ，1&gt;&gt;&gt; seasions = [&apos;spring&apos;, &apos;summer&apos;, &apos;autumn&apos;, &apos;winter&apos;] 现在需要把前面两个元素放入到 列表 L中，正常想到就是 123&gt;&gt;&gt; L = [seasions[0], seasions[1]]&gt;&gt;&gt; L[&apos;spring&apos;, &apos;summer&apos;] 进阶一点就是循环取值：1234567&gt;&gt;&gt; L = []&gt;&gt;&gt; n = 2&gt;&gt;&gt; for i in range(n):... L.append(seasions[i])...&gt;&gt;&gt; L[&apos;spring&apos;, &apos;summer&apos;] 在python中提供了切片（Slice）操作符，简化了索引范围的操作：12&gt;&gt;&gt; seasions[0:2][&apos;spring&apos;, &apos;summer&apos;] 表示从索引为0 开始截取到索引到2 结束，但是不包括索引2的值。 并且第一个索引0，可以省略：12&gt;&gt;&gt; seasions[:2][&apos;spring&apos;, &apos;summer&apos;] 从索引1 开始，截取到索引3 的2个元素：12&gt;&gt;&gt; seasions[1:3][&apos;summer&apos;, &apos;autumn&apos;] 支持省略第二个参数，截取到结束，从第三个开始截取到结束：12&gt;&gt;&gt; seasions[2:][&apos;autumn&apos;, &apos;winter&apos;] Python支持L[-1]取倒数第一个元素，那么它同样支持倒数切片：123456&gt;&gt;&gt; seasions[-1:][&apos;winter&apos;]&gt;&gt;&gt; seasions[-2:][&apos;autumn&apos;, &apos;winter&apos;]&gt;&gt;&gt; seasions[-3:][&apos;summer&apos;, &apos;autumn&apos;, &apos;winter&apos;] 操作（0，99）的数组：12345678910111213141516171819&gt;&gt;&gt; l = list(range(100))&gt;&gt;&gt; l[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]&gt;&gt;&gt; l[:10][0, 1, 2, 3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt; l[-10:][90, 91, 92, 93, 94, 95, 96, 97, 98, 99]&gt;&gt;&gt; l[50:60][50, 51, 52, 53, 54, 55, 56, 57, 58, 59]&gt;&gt;&gt; l[50:60:2][50, 52, 54, 56, 58]&gt;&gt;&gt; l[::10][0, 10, 20, 30, 40, 50, 60, 70, 80, 90]&gt;&gt;&gt; l[:][0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] 第三个参数是每隔几个元素取出一个值。 l[:]复制这个数组。 字符串也支持切片操作： 12345&gt;&gt;&gt; s = &apos;asdfg&apos;&gt;&gt;&gt; s[:2]&apos;as&apos;&gt;&gt;&gt; s[-5::2]&apos;adg&apos; 迭代迭代一个list1234567&gt;&gt;&gt; for i in seasions:... print(i)...springsummerautumnwinter 迭代一个dict1234567&gt;&gt;&gt; d = &#123;&apos;a&apos;: 1, &apos;b&apos;: 2, &apos;c&apos;: 3&#125;&gt;&gt;&gt; for key in d:... print(key)...acb 默认情况下，dict迭代的是key。如果要迭代value，可以用for value in d.values()，如果要同时迭代key和value，可以用for k, v in d.items()。 迭代一个字符串12345678&gt;&gt;&gt; for i in s:... print(i)...asdfg 迭代二维数组123456&gt;&gt;&gt; for x, y in [(1, 1), (2, 4), (3, 9)]:... print(x, y)...1 12 43 9 列表生成式列表生成式即List Comprehensions，是Python内置的非常简单却强大的可以用来创建list的生成式。 生成list [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:12&gt;&gt;&gt; list(range(1, 11))[1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 如果要生成[1x1, 2x2, 3x3, …, 10x10]12&gt;&gt;&gt; [x * x for x in range(1, 11)][1, 4, 9, 16, 25, 36, 49, 64, 81, 100] for循环后面还可以加上if判断，12&gt;&gt;&gt; [x * x for x in range(1, 11) if x % 2 == 0][4, 16, 36, 64, 100] 还可以使用两层循环，可以生成全排列：12&gt;&gt;&gt; [m + n for m in &apos;ABC&apos; for n in &apos;XYZ&apos;][&apos;AX&apos;, &apos;AY&apos;, &apos;AZ&apos;, &apos;BX&apos;, &apos;BY&apos;, &apos;BZ&apos;, &apos;CX&apos;, &apos;CY&apos;, &apos;CZ&apos;] for循环其实可以同时使用两个甚至多个变量，比如dict的items()可以同时迭代key和value：1234567&gt;&gt;&gt; d = &#123;&apos;x&apos;: &apos;A&apos;, &apos;y&apos;: &apos;B&apos;, &apos;z&apos;: &apos;C&apos; &#125;&gt;&gt;&gt; for k, v in d.items():... print(k, &apos;=&apos;, v)...y = Bx = Az = C 使用列表生成式，简化生成一行：123&gt;&gt;&gt; d = &#123;&apos;x&apos;: &apos;A&apos;, &apos;y&apos;: &apos;B&apos;, &apos;z&apos;: &apos;C&apos; &#125;&gt;&gt;&gt; [k + &apos;=&apos; + v for k, v in d.items()][&apos;y=B&apos;, &apos;x=A&apos;, &apos;z=C&apos;] 把一个list中所有的字符串变成大写：12&gt;&gt;&gt; [s.upper() for s in seasions][&apos;SPRING&apos;, &apos;SUMMER&apos;, &apos;AUTUMN&apos;, &apos;WINTER&apos;] 一个既有字符串又有整数的list ，怎么将它的字符串都变成小写，因为整数类型没有lower方法，直接调用会报错：在列表生成式的循环后面加上if 判断isinstance(s, str)，判断是否是需要的类型。123&gt;&gt;&gt; L = [&apos;Hello&apos;, &apos;World&apos;, 18, &apos;Apple&apos;, None]&gt;&gt;&gt; [s.lower() for s in L if isinstance(s, str)][&apos;hello&apos;, &apos;world&apos;, &apos;apple&apos;]]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python学习之路</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python中函数]]></title>
    <url>%2Fpython-function.html</url>
    <content type="text"><![CDATA[python 中内置函数python 中有很多内置函数，参考网站 http://docs.python.org/3/library/functions.html 在调用函数的时候，如果参数数量传入错误，会报错TypeError。 123456&gt;&gt;&gt; abs(-2)2&gt;&gt;&gt; abs(-2, 3)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: abs() takes exactly one argument (2 given) 在调用abs 函数的时候传入两个参数，会报错TypeError，直接提示，abs() 只能有一个参数。 如果传入的参数数量是对的，但参数类型不能被函数所接受，也会报TypeError的错误，并且给出错误信息：str是错误的参数类型： 1234&gt;&gt;&gt; abs(&apos;a&apos;)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: bad operand type for abs(): &apos;str&apos; 数据类型转换python 中内置函数包括数据类型转换。12345678&gt;&gt;&gt; int(3.21)3&gt;&gt;&gt; int(&apos;3&apos;)3&gt;&gt;&gt; int(&apos;3.21&apos;)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;ValueError: invalid literal for int() with base 10: &apos;3.21&apos; 注意的是int()没有做这个转换了字符串成float再转int，直接会报错无效参数。只能这样转了：12&gt;&gt;&gt; int(float(&apos;3.21&apos;))3 任何类型都可以转成str：12345678910&gt;&gt;&gt; str(True)&apos;True&apos;&gt;&gt;&gt; str(False)&apos;False&apos;&gt;&gt;&gt; str(321)&apos;321&apos;&gt;&gt;&gt; str([21,34,2])&apos;[21, 34, 2]&apos;&gt;&gt;&gt; str(&#123;&quot;a&quot;:21, &quot;b&quot;:(1, 2)&#125;)&quot;&#123;&apos;a&apos;: 21, &apos;b&apos;: (1, 2)&#125;&quot; 可以将一个变量赋值为一个函数名：123&gt;&gt;&gt; a = int&gt;&gt;&gt; a(&apos;2&apos;)2 定义函数在Python中，定义一个函数要使用def语句，依次写出函数名、括号、括号中的参数和冒号:，然后，在缩进块中编写函数体，函数的返回值用return语句返回。 写一个根据月份返回季节的函数：1234567891011121314# 根据月份返回季节def get_seasion_by_month(month): if not isinstance(month, int): raise TypeError('bad operand type') if 2 &lt;= month &lt;= 4: return 'spring' elif 5 &lt;= month &lt;= 7: return 'summer' elif 8 &lt;= month &lt;= 10: return 'autumn' elif 11 &lt;= month &lt;= 12 or month == 1: return 'winter' else: return 'invalid “month” value!' 使用python 解释器运行我们自定义的函数的时候，需要引入我们的方法：1234&gt;&gt;&gt; from test import get_seasion_by_month&gt;&gt;&gt; get_seasion_by_month(10)&apos;autumn&apos;&gt;&gt;&gt; 引入了自定义的方法就可以调用了：1234567891011&gt;&gt;&gt; get_seasion_by_month(10)&apos;autumn&apos;&gt;&gt;&gt; get_seasion_by_month(&apos;10&apos;)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; File &quot;F:\JAVA-program\rywis-fastdfs\rywis-fastdfs\learn\test.py&quot;, line 3, in get_seasion_by_month raise TypeError(&apos;bad operand type&apos;)TypeError: bad operand type&gt;&gt;&gt; get_seasion_by_month(13)&apos;invalid “month” value!&apos;&gt;&gt;&gt; 第一步：输入月份10 ，返回autumn，符合预期。 第二步：输入字符串“10”，返回我预先设置TypeError错误信息bad operand type，因为我设置了参数类型为 int，不能使用其他的类型，符合期望。 第三步：输入13 ，返回无效字符串的提示。 返回多个值写一个返回矩形周长和面积的函数：123456789# 获取矩形的周长和面积def rectangle_perimeter_area(width, height): if not isinstance(width, (int, float)): raise TypeError('"width" is bad operand type') if not isinstance(height, (int, float)): raise TypeError('"height" is bad operand type') perimeter = 2 * (width + height) area = width * height return perimeter, area 使用解释器 运行它：1234&gt;&gt;&gt; from test import rectangle_perimeter_area&gt;&gt;&gt; rectangle_perimeter_area(4, 6)(20, 24)&gt;&gt;&gt; 可以看出来，它返回的是一个tuple 数组。 参数检查上面写的函数中，写了一个参数类型的检查：12if not isinstance(month, int): raise TypeError(&apos;bad operand type&apos;) 可以控制参数的类型，错误参数类型制定它抛出错误。 函数参数python 中函数参数有多种写法。 函数的默认参数值写一个打印个人信息的函数：123def person(name, age): print('name:' + name) print('age:' + age) 打印姓名，年龄。123&gt;&gt;&gt; person(&apos;wuwii&apos;, &apos;23&apos;)name:wuwiiage:23 现在需要个人信息要加入city 这一项信息，如果直接加入一个参数city 导致之前使用这个函数的方法都需要重新改，因为python 一个函数名只能有一个，不像java那样重载函数，这个时候就需要默认参数了，12345def person(name, age, city='WuHan'): print('name:' + name) print('age:' + age) print('city:' + city) 现在执行这个函数：12345678&gt;&gt;&gt; person(&apos;wuwii&apos;, &apos;23&apos;)name:wuwiiage:23city:WuHan&gt;&gt;&gt; person(&apos;wuwii&apos;, &apos;23&apos;, &apos;HuangGang&apos;)name:wuwiiage:23city:HuangGang 当不输入参数city的时候，函数使用的默认参数，如果传入city参数，将使用输入的参数。 当默认参数是一个可变对象默认参数有一个特例，就是，参数默认值是一个可变对象的时候，123def add_end(L=[]): L.append('END') return L 正常调用不会有问题：1234&gt;&gt;&gt; add_end([1, 2, 3])[1, 2, 3, &apos;END&apos;]&gt;&gt;&gt; add_end([&apos;x&apos;, &apos;y&apos;, &apos;z&apos;])[&apos;x&apos;, &apos;y&apos;, &apos;z&apos;, &apos;END&apos;] 当使用默认参数的时候：123456&gt;&gt;&gt; add_end()[&apos;END&apos;]&gt;&gt;&gt; add_end()[&apos;END&apos;, &apos;END&apos;]&gt;&gt;&gt; add_end()[&apos;END&apos;, &apos;END&apos;, &apos;END&apos;] 原因：Python函数在定义的时候，默认参数L的值就被计算出来了，即[]，因为默认参数L也是一个变量，它指向对象[]，每次调用该函数，如果改变了L的内容，则下次调用时，默认参数的内容就变了，不再是函数定义时的[]了。 所以一般的时候，都使用不可变的对象作为默认参数，可以尽量避免这种问题。 这个问题的解决就是，调用默认的函数的时候，初始化可变的参数就行了。12345def add_end(L=None): if L is None: L = [] L.append('END') return L 现在就不会有问题了：1234&gt;&gt;&gt; add_end()[&apos;END&apos;]&gt;&gt;&gt; add_end()[&apos;END&apos;] 可变参数在Python函数中，还可以定义可变参数。顾名思义，可变参数就是传入的参数个数是可变的，可以是1个、2个到任意个，还可以是0个。 所以Python允许你在list或tuple前面加一个*号，把list或tuple的元素变成可变参数传进去：123def person_one(*args): for value in args: print('值为：' + value) 测试：1234&gt;&gt;&gt; person_one(&apos;wuwii&apos;, &apos;23&apos;, &apos;Wuhan&apos;)值为：wuwii值为：23值为：Wuhan 在参数实在很多的时候，这样直接输入参数调用函数很不美观，可以直接将参数放在list或者tuple中，只要在函数调用参数前面加个a:12345&gt;&gt;&gt; a = [&apos;wuwii&apos;, &apos;23&apos;, &apos;WuHan&apos;]&gt;&gt;&gt; person_one(*a)值为：wuwii值为：23值为：WuHan *a表示将list a当作函数person_one的参数。 关键字参数关键字参数有什么用？它可以扩展函数的功能。比如，在person函数里，我们保证能接收到name和age这两个参数，但是，如果调用者愿意提供更多的参数，我们也能收到。试想你正在做一个用户注册的功能，除了用户名和年龄是必填项外，其他都是可选项，利用关键字参数来定义这个函数就能满足注册的需求。 1234def person_two(**kw): print('name:' + kw['name']) print('age:' + kw['age']) print('city:' + kw['city']) 执行结果:12345&gt;&gt;&gt; person_two(name=&apos;wuwii&apos;, age=&apos;23&apos;, city=&apos;WuHan&apos;)name:wuwiiage:23city:WuHan&gt;&gt;&gt; 命名关键字参数如果要限制关键字参数的名字，就可以用命名关键字参数，例如，只接收city和job作为关键字参数。 如果函数定义中已经有了一个可变参数，后面跟着的命名关键字参数就不再需要一个特殊分隔符*了：12def person(name, age, *, city, job): print(name, age, city, job) 和关键字参数**kw不同，命名关键字参数需要一个特殊分隔符*，*后面的参数被视为命名关键字参数。 调用方式如下：12&gt;&gt;&gt; person(&apos;Jack&apos;, 24, city=&apos;Beijing&apos;, job=&apos;Engineer&apos;)Jack 24 Beijing Engineer 如果函数定义中已经有了一个可变参数，后面跟着的命名关键字参数就不再需要一个特殊分隔符*了:12def person(name, age, *args, city, job): print(name, age, args, city, job) 命名关键字参数必须传入参数名，这和位置参数不同。如果没有传入参数名，调用将报错：1234&gt;&gt;&gt; person(&apos;Jack&apos;, 24, &apos;Beijing&apos;, &apos;Engineer&apos;)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: person() takes 2 positional arguments but 4 were given 由于调用时缺少参数名city和job，Python解释器把这4个参数均视为位置参数，但person()函数仅接受2个位置参数。 命名关键字参数可以有缺省值，从而简化调用： 12def person(name, age, *, city='Beijing', job): print(name, age, city, job) 由于命名关键字参数city具有默认值，调用时，可不传入city参数：12&gt;&gt;&gt; person(&apos;Jack&apos;, 24, job=&apos;Engineer&apos;)Jack 24 Beijing Engineer 参数组合在Python中定义函数，可以用必选参数、默认参数、可变参数、关键字参数和命名关键字参数，这5种参数都可以组合使用。但是请注意，参数定义的顺序必须是：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。 12def f2(a, b, c=0, *, d, **kw): print('a =', a, 'b =', b, 'c =', c, 'd =', d, 'kw =', kw) 最神奇的是通过一个tuple和dict，你也可以调用上述函数：12345678&gt;&gt;&gt; args = (1, 2, 3, 4)&gt;&gt;&gt; kw = &#123;&apos;d&apos;: 99, &apos;x&apos;: &apos;#&apos;&#125;&gt;&gt;&gt; f1(*args, **kw)a = 1 b = 2 c = 3 args = (4,) kw = &#123;&apos;d&apos;: 99, &apos;x&apos;: &apos;#&apos;&#125;&gt;&gt;&gt; args = (1, 2, 3)&gt;&gt;&gt; kw = &#123;&apos;d&apos;: 88, &apos;x&apos;: &apos;#&apos;&#125;&gt;&gt;&gt; f2(*args, **kw)a = 1 b = 2 c = 3 d = 88 kw = &#123;&apos;x&apos;: &apos;#&apos;&#125; 所以，对于任意函数，都可以通过类似func(*args, **kw)的形式调用它，无论它的参数是如何定义的。 空函数有时候，我们写一个函数，暂时不知道怎么处理，但是在python中，什么语法都不写的话，会报错；写一个空函数：12def blank(): pass 这样代码就可以正常跑起来了。 递归函数写一个一个阶乘函数：1234def fact(n): if n==1: return 1 return n * fact(n - 1) 执行：1234&gt;&gt;&gt; fact(1)1&gt;&gt;&gt; fact(5)120 总结 定义函数时，需要确定函数名和参数个数； 如果有必要，可以先对参数的数据类型做检查； 函数体内部可以用return随时返回函数结果； 行完毕也没有return语句时，自动return None。 以同时返回多个值，但其实就是一个tuple。 要注意定义可变参数和关键字参数的语法：6.1. *args是可变参数，args接收的是一个tuple；6.2. **kw是关键字参数，kw接收的是一个dict。 默认参数一定要用不可变对象，如果是可变对象，程序运行时会有逻辑错误！ 参数定义的顺序必须是：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。 定义命名的关键字参数在没有可变参数的情况下不要忘了写分隔符*，否则定义的将是位置参数。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python学习之路</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最想的人是你，最不想打扰的也是你]]></title>
    <url>%2Fdonot-trouble.html</url>
    <content type="text"><![CDATA[今天是周日，本来一直想着的是她还欠我一餐饭，什么时候能给我，虽然我要不是一餐饭，只是想去见见她，但是想到最近打扰她的时候，没怎么想和我聊天了；我这个人就是这么的多想的吧，感觉是太打扰到了你了，我想的也是很可笑的很啊，我是个这么慢热的人，平时根本不愿意多说话的人，哪怕是一句晚安，现在，感觉多说了几年的话。在想以后是不是要少活好多年了。 忍不住下午，还是去她的学校了，但是还是忍住了没去打扰她，我想我这个人很烦人的吧，还是把愉快的周末留给她自己，不要去打扰了，随便在学校逛了逛，就忍不住的逃离了，其实我的内心还是有些害怕的，真是像个做了亏心事的小偷啊，我这个人这个毛病看来今生没希望改过来了，搞不好要单一辈子了。但是我真的感觉做不到，她总是很忙的样子，实在是怕做错了什么，导致朋友也做不成，我这个人就是适合想念吧，不要把我一点想念的空间也给剥夺了，也不想让她知道我在这里，在这里关心她。 感觉我这个是有点作了吧，很认真的想去吸引她，关心她。也有过动摇，但是还是在想她，还是执念让我坚持吧，不是坚持，给她发的消息，人很开心，等着也高兴，就像是做了什么有意义的事情了，但是有时候也很犹豫，怕她要是在忙了，打扰到了别人，该多不好，人总是有点自私的，说不打扰，我就不去打扰啊，时刻多看两个笑话，给她发过去，要是能到到回应就很好了，然而很多时候没有，我想可能是打扰到她了吧，可能她不是那么喜欢看笑话啊，我也不知道她喜欢着什么吧，虽然很费劲，但是不能给她制造不开心得事情，所以时刻都得忍着点吧。 乐此不疲的去做些事情吧，可能我跟她之间还没开始过，就存在了太多的空白格，不太可能填补上，但是总是想试一试，不管是不甘还是执念吧，我只是关心，不放心的是她。 现在我想可能真的打扰到了，一次次打扰只会消耗一个人的热情，最好的就是舍不得打扰了，未来要做的就是要改掉这个坏毛病。 想，却不去打扰；念，却不去纠缠；只为祝福和守候。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python中集合列表和dict、set]]></title>
    <url>%2Fpython-list.html</url>
    <content type="text"><![CDATA[列表pyhon 中有两种集合列表，一个是list，一个是tuple。 list展示四季：123&gt;&gt;&gt; seasions = [&apos;spring&apos;, &apos;summer&apos;, &apos;autumn&apos;, &apos;winter&apos;]&gt;&gt;&gt; seasions[&apos;spring&apos;, &apos;summer&apos;, &apos;autumn&apos;, &apos;winter&apos;] 得到list长度12&gt;&gt;&gt; len(seasions)4 索引访问：123456789101112131415161718192021222324&gt;&gt;&gt; seasions[0]&apos;spring&apos;&gt;&gt;&gt; seasions[1]&apos;summer&apos;&gt;&gt;&gt; seasions[2]&apos;autumn&apos;&gt;&gt;&gt; seasions[3]&apos;winter&apos;&gt;&gt;&gt; seasions[4]Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;IndexError: list index out of range&gt;&gt;&gt; seasions[-1]&apos;winter&apos;&gt;&gt;&gt; seasions[-2]&apos;autumn&apos;&gt;&gt;&gt; seasions[-3]&apos;summer&apos;&gt;&gt;&gt; seasions[-4]&apos;spring&apos;&gt;&gt;&gt; seasions[-5]Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;IndexError: list index out of range 可以看出索引是从0开始的，并且支持倒序索引，超出索引范围的话，会抛出错误IndexError: list index out of range。 list 是一个可变的有序列表，可以加入删除元素： 在尾部添加元素append(dom)：123&gt;&gt;&gt; seasions.append(&apos;once again&apos;)&gt;&gt;&gt; seasions[&apos;spring&apos;, &apos;summer&apos;, &apos;autumn&apos;, &apos;winter&apos;, &apos;once again&apos;] 要删除list末尾的元素，用pop()方法：1234&gt;&gt;&gt; seasions.pop()&apos;once again&apos;&gt;&gt;&gt; seasions[&apos;spring&apos;, &apos;summer&apos;, &apos;autumn&apos;, &apos;winter&apos;] 支持在任意位置插入一个元素，例：在第二个位置插入 “again” ：123456789&gt;&gt;&gt; seasions.insert(1, &apos;again&apos;)&gt;&gt;&gt; seasions[&apos;spring&apos;, &apos;again&apos;, &apos;summer&apos;, &apos;autumn&apos;, &apos;winter&apos;]&gt;&gt;&gt; seasions.insert(10, &apos;again&apos;)&gt;&gt;&gt; seasions[&apos;spring&apos;, &apos;again&apos;, &apos;summer&apos;, &apos;autumn&apos;, &apos;winter&apos;, &apos;again&apos;]&gt;&gt;&gt; seasions.insert(-10, &apos;again&apos;)&gt;&gt;&gt; seasions[&apos;again&apos;, &apos;spring&apos;, &apos;again&apos;, &apos;summer&apos;, &apos;autumn&apos;, &apos;winter&apos;, &apos;again&apos;, &apos;again&apos;] 可以看出，超出索引范围会加在末尾位置，如果索引是负数的话，则在列表头插入。 也可以删除指定位置的元素删除索引位置为1 的元素123456&gt;&gt;&gt; seasions.pop(10)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;IndexError: pop index out of range&gt;&gt;&gt; seasions.pop(0)&apos;again&apos; 修改列表中指定位置的元素的值将索引为 1 的 ‘again’ 改为 True：12345&gt;&gt;&gt; seasions[&apos;spring&apos;, &apos;again&apos;, &apos;summer&apos;, &apos;autumn&apos;, &apos;winter&apos;, &apos;again&apos;, &apos;again&apos;]&gt;&gt;&gt; seasions[1] = &apos;once&apos;&gt;&gt;&gt; seasions[&apos;spring&apos;, True, &apos;summer&apos;, &apos;autumn&apos;, &apos;winter&apos;, &apos;again&apos;, &apos;again&apos;] python 中列表中可以同时存任何类型的数据：12345&gt;&gt;&gt; seasions[&apos;spring&apos;, &apos;once&apos;, &apos;summer&apos;, &apos;autumn&apos;, &apos;winter&apos;, &apos;again&apos;, &apos;again&apos;]&gt;&gt;&gt; seasions.insert(1, [&apos;heart&apos;, &apos;warm&apos;])&gt;&gt;&gt; seasions[&apos;spring&apos;, [&apos;heart&apos;, &apos;warm&apos;], &apos;once&apos;, &apos;summer&apos;, &apos;autumn&apos;, &apos;winter&apos;, &apos;again&apos;, &apos;again&apos;] tuple另一种有序列表叫元组：tuple。tuple和list非常类似，但是tuple一旦初始化就不能修改： 123&gt;&gt;&gt; seasions = (&apos;spring&apos;, &apos;summer&apos;, &apos;autumn&apos;, &apos;winter&apos;)&gt;&gt;&gt; seasions(&apos;spring&apos;, &apos;summer&apos;, &apos;autumn&apos;, &apos;winter&apos;) tuple 是不可变的，定义下来就能修改它的值，但是可以取出它的值。12&gt;&gt;&gt; seasions[1]&apos;summer&apos; 定义一个空的 tuple123&gt;&gt;&gt; emptyTuple = ()&gt;&gt;&gt; emptyTuple() 需要注意的是定义一个只有一个元素的 tuple 列表123&gt;&gt;&gt; t = (1)&gt;&gt;&gt; t1 定义的不是tuple，是1这个数！这是因为括号()既可以表示tuple，又可以表示数学公式中的小括号，这就产生了歧义，因此，Python规定，这种情况下，按小括号进行计算，计算结果自然是1。 所以，只有1个元素的tuple定义时必须加一个逗号,，来消除歧义： 123&gt;&gt;&gt; t = (1,)&gt;&gt;&gt; t(1,) 当 tuple 列表中有一个 引用类型的时候： 1234567&gt;&gt;&gt; l = [&apos;wuwii&apos;, &apos;trees&apos;]&gt;&gt;&gt; seasions = (&apos;spring&apos;, l)&gt;&gt;&gt; seasions(&apos;spring&apos;, [&apos;wuwii&apos;, &apos;trees&apos;])&gt;&gt;&gt; l.append(&apos;gentle&apos;)&gt;&gt;&gt; seasions(&apos;spring&apos;, [&apos;wuwii&apos;, &apos;trees&apos;, &apos;gentle&apos;]) 当list 引用的内容发生改变， tuple 的值看起来确实变了。 但其实变的不是tuple的元素，而是list的元素。tuple一开始指向的list并没有改成别的list，所以，tuple所谓的“不变”是说，tuple的每个元素，指向永远不变。即指向’a’，就不能改成指向’b’，指向一个list，就不能改成指向其他对象，但指向的这个list本身是可变的！ dictPython内置了字典：dict的支持，dict全称dictionary，在其他语言中也称为map，使用键-值（key-value）存储，具有极快的查找速度。 举个例子，假设要根据同学的名字查找对应的成绩，如果用list实现，需要两个list：12names = [&apos;Michael&apos;, &apos;Bob&apos;, &apos;Tracy&apos;]scores = [95, 75, 85] 给定一个名字，要查找对应的成绩，就先要在names中找到对应的位置，再从scores取出对应的成绩，list越长，耗时越长。 如果用dict实现，只需要一个“名字”-“成绩”的对照表，直接根据名字查找成绩，无论这个表有多大，查找速度都不会变慢。用Python写一个dict如下： 123&gt;&gt;&gt; d = &#123;&apos;Michael&apos;: 95, &apos;Bob&apos;: 75, &apos;Tracy&apos;: 85&#125;&gt;&gt;&gt; d[&apos;Michael&apos;]95 为什么dict查找速度这么快？因为dict的实现原理和查字典是一样的。假设字典包含了1万个汉字，我们要查某一个字，一个办法是把字典从第一页往后翻，直到找到我们想要的字为止，这种方法就是在list中查找元素的方法，list越大，查找越慢。 第二种方法是先在字典的索引表里（比如部首表）查这个字对应的页码，然后直接翻到该页，找到这个字。无论找哪个字，这种查找速度都非常快，不会随着字典大小的增加而变慢。 dict就是第二种实现方式，给定一个名字，比如’Michael’，dict在内部就可以直接计算出Michael对应的存放成绩的“页码”，也就是95这个数字存放的内存地址，直接取出来，所以速度非常快。 你可以猜到，这种key-value存储方式，在放进去的时候，必须根据key算出value的存放位置，这样，取的时候才能根据key直接拿到value。 修改value12345&gt;&gt;&gt; d[&apos;Michael&apos;]95&gt;&gt;&gt; d[&apos;Michael&apos;] = 100&gt;&gt;&gt; d[&apos;Michael&apos;]100 查找key取值的时候，如果 dict 中没有这个 key ，会报错：1234&gt;&gt;&gt; d[&apos;notget&apos;]Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;KeyError: &apos;notget&apos; 避免key不存在的错误，有两种办法： 通过in判断key是否存在：12&gt;&gt;&gt; &apos;notget&apos; in dFalse 可以看出它返回的是布尔值。 通过dict提供的get方法，如果key不存在，可以返回None，或者自己指定的value：12345&gt;&gt;&gt; d.get(&apos;notget&apos;)&gt;&gt;&gt; d.get(&apos;Michael&apos;)100&gt;&gt;&gt; d.get(&apos;Michael&apos;, 99)100 注意：返回None的时候Python的交互式命令行不显示结果。 删除KEY删除 ‘Michael’ ：1234&gt;&gt;&gt; d.pop(&apos;Michael&apos;)100&gt;&gt;&gt; d&#123;&apos;Bob&apos;: 75, &apos;Tracy&apos;: 85&#125; 请务必注意，dict内部存放的顺序和key放入的顺序是没有关系的。 dict 的key 值只能存放不可变的对象 这是因为dict根据key来计算value的存储位置，如果每次计算相同的key得出的结果不同，那dict内部就完全混乱了。这个通过key计算位置的算法称为哈希算法（Hash）。 要保证hash的正确性，作为key的对象就不能变。在Python中，字符串、整数等都是不可变的，因此，可以放心地作为key。而list是可变的，就不能作为key。 和list比较，dict有以下几个特点： 查找和插入的速度极快，不会随着key的增加而变慢； 需要占用大量的内存，内存浪费多。 而list相反： 查找和插入的时间随着元素的增加而增加； 占用空间小，浪费内存很少。 setset和dict类似，也是一组key的集合，但不存储value。由于key不能重复，所以，在set中，没有重复的key。 123&gt;&gt;&gt; s = set([1, 1, 2, 3])&gt;&gt;&gt; s&#123;1, 2, 3&#125; 虽然初始化给了两个1，但是存储到set 中只有一个1，没有重复的值。 add(key) 添加元素123456&gt;&gt;&gt; s.add(5)&gt;&gt;&gt; s&#123;1, 2, 3, 5&#125;&gt;&gt;&gt; s.add(3)&gt;&gt;&gt; s&#123;1, 2, 3, 5&#125; 可以添加key，重复的key 会被过滤。 remove(key) 删除元素12345&gt;&gt;&gt; s&#123;1, 2, 3, 5&#125;&gt;&gt;&gt; s.remove(5)&gt;&gt;&gt; s&#123;1, 2, 3&#125; 删除key，没有的key 会报错1234&gt;&gt;&gt; s.remove(4)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;KeyError: 4 set可以看成数学意义上的无序和无重复元素的集合，因此，两个set可以做数学意义上的交集、并集等操作： 12345&gt;&gt;&gt; s1 = set([1, 3, 4])&gt;&gt;&gt; s1 &amp; s&#123;1, 3&#125;&gt;&gt;&gt; s1 | s&#123;1, 2, 3, 4&#125; FAQ set和dict的唯一区别仅在于没有存储对应的value，但是，set的原理和dict一样，所以，同样不可以放入可变对象，因为无法判断两个可变对象是否相等，也就无法保证set内部“不会有重复元素”。 set()接收一个参数，就是list或tuple或者其他可迭代对象：12L = [x, y, z]s = set(L) 但是L中的元素x、y、z有任何一个可变set就会报错。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python学习之路</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows下调试Hadoop集群报错Failed to find winutils.exe]]></title>
    <url>%2Fhadoop-miss-winutils.html</url>
    <content type="text"><![CDATA[问题在windows 环境使用Java下调试远程虚拟机中的Hadoop集群报错，问题很奇怪，说是少了 winutils.exe 文件，而且少了HADOOP_HOME 的环境变量；我是部署在虚拟机CentOS 7 上的集群，难道Windows 上使用 它的Hadoop还需要自己安装环境，事实上，是真的。。 12345678910111213141516171819202122232425262728293031323334353637383940414210:17:34,377 DEBUG Shell:675 - Failed to find winutils.exejava.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems at org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:528) at org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:549) at org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:572) at org.apache.hadoop.util.Shell.&lt;clinit&gt;(Shell.java:669) at org.apache.hadoop.util.StringUtils.&lt;clinit&gt;(StringUtils.java:79) at org.apache.hadoop.fs.FileSystem$Cache$Key.&lt;init&gt;(FileSystem.java:2972) at org.apache.hadoop.fs.FileSystem$Cache$Key.&lt;init&gt;(FileSystem.java:2967) at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2829) at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:389) at com.devframe.util.HdfsUtils.mkdir(HdfsUtils.java:43) at com.devframe.util.HdfsUtilsTest.testMkdir(HdfsUtilsTest.java:32) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47) at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242) at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)Caused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. at org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:448) at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:419) at org.apache.hadoop.util.Shell.&lt;clinit&gt;(Shell.java:496) ... 31 more 寻找问题百度了下，找到了问题： Problems running Hadoop on Windows Hadoop requires native libraries on Windows to work properly -that includes to access the file:// filesystem, where Hadoop uses some Windows APIs to implement posix-like file access permissions. This is implemented in HADOOP.DLL and WINUTILS.EXE. In particular, %HADOOP_HOME%\BIN\WINUTILS.EXE must be locatable. If it is not, Hadoop or an application built on top of Hadoop will fail. How to fix a missing WINUTILS.EXE You can fix this problem in two ways Install a full native windows Hadoop version. The ASF does not currently (September 2015) release such a version; releases are available externally. Or: get the WINUTILS.EXE binary from a Hadoop redistribution. There is a repository of this for some Hadoop versions on github. Then Set the environment variable %HADOOP_HOME% to point to the directory above the BIN dir containing WINUTILS.EXE. Or: run the Java process with the system property hadoop.home.dir set to the home directory. Hadoop Wiki ——wiki.apache.org/hadoop/WindowsProblems 上面的意思是说Hadoop使用一些Windows api来实现文件访问。 必要 hadoop.DLL和WINUTILS.EXE，这两个文件。 还需要配置 % HADOOP_HOME %的环境变量，来定位 WINUTILS.EXE; 解决办法就是去上面它给的GitHub上 下载对应版本的 文件，将 adoop.DLL和WINUTILS.EXE 文件拷到本地 （Windows）的Hadoop 文件夹下的bin文件夹中。 解决问题在Windows 上配置本地Hadoop 环境本地安装Hadoop 将对应版本的 Hadoop 压缩包，拷一份到Windows 电脑的D盘中解压，我的是Hadoop2.8.1 版本的，将hadoop-2.8.1.tar.gz 解压完就是这样的： 然后将自己从上面引用地址 GitHub 中 下载对应版本的文件，将 hadoop.DLL和WINUTILS.EXE 拷贝到 bin 目录中。 修改 /etc/hadoop/hadoop-env.cmd 文件中1set JAVA_HOME=%JAVA_HOME% 为（修改成自己机器配置的JDK位置）1set JAVA_HOME=C:\Program Files\Java\jdk1.8.0_144 需要注意的是我这个配置还有个小问题，并不能成功使用Hadoop 命令。这个将在文章最后面讲出原因。 查看 /etc/hadoop/core-site.xml 中fs.default.name是不是的属性值是不是和服务器中一致。不一致需要改成一致。1234567891011&lt;configuration&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/root/hadoop/tmp&lt;/value&gt; &lt;description&gt;Abase for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://server1:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置Hadoop环境变量新增环境变量 HADOOP_HOME ，变量值为 D:\hadoop-2.8.1 环境变量Path 中新增 %HADOOP_HOME%\bin 配置本地Hosts需要在C:\Windows\System32\drivers\etc\hosts 文件配置 ip，例如：使用 HDFS 的时候我们机器的配置文件中的地址是：hdfs://server1:9000 ，但是本地电脑没配置Hosts 的话，找不到 server1 的机器。 新增我的三台机器的集群信息123192.168.19.185 server1192.168.19.184 server2192.168.19.199 server3 这样下来，再次本地（Windows）调试虚拟机中Hadoop 集群就不会出现开头的问题了。 最后说下中途说的那个问题我在 /etc/hadoop/hadoop-env.cmd 文件中 修改成这样的：1set JAVA_HOME=C:\Program Files\Java\jdk1.8.0_144 但是Windows 下的 CMD 或者PowerShell 并不能成功使用Hadoop 命令，会报错：123456PS C:\Users\server&gt; hadoop version系统找不到指定的路径。Error: JAVA_HOME is incorrectly set. Please update D:\hadoop-2.8.1\etc\hadoop\hadoop-env.cmd'-Xmx512m' 不是内部或外部命令，也不是可运行的程序或批处理文件。 报错，我们设置的JAVA_HOME 位置并不正确。 这个问题很奇怪，因为我的这个JDK 位置用过很多次了，可以肯定没问题。 在网上找到了问题所在，不过还是需要自己改。。 if your java environment path contains space, such as “C:\Program Files\java\xxxxx” , the word 《Program Files》 contains a space, so CMD can’t identificatethis is the right answer Program Files，就是这个我们安装软件默认的路径，有空格，CMD 不能识别它，导致我的位置失效了。所以设置路径的时候不能有空格。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python中基本数据类型]]></title>
    <url>%2Fpython-basic-type.html</url>
    <content type="text"><![CDATA[数据类型数据类型在数据结构中的定义是一个值的集合以及定义在这个值集上的一组操作。 计算机顾名思义就是可以做数学计算的机器，因此，计算机程序理所当然地可以处理各种数值。但是，计算机能处理的远不止数值，还可以处理文本、图形、音频、视频、网页等各种各样的数据，不同的数据，需要定义不同的数据类型。在Python中，能够直接处理的数据类型有以下几种： 整数Python可以处理任意大小的整数，当然包括负整数，在程序中的表示方法和数学上的写法一模一样，例如：1，100，-8080，0，等等。 浮点数浮点数也就是小数，之所以称为浮点数，是因为按照科学记数法表示时，一个浮点数的小数点位置是可变的。 整数和浮点数在计算机内部存储的方式是不同的，整数运算永远是精确的（除法难道也是精确的？是的！），而浮点数运算则可能会有四舍五入的误差。 字符串字符串是以单引号’或双引号”括起来的任意文本，比如’abc’，”xyz”等等。请注意，’’或””本身只是一种表示方式，不是字符串的一部分，因此，字符串’abc’只有a，b，c这3个字符。如果’本身也是一个字符，那就可以用””括起来，比如”I’m OK”包含的字符是I，’，m，空格，O，K这6个字符。 如果字符串内部既包含’又包含”怎么办？可以用转义字符\来标识。 Python还允许用r’’表示’’内部的字符串默认不转义， 如果字符串内部有很多换行，用\n写在一行里不好阅读，为了简化，Python允许用’’’…’’’的格式表示多行内容，12345678&gt;&gt;&gt; print ('''line1... line2... line3... line4''')line1line2line3line4 布尔值在Python中，可以直接用True、False表示布尔值（请注意大小写），也可以通过布尔运算计算出来123456789101112&gt;&gt;&gt; TrueTrue&gt;&gt;&gt; FalseFalse&gt;&gt;&gt; True and FalseFalse&gt;&gt;&gt; True or FalseTrue&gt;&gt;&gt; 1 &gt; 2 or 3 &gt; 2True&gt;&gt;&gt; not 1 &gt; 2True 空值空值是Python里一个特殊的值，用None表示。None不能理解为0，因为0是有意义的，而None是一个特殊的空值。 变量变量是用来存储值的所在处，它们有名字和数据类型。变量的数据类型决定了如何将代表这些值的位存储到计算机的内存中。在声明变量时也可指定它的数据类型。所有变量都具有数据类型，以决定能够存储哪种数据。 变量不仅可以是数字，还可以是任意数据类型。 变量在程序中就是用一个变量名表示了，变量名必须是大小写英文、数字和_的组合，且不能用数字开头， 在Python中，等号=是赋值语句，可以把任意数据类型赋值给变量，同一个变量可以反复赋值，而且可以是不同类型的变量，这就是动态语言，没有Java中那样必须指定变量类型。1234a = 123 # a是整数print(a)a = &apos;ABC&apos; # a变为字符串print(a) 1234&gt;&gt;&gt; x = 2&gt;&gt;&gt; x += 2&gt;&gt;&gt; print (x)4 python中字符串变量是指向字符串常量池的引用，变量更改的只是对字符串的引用地址变了。 1234&gt;&gt;&gt; x = 2&gt;&gt;&gt; x += 2&gt;&gt;&gt; print (x)4 常量在Python中，通常用全部大写的变量名表示常量 附python 中两种除法 / 除法计算结果是浮点数，即使是两个整数恰好整除，结果也是浮点数: 1234&gt;&gt;&gt; 8 / 32.6666666666666665&gt;&gt;&gt; 9 / 33.0 还有一种除法是//，称为地板除，整数不管是否整除除法都是整数，浮点数除法是浮点数： 12345678&gt;&gt;&gt; 9 / 33.0&gt;&gt;&gt; 8 // 32&gt;&gt;&gt; 9 // 33&gt;&gt;&gt; 9.2123 // 33.0 Python的整数没有大小限制， Python的浮点数也没有大小限制，但是超出一定范围就直接表示为inf（无限大）。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python学习之路</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识python]]></title>
    <url>%2Fpython-first.html</url>
    <content type="text"><![CDATA[Write In the Front本来很早打算就要学习python的，这几个月发生了一些事，导致耽误下来，现在开始重新拾起这个梦想吧。 学习python3 都是从廖雪峰博客网站上学习的，自己新建一栏python学习之路，写下学习笔记，记录学习过程。 Study我安装的pyhon 版本是3.7去官网下载最新版的3.X版本，需要注意的是：安装的时候记得勾选下方的Add Python 3.7 to PATH，将python的环境变量配置到系统中，就可以直接使用python 命令进入 python 交互模式，然后Install Now；当然手快没勾选的百度自己配置，也是没问题的。在 Windows PowerShell 下进入 python 交互模式123PS C:\Users\server&gt; pythonPython 3.7.0a2 (v3.7.0a2:f7ac4fe, Oct 17 2017, 17:06:29) [MSC v.1900 64 bitType "help", "copyright", "credits" or "license" for more information. 运行打印 hello world12&gt;&gt;&gt; print ('hello world')hello world 使用编辑器编辑python ，不能使用记事本。 我目前使用的是 Notepad++ ； 新建一个页面，写入1print (&apos;hello world&apos;) 保存文件名为 helloWorld.py 一定要以py 结尾，以python 文件保存起来。 保存完毕后，可以运行这个脚本文件了，命令进入文件所在位置，我是放在桌面的，执行命令：12PS C:\Users\server\Desktop&gt; python helloWorld.pyhello world 输出成功。 Summary： 用文本编辑器写Python程序，然后保存为后缀为.py的文件，在Windows下就可以使用命令Python直接运行这个程序。 直接输入python进入交互模式，相当于启动了Python解释器，但是等待你一行一行地输入源代码，每输入一行就执行一行。直接运行.py文件相当于启动了Python解释器，然后一次性把.py文件的源代码给执行了，你是没有机会输入源代码的。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python学习之路</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8 新特性Stream 的学习和使用方法]]></title>
    <url>%2Fjava-stream.html</url>
    <content type="text"><![CDATA[流（Stream）流是java 8 中新引入的特性，用来处理集合中的数据，Stream 是一个来自数据源的元素队列并支持聚合操作。 Java 中 Stream 不会存储元素。 数据源 流的来源。 可以是集合，数组，I/O channel， 产生器generator 等。 聚合操作 类似SQL语句一样的操作， 比如filter, map, reduce, find, match, sorted等。 Stream操作还有几个特征： 只遍历一次。我们可以把流想象成一条流水线，流水线的源头是我们的数据源(一个集合)，数据源中的元素依次被输送到流水线上，我们可以在流水线上对元素进行各种操作。一旦元素走到了流水线的另一头，那么这些元素就被“消费掉了”，我们无法再对这个流进行操作。当然，我们可以从数据源那里再获得一个新的流重新遍历一遍。 Pipelining: 中间操作都会返回流对象本身。 这样多个操作可以串联成一个管道， 如同流式风格（fluent style）。 这样做可以对操作进行优化， 比如延迟执行(laziness)和短路( short-circuiting)。 内部迭代： 以前对集合遍历都是通过Iterator或者For-Each的方式, 显式的在集合外部进行迭代， 这叫做外部迭代。 Stream提供了内部迭代的方式， 通过访问者模式(Visitor)实现。 流的使用流的使用过程有三步： 获取流； 中间操作，得到一个新的流； 最终操作，获取结果。 获取流流有两种： stream() ： 创建串行流。 parallelStream() ： 创建并行流。 并行流的特点就是将一个大任务切分成多个小任务，无序一起执行，当然如果我们需要顺序输出的话可以使用forEachOrdered，速度会比串行流快一些。它通过默认的ForkJoinPool,可能提高你的多线程任务的速度。 从集合获取流12List&lt;FarmEntity&gt; list = service.getBySql(sql1);Stream&lt;FarmEntity&gt; stream = list.stream(); 从数组获取流12String[] arrays = &#123;"你", "我", "她"&#125;;Stream&lt;String&gt; stream = Arrays.stream(arrays); 从值获取流1Stream&lt;String&gt; stream = Stream.of("你", "我", "她"); 从文件获取流123456try &#123; Stream&lt;String&gt; file =Files.lines(Paths.get("D:\\zhangkai\\WorkSpace\\Git\\hexo\\_config.yml")); file.forEach(System.out::println);&#125; catch (Exception e) &#123;&#125; 使用NIO获取流，可以打印出文本文件的内容。 流的操作filter 过滤filter函数接收一个Lambda表达式作为参数，该表达式返回boolean，在执行过程中，流将元素逐一输送给filter，并筛选出执行结果为true的元素。12String[] strings = &#123;"珊瑚", "阳光", "细腻", "冷暖", "阳光"&#125;;Arrays.stream(strings).filter(n -&gt; n.startsWith("冷")).forEach(System.out::print); distinct 去重1Arrays.stream(strings).distinct().forEach(System.out::print); limit 截取截取前面两个单位：1Arrays.stream(strings).limit(2).forEach(System.out::print); skip 跳过和上面的limit 相反，跳过前面两个12 map 映射map 方法用于映射每个元素到对应的结果。给每个词语后面加个 “兮”1Arrays.stream(strings).map(s -&gt; s + "兮").forEach(System.out::println); 输出：12345珊瑚兮阳光兮细腻兮冷暖兮阳光兮 sorted 排序12//Arrays.stream(strings).sorted((x, y) -&gt; x.compareTo(y)).forEach(System.out::println);Arrays.stream(strings).sorted(String::compareTo).forEach(System.out::println); 输出：12345冷暖珊瑚细腻阳光阳光 java8 以前排序：12345678910// Before Java 8 sorted System.out.println("java8以前排序："); List&lt;String&gt; list1 = Arrays.asList(strings); list1.sort(new Comparator&lt;String&gt;() &#123; @Override public int compare(String o1, String o2) &#123; return o1.compareTo(o2); &#125; &#125;); System.out.printf("java8 以前的排序：%s%n", list1); 输出：12java8以前排序：java8 以前的排序：[冷暖, 珊瑚, 细腻, 阳光, 阳光] HashMap根据value值排序key：12345678Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;();map.put("spring", 1);map.put("summer", 2);map.put("autumn", 3);map.put("winter", 4);map.entrySet().stream() .sorted((a, b) -&gt; b.getValue().compareTo(a.getValue())) .forEach(a -&gt; System.out.println(a.getKey())); 输出结果：1234winterautumnsummerspring 统计1234567//统计 List&lt;Integer&gt; list4 = Arrays.asList(1, 2, 3, 4, 1); IntSummaryStatistics stats = list4.stream().mapToInt((x) -&gt; x).summaryStatistics(); System.out.println("Highest number in List : " + stats.getMax()); System.out.println("Lowest number in List : " + stats.getMin()); System.out.println("Sum of all numbers : " + stats.getSum()); System.out.println("Average of all numbers : " + stats.getAverage()); 运行结果：1234Highest number in List : 4Lowest number in List : 1Sum of all numbers : 11Average of all numbers : 2.2 match 匹配 anyMatch用于判断流中是否存在至少一个元素满足指定的条件，这个判断条件通过Lambda表达式传递给anyMatch，执行结果为boolean类型。 noneMatch与allMatch恰恰相反，它用于判断流中的所有元素是否都不满足指定条件 findAny能够从流中随便选一个元素出来，它返回一个Optional类型的元素。123456789Boolean result1 = Arrays.stream(strings).allMatch(s -&gt; s.equals("java")); System.out.println(result1); Boolean reslut2 = Arrays.stream(strings).noneMatch(s -&gt; s.equals("java")); System.out.println(reslut2); //随机读取一个 Optional&lt;String&gt; getResult = Arrays.stream(strings).findAny(); System.out.println(getResult); System.out.printf("获取Optional中的值：%s%n", getResult.get()); 运行结果：1234falsetrueOptional[冷暖]获取Optional中的值：冷暖 Optional是Java8新加入的一个容器，这个容器只存1个或0个元素，它用于防止出现NullpointException，它提供如下方法： isPresent() 判断容器中是否有值。 ifPresent(Consume lambda) 容器若不为空则执行括号中的Lambda表达式。 T get() 获取容器中的元素，若容器为空则抛出NoSuchElement异常。 T orElse(T other) 获取容器中的元素，若容器为空则返回括号中的默认值。 reduce 归约求和：12345678//归约 //第一种方法求和 String connectStrings = Arrays.stream(strings).reduce("", (x, y) -&gt; x + y); System.out.println(connectStrings); // 第二种方法求和 String connectStrings1 = Arrays.stream(strings).reduce("", TestStream::getConnectStrings); System.out.println(connectStrings1); getConnectStrings方法：123456789/*** Connect Strings* @param s1 参数1* @param s2 参数2* @return java.lang.String*/private static String getConnectStrings(String s1, String s2) &#123; return s1 + s2;&#125; reduce中第一个参数是初始值，第二个参数是方法引用。 数据流StreamAPI提供了三种数值流：IntStream、DoubleStream、LongStream，也提供了将普通流转换成数值流的三种方法：mapToInt、mapToDouble、mapToLong。 每种数值流都提供了数值计算函数，如max、min、sum等。 下面使用 mapToInt 为例： 1234567String[] numberStrings = &#123;"1", "2", "3"&#125;;// mapToInt参数： 需要转换成相应的类型方法IntStream intStream = Arrays.stream(numberStrings).mapToInt(Integer::valueOf);//使用对应的 Optional 接收OptionalInt optionalNumber = intStream.max();// 取值，给默认值 0，为空结果为0System.out.printf("numberStrings's max number is: %s%n", optionalNumber.orElse(0)); 打印结果：1numberStrings&apos;s max number is: 3 由于数值流可能为空，并且给空的数值流计算最大值是没有意义的，因此max函数返回OptionalInt，它是Optional的一个子类，能够判断流是否为空，并对流为空的情况作相应的处理。 所以可以直接使用 OptionalInt.getAsInt()获取容器的值。为空的话捕捉异常：123java.util.NoSuchElementException: No value present at java.util.OptionalInt.getAsInt(OptionalInt.java:118) at com.wuwii.test.TestStream.main(TestStream.java:105) 此外，mapToInt、mapToDouble、mapToLong进行数值操作后的返回结果分别为：OptionalInt、OptionalDouble、OptionalLong。 Collectors 集合归约将流转换成集合和聚合元素。123456//Collectors 集合归约 // toList List&lt;String&gt; list2 = Arrays.stream(strings).collect(Collectors.toList()); // Get String by connected String connectStrings2 = Arrays.stream(strings).collect(Collectors.joining(",")); System.out.printf("Collectors toList: %s , Conlletors Join Strings: %s%n", list2, connectStrings2); 打印结果：1Collectors toList: [冷暖, 珊瑚, 细腻, 阳光, 阳光] , Conlletors Join Strings: 冷暖,珊瑚,细腻,阳光,阳光 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120package com.wuwii.test;import java.nio.file.Files;import java.nio.file.Paths;import java.util.*;import java.util.stream.Collectors;import java.util.stream.IntStream;import java.util.stream.Stream;/** * Learn Java 8 Stream * * @author Zhang Kai * @version 1.0 * @since &lt;pre&gt;2017/10/25 22:16&lt;/pre&gt; */public class TestStream &#123; public static void main(String[] args) &#123; // Get Stream from file System.out.println("读取文件："); try &#123; Stream&lt;String&gt; file = Files.lines(Paths.get("D:\\zhangkai\\WorkSpace\\Git\\hexo\\_config.yml")); file.forEach(System.out::println); &#125; catch (Exception e) &#123; &#125; // Get Stream by Filter String[] strings = &#123;"珊瑚", "阳光", "细腻", "冷暖", "阳光"&#125;; Arrays.stream(strings).filter(n -&gt; n.startsWith("冷")).forEach(System.out::print); // Get Stream by Distinct System.out.println("去重:"); Arrays.stream(strings).distinct().forEach(System.out::print); // Get Stream by Limit System.out.println("截取:"); Arrays.stream(strings).limit(2).forEach(System.out::print); // Get Stream by Skip System.out.println("跳过:"); Arrays.stream(strings).skip(2).forEach(System.out::print); // Java 8 sorted System.out.println("排序："); //Arrays.stream(strings).sorted((x, y) -&gt; x.compareTo(y)).forEach(System.out::println); Arrays.stream(strings).sorted(String::compareTo).forEach(System.out::println); // Before Java 8 sorted System.out.println("java8以前排序："); List&lt;String&gt; list1 = Arrays.asList(strings); list1.sort(new Comparator&lt;String&gt;() &#123; @Override public int compare(String o1, String o2) &#123; return o1.compareTo(o2); &#125; &#125;); System.out.printf("java8 以前的排序：%s%n", list1); //Handle map System.out.println("map 映射："); Arrays.stream(strings).map(s -&gt; s + "兮").forEach(System.out::println); //Match Boolean result1 = Arrays.stream(strings).allMatch(s -&gt; s.equals("java")); System.out.println(result1); Boolean reslut2 = Arrays.stream(strings).noneMatch(s -&gt; s.equals("java")); System.out.println(reslut2); //findAny to find anyone Optional&lt;String&gt; getResult = Arrays.stream(strings).findAny(); System.out.println(getResult); System.out.printf("获取Optional中的值：%s%n", getResult.get()); //统计 List&lt;Integer&gt; list4 = Arrays.asList(1, 2, 3, 4, 1); IntSummaryStatistics stats = list4.stream().mapToInt((x) -&gt; x).summaryStatistics(); System.out.println("Highest number in List : " + stats.getMax()); System.out.println("Lowest number in List : " + stats.getMin()); System.out.println("Sum of all numbers : " + stats.getSum()); System.out.println("Average of all numbers : " + stats.getAverage()); //归约 //第一种方法求和 String connectStrings = Arrays.stream(strings).reduce("", (x, y) -&gt; x + y); System.out.println(connectStrings); // 第二种方法求和 String connectStrings1 = Arrays.stream(strings).reduce("", TestStream::getConnectStrings); System.out.println(connectStrings1); //Collectors 集合归约 // toList List&lt;String&gt; list2 = Arrays.stream(strings).collect(Collectors.toList()); // Get String by connected String connectStrings2 = Arrays.stream(strings).collect(Collectors.joining(",")); System.out.printf("Collectors toList: %s , Conlletors Join Strings: %s%n", list2, connectStrings2); String[] numberStrings = &#123;"1", "2", "3"&#125;; // mapToInt参数： 需要转换成相应的类型方法 IntStream intStream = Arrays.stream(numberStrings).mapToInt(Integer::valueOf); //使用对应的 Optional 接收 OptionalInt optionalNumber = intStream.max(); // 取值，给默认值 0，为空结果为0 System.out.printf("numberStrings's max number is: %s%n", optionalNumber.orElse(0)); &#125; /** * 拼接字符串 * * @param s1 参数1 * @param s2 参数2 * @return java.lang.String */ private static String getConnectStrings(String s1, String s2) &#123; return s1 + s2; &#125;&#125;]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[珍惜]]></title>
    <url>%2Fcherish-her.html</url>
    <content type="text"><![CDATA[话说开会的时候，总是有人心不在焉的，没错，那个人就是我，开会随手刷刷手机，看到这个文章的不要学我哈。无意中看到一个句子。 其实人生的路很漫长在这条人生的路上你会遇到很多的人很多的风景当你错过以后你以为人生就已经结束了实际上没有因为它还在继续你还会遇到更多的人更多的风景也许下一个人才是真正适合你的人 可是你又没跟那个人在一起过你怎么知道她不是最适合你的人呢你错过了她你以为你会碰到更好的人可是事实证明呢你到现在还是单着这说明了什么说明了你在潜意识里你觉得她是最值得珍惜的是最值得你去爱的最值得你去关怀的你所错过的才是真正美丽的风景 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--宁财神 《龙门镖局》]]></content>
      <categories>
        <category>那些很美的句子</category>
      </categories>
      <tags>
        <tag>桔子</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Programmer's Day]]></title>
    <url>%2Fprogrammer-day.html</url>
    <content type="text"><![CDATA[今天议论关注最多的就是1024，程序猿节日，可怕，什么时候程序猿都有节日了。。。 当然公司明天还有活动，很高兴有这么个节日，作为一个单身狗，最讨厌的估计就是加班，尼玛，单身狗还害怕什么加班，太没志气了，怎么能跟那些秀恩爱的去比高低，逃。 123456789101112131415161718192021package com.wuwii.test;import java.util.Arrays;import java.util.List;public class NoOT &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = Arrays.asList( "1024不加班的理由：", "Cannot find the object", "Cannot find the object", "Cannot find the object", "太冷，我选择睡觉！！！ ", " ☽ ", " // /￣'- 、_ ", " // ℂ/ &lt;_/ _____/ ", " ￣￣￣￣￣￣￣ " ); list.stream().forEach(System.out::println); &#125;&#125; 这个是今年自己写在 华为云 论坛上的一个回帖，当然是为了福利的，其实我是为了混个华为P10，实在不行，给个鼠标垫算了，原谅了。 另外附几张论坛好玩的几个图（侵删） 就发这么多了，，该洗洗睡了。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 中lambda表达式的使用]]></title>
    <url>%2Fjava-lambda.html</url>
    <content type="text"><![CDATA[java 中lambda表达式 实在 java 8 版本后新加入的特性，Lambda 允许把函数作为一个方法的参数（函数作为参数传递进方法中）。 特征: 可选类型声明：不需要声明参数类型，编译器可以统一识别参数值。 可选的参数圆括号：一个参数无需定义圆括号，但多个参数需要定义圆括号。 可选的大括号：如果主体包含了一个语句，就不需要使用大括号。 可选的返回关键字：如果主体只有一个表达式返回值则编译器会自动返回值，大括号需要指定明表达式返回了一个数值。 总结语法就是： 123(params) -&gt; expression(params) -&gt; statement(params) -&gt; &#123; statements &#125; 使用lambda表达式替换匿名类以 Runnable 为例123456789101112131415161718192021//before java8new Thread(new Runnable() &#123; /** * When an object implementing interface &lt;code&gt;Runnable&lt;/code&gt; is used * to create a thread, starting the thread causes the object's * &lt;code&gt;run&lt;/code&gt; method to be called in that separately executing * thread. * &lt;p&gt; * The general contract of the method &lt;code&gt;run&lt;/code&gt; is that it may * take any action whatsoever. * * @see Thread#run() */ public void run() &#123; System.out.println("before jdk 1.8;"); &#125;&#125;).start();// after jdk 1.8new Thread(() -&gt; System.out.println("after jdk 1.8;")).start(); 执行结果是：12before jdk 1.8;after jdk 1.8; 使用lambda表达式 迭代以 forEach 为例，迭代所有对象12345678List&lt;String&gt; list1 = Arrays.asList("spring", "summer", "autumn", "winter"); //before java8 for (String s : list1) &#123; System.out.println("before: " + s); &#125; //after list1.forEach(n -&gt; System.out.println("after: " + n)); //list1.forEach(System.out::println); //可以打印，方法引用由::双冒号操作符标示， 打印结果：12345678before: springbefore: summerbefore: autumnbefore: winterafter: springafter: summerafter: autumnafter: winter 使用lambda表达式和函数式接口Predicate除了在语言层面支持函数式编程风格，Java 8也添加了一个包，叫做 java.util.function。它包含了很多类，用来支持Java的函数式编程。其中一个便是Predicate，使用 java.util.function.Predicate 函数式接口以及lambda表达式，可以向API方法添加逻辑，用更少的代码支持更多的动态行为。下面是Java 8 Predicate 的例子，展示了过滤集合数据的多种常用方法。Predicate接口非常适用于做过滤。12345678910111213141516171819202122List&lt;String&gt; list1 = Arrays.asList("spring", "summer", "autumn", "winter"); System.out.println("Print which end with n: "); filter(list1, str -&gt; (str + "").endsWith("n")); System.out.println("Print which start with s: "); filter(list1, str -&gt; (str + "").startsWith("s")); System.out.println("Print whose length greater than 6: "); filter(list1, str -&gt; (str + "").length() &gt; 6); System.out.println("Print all:"); filter(list1, str -&gt; true); System.out.println("Print none:"); filter(list1, str -&gt; false); public static void filter (List list, Predicate condition) &#123; list.stream(). filter(s -&gt; condition.test(s)). forEach(s -&gt; System.out.println(s)); &#125; 打印结果：123456789101112Print which end with n: autumnPrint which start with s: springsummerPrint whose length greater than 6: Print all:springsummerautumnwinterPrint none: 例外 filter 还提供逻辑操作符AND和OR的方法，名字叫做and()、or()和xor()，用于将传入 filter() 方法的条件合并起来。123456List&lt;String&gt; list1 = Arrays.asList("spring", "summer", "autumn", "winter");Predicate&lt;String&gt; startWithS = s -&gt; s.startsWith("s"); Predicate&lt;String&gt; endWithG = g -&gt; g.endsWith("g"); list1.stream() .filter(startWithS.and(endWithG)) .forEach(System.out::println); 打印结果：1spring 使用lambda表达式的Map和Reduce给list 中 每个数据 增加 50%123456789List&lt;Integer&gt; list2 = Arrays.asList(100, 200, 300, 400); for (Integer num : list2) &#123; Double result = num + num * 0.5; System.out.println(result); &#125; list2.stream() .map(num -&gt; num + num * 0.5) .forEach(System.out::println); 打印结果：12345678150.0300.0450.0600.0150.0300.0450.0600.0 计算一个list 每个值加上 50%后的和123456789101112 List&lt;Integer&gt; list2 = Arrays.asList(100, 200, 300, 400);double total = 0; for (Integer num : list2) &#123; Double result = num + num * 0.5; total += result; System.out.println(total); &#125; total = list2.stream() .map(num -&gt; num + num * 0.5) .reduce((sum, result) -&gt; sum + result).get(); System.out.println(total); 打印结果：121500.01500.0 map将集合类（例如列表）元素进行转换的。还有一个 reduce() 函数可以将所有值合并成一个。Map和Reduce操作是函数式编程的核心操作，因为其功能，reduce 又被称为折叠操作。 通过过滤创建一个String列表 通过过滤创建一个新的字符串列表，每个字符串长度大于21234List&lt;String&gt; list3 = Arrays.asList("abc", "def", "hi", "hello"); // 创建一个字符串列表，每个字符串长度大于2 List&lt;String&gt; filtered = list3.stream().filter(x -&gt; x.length()&gt; 2).collect(Collectors.toList()); System.out.printf("Original List : %s, filtered list : %s %n", list3, filtered); 对列表的每个元素应用函数对list3 的每个元素转换成大写，并用逗号连接起来。123List&lt;String&gt; list3 = Arrays.asList("abc", "def", "hi", "hello");String string = list3.stream().map(s -&gt; s.toUpperCase()).collect(Collectors.joining(",")); System.out.printf("Original List : %s, After String : %s %n", list3, string); 运行结果：1Original List : [abc, def, hi, hello], After String : ABC,DEF,HI,HELLO 复制不同的值，创建一个子列表如何利用流的 distinct() 方法来对集合进行去重。123List&lt;Integer&gt; list4 = Arrays.asList(1, 2, 3, 4, 1); List&lt;Integer&gt; distinctList = list4.stream().map( i -&gt; i * i).distinct().collect(Collectors.toList()); System.out.printf("Original List : %s, Square Reslut : %s %n", list4, distinctList); 运行结果：1Original List : [1, 2, 3, 4, 1], Square Reslut : [1, 4, 9, 16] 计算集合元素的最大值、最小值、总和以及平均值IntStream、LongStream 和 DoubleStream 等流的类中，有个非常有用的方法叫做 summaryStatistics() 。可以返回 IntSummaryStatistics、LongSummaryStatistics 或者 DoubleSummaryStatistic s，描述流中元素的各种摘要数据。 我们用这个方法来计算列表的最大值和最小值。它也有 getSum() 和 getAverage() 方法来获得列表的所有元素的总和及平均值。123456List&lt;Integer&gt; list4 = Arrays.asList(1, 2, 3, 4, 1); IntSummaryStatistics stats = list4.stream().mapToInt((x) -&gt; x).summaryStatistics(); System.out.println("Highest number in List : " + stats.getMax()); System.out.println("Lowest number in List : " + stats.getMin()); System.out.println("Sum of all numbers : " + stats.getSum()); System.out.println("Average of all numbers : " + stats.getAverage()); 运行结果：1234Highest number in List : 4Lowest number in List : 1Sum of all numbers : 11Average of all numbers : 2.2 总结 lambda 表达式只能引用 final 或 final 局部变量，这就是说不能在 lambda 内部修改定义在域外的变量，否则会编译错误。 Lambda表达式在Java中又称为闭包或匿名函数， lambda内部可以使用静态、非静态和局部变量，这称为lambda内的变量捕获。 如果在 lambda 表达式 内部不能调用参数方法的引用，需要声明参数类型。 参考博客： http://www.importnew.com/16436.html]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>lambda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intellij Idea 的maven 项目设置 默认java编译版本]]></title>
    <url>%2Fcompiler-version.html</url>
    <content type="text"><![CDATA[使用 Intellij Idea 创建maven 项目后，每次 reimport 都会回归默认 java 版本 1.5 ，每次都要重新设置版本，很麻烦。下面的方法同样适用Eclipse。 解决方法一修改该项目的pom.xml , 只对该项目有效。123456789101112131415161718192021&lt;properties&gt; &lt;maven.compiler.version&gt;2.3.2&lt;/maven.compiler.version&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;&lt;/properties&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven.compiler.version&#125;&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;$&#123;maven.compiler.source&#125;&lt;/source&gt; &lt;target&gt;$&#123;maven.compiler.target&#125;&lt;/target&gt; &lt;encoding&gt;$&#123;project.build.sourceEncoding&#125;&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 保存，eclipse 是Update maven 项目， Intellij reimport。 方法二修改 maven 的 配置文件 settings.xml，在profiles节点中加入自己的Jdk版本：1234567891011&lt;profile&gt; &lt;id&gt;jdk-1.8&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;/profile&gt; 这个方法对于所有使用这个maven 插件的项目都有效。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[别太懂事了]]></title>
    <url>%2Fsensible.html</url>
    <content type="text"><![CDATA[不知不觉，又想起了她，自从上次见过她了，心里总是那么时刻的泛起她的影子吧，虽然说好久没见再相见，但是彼此应该没什么深刻的记忆吧，而且排斥的我很厉害，这让我心疼得厉害，到底是什么成为这样的她，不想懂了。 或许吧，是以前一个人久了，什么事都得自己撑着吧，什么事情都得面对，她也是一个很拼的女孩子，什么事情都得抢在前头吧，最后了，有了委屈自己忍，有了眼泪只好自己吞。总是在乎别人的感受，然而不知道自己会有多疼的人，就是这样太懂事的人吧。明明她也很脆弱，无关外表，还是心里，却总要装作坚强的样子，明明她也有时候表现的无所适从的害怕，却还要表现得无所畏惧的淡然。可是，在别人面前，她一直装作那么懂事，别人都不相信她会难过，会流泪了吧。但是，她不这么认为的，相信自己能够修复所有的伤疤，可以完成所有的事情。 但是，太懂事的人，常常会不太幸福吧，常常顾及别人得感受，不懂得去拒绝别人，更不忍心看别人难过，宁可自己委屈，宁可自己疲惫，也不想给任何人带来麻烦，这样真的会活得很累很累，考虑得太多，却总是忽略了自己。这也是我为什么总是说好担心你呀。 别太懂事了，不要太善良了，给别人一次心疼自己的机会，卸下面具，天 塌下来了也不用自己去抗；别再逞强了，你也值得被人疼人。别把所有的事情都揽到自己身上，你只是你自己，不需要活成别人，也可以不管不顾一切，活成自己的模样。 加油，姑娘。真希望你能好好的生活下去，忘了一切烦恼。 晚安。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 上安装Hadoop V 2.8.1集群及配置]]></title>
    <url>%2Flinux-hadoop.html</url>
    <content type="text"><![CDATA[Hadoop是一个由Apache基金会所开发的分布式系统基础架构。用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。 Hadoop实现了一个分布式文件系统（Hadoop Distributed File System），简称HDFS。HDFS有高容错性的特点，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高吞吐量（high throughput）来访问应用程序的数据，适合那些有着超大数据集（large data set）的应用程序。HDFS放宽了（relax）POSIX的要求，可以以流的形式访问（streaming access）文件系统中的数据。Hadoop的框架最核心的设计就是：HDFS和MapReduce。HDFS为海量的数据提供了存储，则MapReduce为海量的数据提供了计算。(百科) 下载Hadoop本次使用的是2.8.1版本的Hadoop，官网地址http://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.8.1/hadoop-2.8.1.tar.gz 点击（不用进官网直接点这个链接就能下载） http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.8.1/hadoop-2.8.1.tar.gz 安装3个虚拟机并实现ssh免密码登录修改host使用的Linux系统是CentOS 7 ，修改三台机器的Hosts，让它们能相互映射到，能ping t通参考我的上一篇文章 http://blog.wuwii.com/linux-hostname.html 添加Hosts，这是我的三台机器123192.168.19.185 server1192.168.19.184 server2192.168.19.199 server3 ping 结果都能ping 通12345678910[root@server2 ~]# ping -c 4 server1PING server1 (192.168.19.185) 56(84) bytes of data.64 bytes from server1 (192.168.19.185): icmp_seq=1 ttl=64 time=0.536 ms64 bytes from server1 (192.168.19.185): icmp_seq=2 ttl=64 time=0.388 ms64 bytes from server1 (192.168.19.185): icmp_seq=3 ttl=64 time=0.309 ms64 bytes from server1 (192.168.19.185): icmp_seq=4 ttl=64 time=0.368 ms--- server1 ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 3001msrtt min/avg/max/mdev = 0.309/0.400/0.536/0.084 ms 生成密钥密钥三台机器都需要生成，就以一台 server1 机器为例 使用命令 ssh-keygen -t rsa 一路 enter123456789101112131415161718192021[root@server1 ~]# ssh-keygen -t rsaGenerating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:e0:ea:e3:5d:95:be:c5:9a:dc:90:99:22:d1:cf:99:49 root@server1The key's randomart image is:+--[ RSA 2048]----+| || || . || . o . || o S E || . . * O || . . o % o || ... o o B || .o.. = . |+-----------------+ 出现上面的 ，可以在本帐户的根目录看到一个 .ssh 文件夹 123456789101112131415161718[root@server1 ~]# ll -a总用量 68dr-xr-x---. 6 root root 256 10月 18 15:00 .dr-xr-xr-x. 20 root root 4096 10月 18 10:35 ..-rw-------. 1 root root 1456 8月 14 08:44 anaconda-ks.cfg-rw-------. 1 root root 24538 10月 18 10:35 .bash_history-rw-r--r--. 1 root root 18 12月 29 2013 .bash_logout-rw-r--r--. 1 root root 176 12月 29 2013 .bash_profile-rw-r--r--. 1 root root 176 12月 29 2013 .bashrc-rw-r--r--. 1 root root 100 12月 29 2013 .cshrc-rw-r--r-- 1 root root 223 9月 27 10:47 dump.rdbdrwxr-xr-x. 11 root root 270 8月 15 15:57 fastdfsdrwxr-xr-x. 2 root root 40 8月 15 15:04 .oracle_jre_usagedrwxr-----. 3 root root 19 8月 15 15:53 .pki-rw------- 1 root root 571 9月 27 16:58 .rediscli_historydrwx------ 2 root root 38 10月 18 14:56 .ssh-rw-r--r--. 1 root root 129 12月 29 2013 .tcshrc-rw------- 1 root root 7372 10月 18 11:35 .viminfo 注意它是个隐藏的文件，我是用的是secureFx 显示隐藏文件，需要 视图 -&gt; 文件 勾选上就行1234[root@server1 .ssh]# ll总用量 8-rw------- 1 root root 668 10月 18 15:12 id_rsa-rw-r--r-- 1 root root 602 10月 18 15:12 id_rsa.pub 打开 /root/.ssh/id_rsa.pub12[root@server1 .ssh]# cat id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCpRge0XRJya0rXjaMs7VQ5uHrmaVxzFekB/gNoFNUsJ7cjWfFUpUao8zZpioCUceUWdI4sL0doQGriTXBjwrhDtcaO0IZujG2oyD1OGfOVbn7Yuhc6EZz0fed5soj6AZrGIgTMrweRpD268bvcJCcWOPV7U2iAjOqYSmP2Z/1ckYwJ983qSLvHPhPVnFBENmo9Evgzfa/6QM+j2UbVIIjfiUPxo4BNWxcvVruxJV+pEFa1ycAT8ORvLxirgafctdfw+Md1Epuna0RIE59H3382COUjC/UonAya5ebl1z5JGY65dREIdRDcvYfwnMcpeF5mkEuowyX/1Ev3y+JFENBV root@server1 查看到了我们生成的密钥成功了 然后我们把三个机器都生成密钥，然后把他们合并成一个文件创建一个/root/.ssh/authorized_keys 文件保存着。 使用命令1[root@server1 ~]# cat /root/.ssh/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys 其他机器的公共密钥也复制到到这个文件里来（补充，不要连着复制，上一行后面打个空格，再换行。） 所以最后是这样的12345678910111213141516[root@server1 .ssh]# vim authorized_keysssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCpRge0XRJya0rXjaMs7VQ5uHrmaVxzFekB/gNoFNUsJ7cjWfFUpUao8zZpioCUceUWdI4sL0doQGriTXBjwrhDtcaO0IZujG2oyD1OGfOVbn7Yuhc6EZz0fed5soj6AZrGIgTMrweRpD268bvcJCcWOPV7U2iAjOqYSmP2Z/1ckYwJ983qSLvHPhPVnFBENmo9Evgzfa/6QM+j2UbVIIjfiUPxo4BNWxcvVruxJV+pEFa1ycAT8ORvLxirgafctdfw+Md1Epuna0RIE59H3382COUjC/UonAya5ebl1z5JGY65dREIdRDcvYfwnMcpeF5mkEuowyX/1Ev3y+JFENBV root@server1ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDFwe2pGEMWt+X0FXFPotOQrUAJFDOLflMjtwBIJxTSFBPQuVhoEtJHkacnpsPAtT4zOJxjieLOrsC/G5fKZVpSgYRwmMw6iobe3IsL5uElVfRYoO+HIr/BDep1imVFkmj0DTMUj0q+UYz3wiEaFQk4zh7Gas2qIdgyOtfSQcYN3T7qNh4dPDfdOrBIqZq/fP33UFDBgbUqGZUZhL6mHc8LRHo9+eby3ZPtiEudfeczvi3pI0Dcp0zX+WSuqPK/z47hBN2XlGMIDO2Ta5sAu9WfECe0WcxsPLOPsKPCRsakyMrYlnGk3hEQ9Ci1YsNKUX8j1RhBi3YLKsl5rjhQR67r root@server2ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDFPaRkR/0i51MORrPVnsEZR60t7FZDmJ3DlhVKdt4crCHO+QhsHr5ZwbcLT/9vTBAdRoveuwHJreEO5MLnlcG0dxFjVDduip5M84zGjmKI1k7/tyeNT1bHUhoMWRAaDEk9RUx/rrYzR/DzHvkdXPwPK+uENFCFBo0RTEGxAMkrXkex7SFNITh8t48sto23D20v7O4A+h4Fbe4oiEjlFBeK6H+dJxZVqYE5Xof1Y4Nc0Xh0YfEg9rUT4BS1AdYWZB9ptVyuSzsbmBd1mve8GcR8cf0M75uSIovc3ww/z/sVpx+hluldhVN9wXyUtFZdWcbklJcq6oTMfejY7ISv2lKh root@server3~ ~ ~ ~ ~ ~ ~ &quot;authorized_keys&quot; [新] 5L, 1183C 已写入 每个电脑都需要这个/root/.ssh/authorized_keys文件，所以直接把它复制到对应位置就行了。 注意我们需要给它们相应的权限，一般默认的就是这个权限，下面是root 用户的。chmod 700 ~/.ssh #注意：这两条权限设置特别重要，决定成败。chmod 600 ~/.ssh/authorized_keys 测试使用ssh 密钥无密码登陆 首先测试下localhost ，看能否无密码登陆自己123[root@server1 ~]# ssh localhostLast login: Thu Oct 19 09:01:34 2017 from 192.168.19.207[root@server1 ~]# 演示下server2 电脑上进行登陆 server1 并进行操作，123456789[root@server2 ~]# ssh server1The authenticity of host 'server1 (192.168.19.185)' can't be established.ECDSA key fingerprint is bd:50:b8:e7:b3:69:ad:6c:14:6b:a9:fb:18:43:b9:c9.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added 'server1,192.168.19.185' (ECDSA) to the list of known hosts.Last login: Wed Oct 18 16:46:53 2017 from server1[root@server1 ~]# exitlogoutConnection to server1 closed. 之前配置 authorized_keys 搞了半天，虽然用了三行，但是后面没空格，导致 密钥不能使用，每次登陆还需要密码。12[root@server1 ~]# ssh server2root@server2's password: 没百度出来，自己最后卡了一个小时 恍然大悟，每行后面空出空格就好了。 在其余的电脑相互登陆试试，都能无密登陆，说明，配置成功。 但是一定要注意的是，每次ssh登陆完成后，都要执行 exit，否则你的后续命令是在另外一台机器上执行的。 安装JDK 和Hadoop安装jdk三台机器都需要安装jdk，CentOS7 安装JDK参考 http://blog.wuwii.com/linux-jdk.html 安装hadoop首先 三台机器都需要安装hadoop，都需要执行下面所有的操作。 上载文件，并且解压1[root@server1 opt]# tar -xvf hadoop-2.8.1.tar.gz 解压缩后得到hadoop-2.8.1 文件夹。 新建目录在/root 目录下新建123456mkdir /root/hadoopmkdir /root/hadoop/tmpmkdir /root/hadoop/varmkdir /root/hadoop/dfsmkdir /root/hadoop/dfs/namemkdir /root/hadoop/dfs/data 修改配置文件配置文件都在 解压后的文件夹 hadoop-2.8.1/etc/hadoop 下。 修改core-site.xml 在configuration&gt;节点内加入配置:123456789&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/root/hadoop/tmp&lt;/value&gt; &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://server1:9000&lt;/value&gt;&lt;/property&gt; 修改 hadoop-env.sh文件修改./hadoop-2.8.1/etc/hadoop/hadoop-env.sh文件将export JAVA_HOME=${JAVA_HOME}修改为：export JAVA_HOME=/usr/java/jdk1.8.0_144 说明：修改为自己的JDK路径和版本号 修改hdfs-site.xml修改./hadoop-2.8.1/etc/hadoop/hdfs-site.xml文件，在节点内加入配置: 1234567891011121314151617181920&lt;property&gt; &lt;name&gt;dfs.name.dir&lt;/name&gt; &lt;value&gt;/root/hadoop/dfs/name&lt;/value&gt; &lt;description&gt;Path on the local filesystem where theNameNode stores the namespace and transactions logs persistently.&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.data.dir&lt;/name&gt; &lt;value&gt;/root/hadoop/dfs/data&lt;/value&gt; &lt;description&gt;Comma separated list of paths on the localfilesystem of a DataNode where it should store its blocks.&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;description&gt;need not permissions&lt;/description&gt;&lt;/property&gt; 说明：dfs.permissions配置为false后，可以允许不要检查权限就生成dfs上的文件，方便倒是方便了，但是你需要防止误删除，请将它设置为true，或者直接将该property节点删除，因为默认就是true。 新建并且修改mapred-site.xml在该版本中，有一个名为mapred-site.xml.template的文件，复制该文件，然后改名为mapred-site.xml，命令是：1[root@server1 hadoop]# cp mapred-site.xml.template mapred-site.xml 修改这个新建的mapred-site.xml文件，在节点内加入配置:12345678910111213 &lt;property&gt; &lt;name&gt;mapred.job.tracker&lt;/name&gt; &lt;value&gt;server1:49001&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapred.local.dir&lt;/name&gt; &lt;value&gt;/root/hadoop/var&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt; 修改slaves文件 修改./hadoop-2.8.1/etc/hadoop/slaves文件，将里面的localhost删除，添加如下内容： 12server2server3 修改yarn-site.xml文件修改./hadoop-2.8.1/etc/hadoop/yarn-site.xml 文件，在节点内加入配置(注意了，内存根据机器配置越大越好): 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;server1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;The address of the applications manager interface in the RM.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8032&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;The address of the scheduler interface.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8030&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;The http address of the RM web application.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8088&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;The https adddress of the RM web application.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.webapp.https.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8090&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8031&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;The address of the RM admin interface.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8033&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt; &lt;value&gt;1024&lt;/value&gt; &lt;discription&gt;每个节点可用内存,单位MB,默认8182MB&lt;/discription&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt; &lt;value&gt;2.1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt; &lt;value&gt;1024&lt;/value&gt;&lt;/property&gt; 说明：yarn.nodemanager.vmem-check-enabled 这个的意思是忽略虚拟内存的检查，如果你是安装在虚拟机上，这个配置很有用，配上去之后后续操作不容易出问题。如果是实体机上，并且内存够多，可以将这个配置去掉。 启动Hadoop在namenode上执行初始化 因为server1是namenode，server2和server3都是datanode，所以只需要对server1进行初始化操作，也就是对hdfs进行格式化。进入到server1这台机器的/opt/hadoop-2.8.1/bin目录，执行初始化命令：./hadoop namenode -format ，格式化一个新的分布式文件系统。如下12345678910111213[root@server1 bin]# cd /opt/hadoop-2.8.1/bin/ [root@server1 bin]# ./hadoop namenode -format DEPRECATED: Use of this script to execute hdfs command is deprecated.Instead use the hdfs command for it.17/10/19 15:09:05 INFO namenode.NameNode: STARTUP_MSG: /************************************************************STARTUP_MSG: Starting NameNodeSTARTUP_MSG: user = rootSTARTUP_MSG: host = server1/192.168.19.185STARTUP_MSG: args = [-format]STARTUP_MSG: version = 2.8.1STARTUP_MSG: classpath = /opt/hadoop-2.8.1/etc/hadoop:/opt/hadoop-2.8.1/share/ 执行完成，不报错，说明启动成功。 格式化成功后，可以在看到在/root/hadoop/dfs/name/目录多了一个current目录，而且该目录内有一系列文件。 在namenode上执行启动命令因为server1是namenode，server2和server3都是datanode，所以只需要再server1上执行启动命令即可。进入到hserver1这台机器的/opt/hadoop-2.8.1/sbin目录，也就是执行命令：cd /opt/hadoop/hadoop-2.8.0/sbin执行初始化脚本，也就是执行命令：./start-all.sh第一次执行上面的启动命令，会需要我们进行交互操作，在问答界面上输入yes回车 1234567891011121314151617181920212223242526[root@server1 hadoop-2.8.1]# sbin/start-all.sh This script is Deprecated. Instead use start-dfs.sh and start-yarn.shStarting namenodes on [server1]server1: namenode running as process 3609. Stop it first.server3: starting datanode, logging to /opt/hadoop-2.8.1/logs/hadoop-root-datanode-server3.outserver2: datanode running as process 17888. Stop it first.server3: [Fatal Error] yarn-site.xml:16:1: Content is not allowed in prolog.Starting secondary namenodes [0.0.0.0]0.0.0.0: secondarynamenode running as process 3795. Stop it first.starting yarn daemonsresourcemanager running as process 3942. Stop it first.server3: starting nodemanager, logging to /opt/hadoop-2.8.1/logs/yarn-root-nodemanager-server3.outserver2: nodemanager running as process 18038. Stop it first.server3: [Fatal Error] yarn-site.xml:16:1: Content is not allowed in prolog.[root@server1 hadoop-2.8.1]# sbin/start-all.sh This script is Deprecated. Instead use start-dfs.sh and start-yarn.shStarting namenodes on [server1]server1: namenode running as process 3609. Stop it first.server3: starting datanode, logging to /opt/hadoop-2.8.1/logs/hadoop-root-datanode-server3.outserver2: datanode running as process 17888. Stop it first.Starting secondary namenodes [0.0.0.0]0.0.0.0: secondarynamenode running as process 3795. Stop it first.starting yarn daemonsresourcemanager running as process 3942. Stop it first.server2: nodemanager running as process 18038. Stop it first.server3: starting no 没报错，说明执行成功，之前我的server3 上的一个xml 配置错了，很明了的说出了错误的位置。 测试hadoop启动后，需要测试能使用，才能说明配置正确 首先需要关闭防火墙。 1[root@server1 ~]# systemctl stop firewalld.service 我们的namanode机器是server1，IP是192.168.19.185，直接在谷歌浏览器上输入到端口 50070，自动跳转到了overview页面 （dfshealth.html） 继续；测试 8088 端口 ：自动跳转到了cluster页面 在namenode机器上执行jps12345[root@server1 hadoop-2.8.1]# jps12469 ResourceManager12119 NameNode12313 SecondaryNameNode12730 Jps 在datanode机器上执行jps1234[root@server3 hadoop-2.8.1]# jps10776 NodeManager11114 Jps10635 DataNode 这只能证明它们启动成功，还要看它们之间互相通信。出现datanode 机器，通信成功。 配置完成。 参考博客： http://blog.csdn.net/pucao_cug/article/details/71698903]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 安装JDK和环境变量的配置]]></title>
    <url>%2Flinux-jdk.html</url>
    <content type="text"><![CDATA[系统环境：centos7 安装方式：rpm安装 版本：jdk1.8.0_144 首先查看电脑的 jdk1234[root@server2 ~]# java -versionopenjdk version "1.8.0_102"OpenJDK Runtime Environment (build 1.8.0_102-b14)OpenJDK 64-Bit Server VM (build 25.102-b14, mixed mode) 是默认安装的openjdk 不是我们需要的oracle 版本的，安装前需要卸载 。123456789101112131415161718[root@server2 ~]# rpm -qa | grep javajavapackages-tools-3.4.1-11.el7.noarchjava-1.8.0-openjdk-headless-1.8.0.102-4.b14.el7.x86_64java-1.7.0-openjdk-headless-1.7.0.111-2.6.7.8.el7.x86_64tzdata-java-2016g-2.el7.noarchjava-1.8.0-openjdk-1.8.0.102-4.b14.el7.x86_64java-1.7.0-openjdk-1.7.0.111-2.6.7.8.el7.x86_64python-javapackages-3.4.1-11.el7.noarch[root@server2 ~]# rpm -e --nodeps tzdata-java-2016g-2.el7.noarch[root@server2 ~]# rpm -e -nodeps java-1.7.0-openjdk-headless-1.7.0.111-2.6.7.8.el7.x86_64rpm: -nodeps: unknown option[root@server2 ~]# rpm -e -nodeps java-1.8.0-openjdk-1.8.0.102-4.b14.el7.x86_64rpm: -nodeps: unknown option[root@server2 ~]# rpm -e --nodeps java-1.8.0-openjdk-headless-1.8.0.102-4.b14.el7.x86_64^[[A[root@server2 rpm -e --nodeps java-1.7.0-openjdk-headless-1.7.0.111-2.6.7.8.el7.x86_64[root@server2 ~]# rpm -e --nodeps java-1.8.0-openjdk-1.8.0.102-4.b14.el7.x86_64[root@server2 ~]# rpm -e --nodeps java-1.7.0-openjdk-1.7.0.111-2.6.7.8.el7.x86_64 最后查看卸载完成12[root@server2 ~]# java -version-bash: /usr/bin/java: No such file or directory 下载jdk官网下载 安装JDK我下载的是rpm 文件，12345678910111213[root@server2 opt]# rpm -ivh jdk-8u144-linux-x64.rpm Preparing... ################################# [100%]Updating / installing... 1:jdk1.8.0_144-2000:1.8.0_144-fcs rpm ( 1%################################# [100%]Unpacking JAR files... tools.jar... plugin.jar... javaws.jar... deploy.jar... rt.jar... jsse.jar... charsets.jar... localedata.jar... 默认安装的是路径是 /usr/java 配置环境变量在 /etc/profile 文件中加入 12JAVA_HOME=/usr/java/jdk1.8.0_144 PATH=$JAVA_HOME/bin:$PATH CLASSPATH=$JAVA_HOME/jre/lib/ext:$JAVA_HOME/lib/tools.jar export PATH JAVA_HOME CLASSPATH 使生效12[root@server2 opt]# source /etc/profile-bash: jre/lib/ext:/usr/java/jdk1.8.0_144/lib/tools.jar: No such file or directory 查看系统环境状态path 是否生效12[root@server2 opt]# echo $PATH /usr/java/jdk1.8.0_144/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin 完成。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20171018]]></title>
    <url>%2F20171018.html</url>
    <content type="text"><![CDATA[最近看她的空间留言，写了又删，删了又写，心里也和不是滋味，现在一想起她，就想到昨天见到第一眼她那种憔悴的面容，真是令人疼惜。我想可能真的不应该去见她吧，弄得现在都没能说上两句话，可能是我太自私了点，打破了一点存留下的美好吧。 最近脑经确实有点炸裂，确实不怎么敢再去看她的空间了，不想再去看那种互相残忍的伤害的局面，不知道他们心里怎么想的，我根本就不想明白，明白的越多，失望估计也就越大了。突然想起，以前那么长时间公司有网，有wifi 也要强忍着不上QQ 不看手机， 就是怕突然看到她的动态，就像一下子惊起梦中的我，然后开始梦游，梦游开始不知觉中触碰各种神经，幻想着有人来刺伤自己。 自从昨天打通了她的手机，今天就无时无刻的想起要去给她拨号过去，问下，你怎么现在再干嘛，过得怎么样了。想着，还是算了，昨天她见到我那种惊慌失措的样子，是真的可爱极了，她一直说她很忙，口中支支吾吾的说还有什么事情没做完。我也是那种慢热的人，做事总是顾及其他，想想还是放下，生怕打扰她，弄不好什么时候又要拉黑了。 想着今晚再打过去吧，不论对错，或许，相见不如怀念，至少能不必再给她带来更多的压力，我想我这个人根本就读不懂女人的心吧，就是直嘛，也好，不要去想那些隐喻，也不要去有那些烦恼，姑且就将自己的快乐带给她人。 既然她想做个坚强的人，就希望她永远做个坚强的女人吧，不要轻易的被击倒。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 上永久修改hostname]]></title>
    <url>%2Flinux-hostname.html</url>
    <content type="text"><![CDATA[由于要做Hadoop集群，需要修改系统的hostname 做一个映射，hostname 命令只能临时修改，重启就会失效，为了有效性，所以需要永久修改系统的hostname。 百度了下，网上都是说修改 /etc/sysconfig/network 配置文件，修改hostname参数，reboot 重启后也生效，然而我这样做了并没有生效，而且我打开这个配置文件，并没有Hostname 参数，完全是自己后来加上去的，它里面只有一句话 # Created by anaconda。 操作临时生效使用 hostname 命令 ，hostname ，系统重启后失效。123456[root@localhost ~]# hostnamelocalhost.localdomain[root@localhost ~]# hostname server1[root@localhost ~]# hostnameserver1[root@localhost ~]# 也可以直接cat /proc/sys/kernel/hostname查看。12[root@localhost ~]# cat /proc/sys/kernel/hostnameserver1 hostname newname 即要设置的新的hostname，运行后立即生效，但是在系统重启后会丢失所做的修改，如果要永久更改系统的hostname，就要修改相关的设置文件。 永久更改Linux的hostnameman hostname里有这么一句话， The host name is usually set once at system startup in/etc/rc.d/rc.inet1 or /etc/init.d/boot (normally by reading thecontents of a file which contains the host name, e.g. /etc/hostname).” RedHat里没有这个文件，而是由/etc/rc.d/rc.sysinit这个脚本负责设置系统的hostname，它读取/etc/sysconfig/network这个文本文件，RedHat的hostname就是在这个文件里设置。 所以，如果要永久修改RedHat的hostname，就修改/etc/sysconfig/network文件，将里面的HOSTNAME这一行修改成 HOSTNAME=NEWNAME，其中NEWNAME就是你要设置的hostname。 Debian发行版的hostname的配置文件是/etc/hostname。 修该配置文件后，重启系统就会读取配置文件设置新的hostname。 我想我就是 Debian发行版 吧 执行12[root@localhost ~]# vim /etc/hostname localhost.localdomain 果然是这里，直接修改，保存，退出，重启。再去查看Hostname123[root@server1 ~]# hostnameserver1[root@server1 ~]# 修改成功 hostname与/etc/hosts的关系很过人一提到更改hostname首先就想到修改/etc/hosts文件，认为hostname的配置文件就是/etc/hosts。其实不是的。 hosts文件的作用相当如DNS，提供IP地址到hostname的对应。 早期的互联网计算机少，单机hosts文件里足够存放所有联网计算机。 不过随着互联网的发展，这就远远不够了。于是就出现了分布式的DNS系统。由DNS服务器来提供类似的IP地址到域名的对应。具体可以man hosts。 Linux系统在向DNS服务器发出域名解析请求之前会查询/etc/hosts文件，如果里面有相应的记录，就会使用hosts里面的记录。/etc/hosts文件通常里面包含这一条记录1127.0.0.1 localhost.localdomain localhost hosts文件格式是一行一条记录，分别是IP地址 hostname aliases，三者用空白字符分隔，aliases可选。 127.0.0.1到localhost这一条建议不要修改，因为很多应用程序会用到这个，比如sendmail，修改之后这些程序可能就无法正常运行。在/etc/hosts 添加12192.168.19.185 server1192.168.19.184 server2 ping server2 能ping 通说明1234567[root@server1 ~]# ping server2 PING server2 (192.168.19.184) 56(84) bytes of data.64 bytes from server2 (192.168.19.184): icmp_seq=1 ttl=64 time=0.421 ms64 bytes from server2 (192.168.19.184): icmp_seq=2 ttl=64 time=0.602 ms64 bytes from server2 (192.168.19.184): icmp_seq=3 ttl=64 time=0.304 ms64 bytes from server2 (192.168.19.184): icmp_seq=4 ttl=64 time=1.10 ms64 bytes from server2 (192.168.19.184): icmp_seq=5 ttl=64 time=0.545 ms 还有一个问题123456[root@localhost ~]# hostnamelocalhost.localdomain[root@localhost ~]# vim /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.19.199 server3 重启系统后发现123[root@server3 ~]# hostnameserver3[root@server3 ~]# hostname 被修改了 在 /etc/rc.d/rc.sysinit 这个启动脚本里发现了问题的所在。rc.sysinit文件里一开始就设置了hostname。123456if [ -f /etc/sysconfig/network ]; then. /etc/sysconfig/networkfiif [ -z "$HOSTNAME" -o "$HOSTNAME" = "(none)" ]; thenHOSTNAME=localhostfi 确实使用了/etc/sysconfig/network 里的hostname值。不过后面还有一段关于设置hostname的 12345678910ipaddr=if [ "$HOSTNAME" = "localhost" -o "$HOSTNAME" = "localhost.localdomain" ]; thenipaddr=$(ip addr show to 0/0 scope global | awk '/[[:space:]]inet/ &#123; print gensub("/.*","","g",$2) &#125;')if [ -n "$ipaddr" ]; theneval $(ipcalc -h $ipaddr 2&gt;/dev/null)hostname $&#123;HOSTNAME&#125;fifi 脚本判断hostname是否为localhost或者localhost.localdomain，如果是的话，将会使用接口IP地址对应的 hostname来重新设置系统的hostname。问题就出在这里，我的/etc/sysconfig/network 默认的hostname是 localhost.localdomain，它的IP是192.168.19.199，而/etc/hosts里有192.168.19.199的记录。 于是就用192.168.19.199这条记录来替换了hostname。 估计这也是很多人将/etc/hosts误以为是hostname的配置文件的原因。 总结 查看hostname : hostname 临时修改: hostname vim /etc/hosts 修改 hostname 参数为 newname vim /etc/sysconfig/network 修改 hostname 参数为 newname 参考博客 http://blog.csdn.net/yangshangwei/article/details/52878530]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20171017]]></title>
    <url>%2F20171017.html</url>
    <content type="text"><![CDATA[我想我是个固执的人吧，今天上午看到你跟我说她胃疼，最终还是下定决心，去学校见见她吧。 中午下班跟经理打声招呼说下午晚点来，得到回应马上就出发了，第一站是来到药店帮忙询问下暖胃的药吧，平时自己吃过的拿吧，外加一盒消炎的。 我到了学校，我感觉到我已经怂了，好多年没见她了，能把她叫出来吗，经历一段波折，通过手机还是成功约出了她，最终在人海的广场上看到了她，第一眼看上去她看起来憔悴了好多，人也是超级的瘦弱，心中都是一阵疼痛，这么一段时间，人都成什么样子了，这么突然的见面，在这种场合，都有些紧张吧，曾经说，最喜欢看的就是她的眼睛了，现在突然不敢看了，是内心的愧疚吧。 在遇见她的时候，感觉到内心好像充满了惊喜，又有点害怕马上消失，我想是我真的还没准备好，自己现在还是像以前一样的差劲，不敢怎么看她，但是就是这么恰巧，她就这么的一直住在我心里。 她就这样在前面走着，我就在旁边跟着，真是个大傻蛋啊，但是我当时真的什么也想不到说什么了，因为脑子想的都是她，杂乱到无法思考我是来干嘛的，怎么聊下去。说了点心里话，她却一直浅浅的回应，就像手足无措的孩子一样，人还往树上撞，我是超级的难受啊，这样的人怎么去照顾好自己，真的想过去抓住她的手，跟她说，跟着我吧。期间问了她以后想去哪，她说哪里工资高就去哪，我问，你不是那种缺钱的人吧；她回答得那么快，生活开支很高的，我明白她，其实她是个很节俭的人，没什么攀比的，只是想让身边的人过得更好些吧，却一直在逞强着，难受。我随口提了下为什么会留在武汉吧，以前对她说过，她大概忘了，我也不想再提了，或许，很难受，即使不难受，也没人敢承诺一辈子能在一个地方工作的，承诺太多，都是废话了，再自己没信心办好一件事的时候，再也不会去承诺了，我只是轻轻的告诉自己，以后跟着你了。说了下以前高中的时候，我想我可能是个固执的人，这么多年都没能忘记她，内心都是你，这个姑娘，真是个骗子，居然跟我小声说可能不合适。。。当然说的好多我走的时候都想不起来。。有点情绪了。 最后很简单，她送我离开了，走的时候看着她，她太害羞了，她见到我那种惊慌失措的样子，是真的可爱极了，她一直说她很忙，口中支支吾吾的说还有什么事情没做完，我也没听清，压根没打算听这些无用的话语，我将药给她了，离开了，没去追回她，看着她那孤单的背影，真想抱一下，心里真的好想去懂她啊，只是留了张背影照片，模糊了视线。告诉她，等我。 好好善待自己，活出最美丽的自己，多么希望有些事情不要变了。 我想我也是个大傻蛋，中午没吃饭，赶回来两点半，吃了两个包子，混了个苹果，就是直接困了一下午吧，，，]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Log4j格式输出工具类]]></title>
    <url>%2Fcustom-log.html</url>
    <content type="text"><![CDATA[将输出的Log日志进行输出到指定位置，控制台、文件、邮件和数据库等，需要对每一条日志的输出格式，把日志分为不同的级别，写一个工具类可以把日志信息格式化输出到 控制台 或 文件等。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127import java.io.PrintWriter;import java.io.StringWriter;import org.apache.log4j.Logger;/** * @ClassName: Log * @Description: LOG工具类* @author * @date* */public class Log &#123; public static Logger log = Logger.getLogger(Log.class); /** * 打印警告 * * @param obj */ public static void warn(Object obj) &#123; try&#123; /*** 获取输出信息的代码的位置 ***/ String location = ""; StackTraceElement[] stacks = Thread.currentThread().getStackTrace(); location = stacks[2].getClassName() + "." + stacks[2].getMethodName() + "(" + stacks[2].getLineNumber() + ")"; /*** 是否是异常 ***/ if (obj instanceof Exception) &#123; Exception e = (Exception) obj; StringWriter sw = new StringWriter(); e.printStackTrace(new PrintWriter(sw, true)); String str = sw.toString(); log.warn(location + str); &#125; else &#123; log.warn(location + obj.toString()); &#125; &#125;catch (Exception e) &#123; log.error(e); &#125; &#125; /** * 打印信息 * * @param obj */ public static void info(Object obj) &#123; try&#123; /*** 获取输出信息的代码的位置 ***/ String location = ""; StackTraceElement[] stacks = Thread.currentThread().getStackTrace(); location = stacks[2].getClassName() + "." + stacks[2].getMethodName() + "(" + stacks[2].getLineNumber() + ")"; /*** 是否是异常 ***/ if (obj instanceof Exception) &#123; Exception e = (Exception) obj; StringWriter sw = new StringWriter(); e.printStackTrace(new PrintWriter(sw, true)); String str = sw.toString(); log.info(location + str); &#125; else &#123; log.info(location + obj.toString()); &#125; &#125;catch (Exception e) &#123; log.error(e); &#125; &#125; /** * 打印错误 * * @param obj */ public static void error(Object obj) &#123; try&#123; /*** 获取输出信息的代码的位置 ***/ String location = ""; StackTraceElement[] stacks = Thread.currentThread().getStackTrace(); location = stacks[2].getClassName() + "." + stacks[2].getMethodName() + "(" + stacks[2].getLineNumber() + ")"; /*** 是否是异常 ***/ if (obj instanceof Exception) &#123; Exception e = (Exception) obj; StringWriter sw = new StringWriter(); e.printStackTrace(new PrintWriter(sw, true)); String str = sw.toString(); log.error(location + str); &#125; else &#123; log.error(location + obj.toString()); &#125; &#125;catch (Exception e) &#123; log.error(e); &#125; &#125; /** * debug * * @param obj */ public static void debug(Object obj) &#123; try&#123; /*** 获取输出信息的代码的位置 ***/ String location = ""; StackTraceElement[] stacks = Thread.currentThread().getStackTrace(); location = stacks[2].getClassName() + "." + stacks[2].getMethodName() + "(" + stacks[2].getLineNumber() + ")"; /*** 是否是异常 ***/ if (obj instanceof Exception) &#123; Exception e = (Exception) obj; StringWriter sw = new StringWriter(); e.printStackTrace(new PrintWriter(sw, true)); String str = sw.toString(); log.debug(location + str); &#125; else &#123; log.debug(location + obj.toString()); &#125; &#125;catch (Exception e) &#123; log.error(e); &#125; &#125;&#125; 代码忘了从哪里copy 过来的，暂时是这么用的，感觉可以自己定制打印这个规则很好，而且使用的时候直接调用静态方法就可以了，在也不用去各个类上面获取Logger 。 测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package com.devframe.util; import org.junit.Test; import org.junit.Before; import org.junit.After; /** * Log Tester. * * @author Zhang Kai * @since &lt;pre&gt;10/17/2017&lt;/pre&gt; * @version 1.0 */ public class LogTest &#123; @Beforepublic void before() throws Exception &#123; &#125; @Afterpublic void after() throws Exception &#123; &#125; /** * * Method: warn(Object obj) * */ @Testpublic void testWarn() throws Exception &#123; //TODO: Test goes here... Log.warn("他真的很喜欢你 像春雨下得淅淅沥沥");&#125; /** * * Method: info(Object obj) * */ @Testpublic void testInfo() throws Exception &#123; //TODO: Test goes here... Log.info("他真的很喜欢你 像夏日聒噪的蝉鸣");&#125; /** * * Method: error(Object obj) * */ @Testpublic void testError() throws Exception &#123; //TODO: Test goes here... Log.error("他真的很想念你 像秋叶落得悄无声息");&#125; /** * * Method: debug(Object obj) * */ @Testpublic void testDebug() throws Exception &#123; //TODO: Test goes here... Log.debug("他真的很喜欢你 想冬天的雪沁在心里");&#125; &#125; 测试结果， 这样定制的结果，更符合我们的阅读习惯，更加清晰的查看日志内容]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>log4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中Log4j的使用及配置详情]]></title>
    <url>%2Fjava-log4j.html</url>
    <content type="text"><![CDATA[Log4j是Apache的一个开源项目，通过使用Log4j，我们可以控制日志信息输送的目的地是控制台、文件、GUI组件，甚至是套接口服务器、NT的事件记录器、UNIX Syslog守护进程等；我们也可以控制每一条日志的输出格式；通过定义每一条日志信息的级别，我们能够更加细致地控制日志的生成过程。最令人感兴趣的就是，这些可以通过一个配置文件来灵活地进行配置，而不需要修改应用的代码。 项目中日志功能十分强大，可以实时监控你的代码的运行情况，并且就像书页一样清晰可见。 环境首先在pom.xml 配置好相关依赖，我这里只使用Log4j，当然还可以使用slf4j 可以管理，123456&lt;log4j.version&gt;1.2.16&lt;/log4j.version&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; 在web.xml 监听 log4j.properties12345678&lt;!-- 启动Log4j --&gt; &lt;context-param&gt; &lt;param-name&gt;log4jConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:log4j.properties&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.util.Log4jConfigListener&lt;/listener-class&gt; &lt;/listener&gt; 配置log4j.properties 配置文件12345678log4j.rootLogger=DEBUG, stdout , R log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern=[QC] %p [%t] %C.%M(%L) | %m%n log4j.appender.R=org.apache.log4j.DailyRollingFileAppender log4j.appender.R.File=d://log//FTASWorkFlow.log log4j.appender.R.layout=org.apache.log4j.PatternLayout log4j.appender.R.layout.ConversionPattern=%d-[TS] %p %t %c - %m%n&lt;/span&gt; 说明rootLogger也可以写作rootCategory,rootLogger value的含义第一个逗号前表示log的级别：FATAL,ERROR,WARN,INFO,DEBUG,级别依次降低，开发的时候一般选作DEBUG，上线前期可以INFO或者DEBUG，版本稳定了可以WARN或者ERROR。稳定以后可以每天将日志发送到你的邮箱（至于怎么发，看最下面的Appender），这样就不需要每天去看检查上线的项目有没有异常。 第一个逗号后面的表示你定义的appender，比如我们这里定义了stdout和R，这个名字可以随便定，和下面的对应就好了。这里的stdout代表控制台输出，上线的时候别忘记关掉，直接在rootLogger里去掉stdout就好了。 Log4j提供的appender有以下几种：123456org.apache.log4j.ConsoleAppender（控制台）org.apache.log4j.FileAppender（文件）org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件）org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生新文件）org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方）ConsoleAppender和DailyRollingFileAppender以及RollingFileAppender用的比较多，后面两个用哪个看需求。 log4j提供以下4种布局样式：不同的Appender有不同的属性，但是Appender都会有一个属性layout，layout又有一个属性PatternLayout1234org.apache.log4j.HTMLLayout（以HTML表格形式布局）org.apache.log4j.PatternLayout（可以灵活地指定布局模式，就是可以自定义输出样式），org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串），org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息） 再看一下PatternLayout的值代表的什么意思%d 输出日志时间点的日期或时间，紧跟一对花括号进行自定义格式%t 输出产生该日志事件的线程名%c 输出所属的类目，通常就是所在类的全名%l 输出行号%m 输出代码中指定的消息%n 输出一个回车换行符，Windows平台为 \r\n，Unix平台为 \n，也就是一跳消息占用一行，所以%m%n基本都是一起用%p 输出优先级，即DEBUG，INFO，WARN，ERROR，FATAL 我们经常会看到[%-5p]这样的用法，就是对%p进行格式化，占用几个字符空间，因为INFO，DEBUG他们有的占用4个有的占用5个，日志看起来不对其，进行一个格式化而已。%r 输出自应用启动到输出该log信息耗费的毫秒数%c 输出所属的类目，通常就是所在类的全名%x 输出对齐 再看看appender的其他属性123log4j.appender.FILE.File=D:/logs/log4j.log --------定义输出文件的位置及文件名log4j.appender.FILE.MaxFileSize=1MB --------定义每个文件的大小，超过这个大小，则新建一个文件，注意单位 MB 或 KBlog4j.appender.D.Threshold = DEBUG --------输出DEBUG级别以上的日志 输出到邮件12345678910111213141516171819log4j.appender.MAIL=org.apache.log4j.net.SMTPAppender（指定输出到邮件）log4j.appender.MAIL.Threshold=FATALlog4j.appender.MAIL.BufferSize=10log4j.appender.MAIL.From=chenyl@hollycrm.com（发件人）log4j.appender.MAIL.SMTPHost=mail.hollycrm.com（SMTP服务器）log4j.appender.MAIL.Subject=Log4J Messagelog4j.appender.MAIL.To=chenyl@hollycrm.com（收件人）log4j.appender.MAIL.layout=org.apache.log4j.PatternLayout（布局）log4j.appender.MAIL.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n（格式） 输出到数据库log4j.appender.DATABASE=org.apache.log4j.jdbc.JDBCAppender（指定输出到数据库）log4j.appender.DATABASE.URL=jdbc:mysql://localhost:3306/test（指定数据库URL）log4j.appender.DATABASE.driver=com.mysql.jdbc.Driver（指定数据库driver）log4j.appender.DATABASE.user=root（指定数据库用户）log4j.appender.DATABASE.password=root（指定数据库用户密码）log4j.appender.DATABASE.sql=INSERT INTO LOG4J (Message) VALUES (&apos;[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n&apos;)（组织SQL语句）log4j.appender.DATABASE.layout=org.apache.log4j.PatternLayout（布局）log4j.appender.DATABASE.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n（格式） 我的项目最终配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566# Rules reminder:# DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL### 设置级别和目的地(这里多个目的地) ####级别为DEBUG#目的地为CONSOLE，zhangLog；zhangLog为自定义输出端，可随意命名log4j.rootLogger = DEBUG,CONSOLE,zhangLog### 这里的com.wuwii是我项目的包名，也就是在这个包记录日志时，开发阶段是只记录DEBUG及以上级别的日志，正式上线的时候可以改成INFO、ERROR#### 当然就可以设定特定包打印的级别log4j.logger.com.wuwii=DEBUG#Log4j提供的appender有以下几种：#org.apache.log4j.ConsoleAppender（控制台），#org.apache.log4j.FileAppender（文件），#org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件），#org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件），#org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方）### 输出到控制台 ###log4j.appender.CONSOLE = org.apache.log4j.ConsoleAppenderlog4j.appender.CONSOLE.Target = System.outlog4j.appender.CONSOLE.layout = org.apache.log4j.PatternLayoutlog4j.appender.CONSOLE.layout.ConversionPattern = %d&#123;ABSOLUTE&#125; %5p %c&#123;1&#125;:%L - %m%n# My logging configuration...## 可以设置特定工具的打印日志级别log4j.logger.org.mybatis.jpetstore=INFOlog4j.logger.com.ibatis=INFOlog4j.logger.com.ibatis.common.jdbc.SimpleDataSource=INFOlog4j.logger.com.ibatis.common.jdbc.ScriptRunner=INFOlog4j.logger.com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate=INFOlog4j.logger.java.sql.Connection = INFOlog4j.logger.java.sql.Statement = INFOlog4j.logger.java.sql.PreparedStatement = INFOlog4j.logger.java.sql.ResultSet = INFO### 输出到日志文件 ####写到文件中，并且追加log4j.appender.zhangLog = org.apache.log4j.DailyRollingFileAppender# 设置文件输出位置#log4j.appender.zhangLog.File =D\:\\debug.loglog4j.appender.zhangLog.File=$&#123;catalina.home&#125;/logs/wuwii/debug.log#log4j.appender.zhangLog.File =/var/debug/debug.loglog4j.appender.zhangLog.Append = true## 只输出DEBUG级别以上的日志log4j.appender.zhangLog.Threshold = DEBUG#&apos;.&apos;yyyy-MM-dd: 设置为每天产生一个新的文件#1)’.’yyyy-MM: 每月#2)’.’yyyy-ww: 每周#3)’.’yyyy-MM-dd: 每天#4)’.’yyyy-MM-dd-a: 每天两次#5)’.’yyyy-MM-dd-HH: 每小时#6)’.’yyyy-MM-dd-HH-mm: 每分钟log4j.appender.zhangLog.DatePattern = &apos;.&apos;yyyy-MM-dd#当文件达到2kb时，文件会被备份成&quot;debug.txt.1&quot;，新的&quot;log.txt&quot;继续记录log信息## 在DailyRollingFileAppender 没这个属性#log4j.appender.zhangLog.MaxFileSize = 2KB #最多建5个文件，当文件个数较多时，后面不再新建文件## 在DailyRollingFileAppender 没这个属性#log4j.appender.zhangLog.MaxBackupIndex = 5log4j.appender.zhangLog.layout = org.apache.log4j.PatternLayoutlog4j.appender.zhangLog.layout.ConversionPattern = %-d&#123;yyyy-MM-dd HH:mm:ss&#125; [%t:%r] - [%p] [%c&#123;1&#125;:%L] [%M] %m%n#设置子Logger是否继承父Logger的输出源#默认情况下子Logger会继承父Logger的appender，也就是说子Logger会在父Logger的appender里输出log4j.additivity.zhangLog = false 测试测试的类没有启动 web ，默认的是查找 resources 根目录下的 log4j.properties ，没有则找不到。123456789101112131415package com.wuwii.test;import org.apache.log4j.Logger;public class Log4jTest &#123; public static Logger logger1 = Logger.getLogger(Log4jTest.class); public static void main(String[] args) &#123; //logger1 logger1.trace(&quot;他真的很喜欢你 像春雨下得淅淅沥沥，trace&quot;); logger1.debug(&quot;他真的很喜欢你 像夏日聒噪的蝉鸣，debug&quot;); logger1.info(&quot;他真的很想念你 像秋叶落得悄无声息，info&quot;); logger1.warn(&quot;他真的很喜欢你 想冬天的雪沁在心里，warn&quot;); logger1.error(&quot;他真的很喜欢你 像狗本性难移，error&quot;); logger1.fatal(&quot;他真的很喜欢你 所以他可以一直没脸没皮，fatal&quot;); &#125;&#125; 运行代码后，我们可以看到控制台打印了： 因为我们设置了输入到控制台了，再去查看我们的打印日志文件的位置，也可以看到报错信息，使用的 是org.apache.log4j.DailyRollingFileAppender，并没有 maxBackupIndex 和 maxFileSize 属性，所以上面的配置文件也不正确，需要删掉这两行， 使用的是每天生成一个文件，前一天的备份成yyyy-MM-dd 符合。 打开文件看到 正确写入， Log4j的使用及配置就是这样的了。 参考博客 http://blog.csdn.net/zhengliusu/article/details/44619023]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>log4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用spring-test 结合JUnit完成单元测试]]></title>
    <url>%2Fspring-test.html</url>
    <content type="text"><![CDATA[Java web项目怎么能少了spring ,当然少不了代码的单元测试，学习一下spring-test 结合 JUnit 完成单元测试，这样做会有很多好处，可以不用写额外一些方法去重复加载 applicationContext ，而且可以事务回滚等特点。下面再详细介绍。 介绍很多人做单元测试的时候，还要在Before方法中，初始化Spring容器，导致容器被初始化多次。 123456@Before public void init() &#123; ApplicationContext ctx = new FileSystemXmlApplicationContext( "classpath:spring/spring-basic.xml"); baseDao = (IBaseDao) ctx.getBean("baseDao"); assertNotNull(baseDao); &#125; 在开发基于Spring的应用时，如果你还直接使用Junit进行单元测试，那你就错过了Spring满汉全席中最重要的一道硬菜。 再说这道菜之前，我们先来讨论下，在基于Spring的javaweb项目中使用Junit直接进行单元测试有什么不足 导致多次Spring容器初始化问题根据JUnit测试方法的调用流程，每执行一个测试方法都会创建一个测试用例的实例并调用setUp()方法。由于一般情况下，我们在setUp()方法中初始化Spring容器，这意味着如果测试用例有多少个测试方法，Spring容器就会被重复初始化多次。虽然初始化Spring容器的速度并不会太慢，但由于可能会在Spring容器初始化时执行加载Hibernate映射文件等耗时的操作，如果每执行一个测试方法都必须重复初始化Spring容器，则对测试性能的影响是不容忽视的； /////////使用Spring测试套件，Spring容器只会初始化一次！ 需要使用硬编码方式手工获取Bean 在测试用例类中我们需要通过ctx.getBean()方法从Spirng容器中获取需要测试的目标Bean，并且还要进行强制类型转换的造型操作。这种乏味的操作迷漫在测试用例的代码中，让人觉得烦琐不堪； ////////使用Spring测试套件，测试用例类中的属性会被自动填充Spring容器的对应Bean ，无须在手工设置Bean！ 数据库现场容易遭受破坏 测试方法对数据库的更改操作会持久化到数据库中。虽然是针对开发数据库进行操作，但如果数据操作的影响是持久的，可能会影响到后面的测试行为。举个例子，用户在测试方法中插入一条ID为1的User记录，第一次运行不会有问题，第二次运行时，就会因为主键冲突而导致测试用例失败。所以应该既能够完成功能逻辑检查，又能够在测试完成后恢复现场，不会留下“后遗症”； ////////使用Spring测试套件，Spring会在你验证后，自动回滚对数据库的操作，保证数据库的现场不被破坏，因此重复测试不会发生问题！ 不方便对数据操作正确性进行检查假如我们向登录日志表插入了一条成功登录日志，可是我们却没有对t_login_log表中是否确实添加了一条记录进行检查。一般情况下，我们可能是打开数据库，肉眼观察是否插入了相应的记录，但这严重违背了自动测试的原则。试想在测试包括成千上万个数据操作行为的程序时，如何用肉眼进行检查？ ////////只要你继承Spring的测试套件的用例类，你就可以通过jdbcTemplate在同一事务中访问数据库，查询数据的变化，验证操作的正确性！ 使用搭建环境在pom.xml中加入相关依赖 spring-test, JUnit 1234567891011121314&lt;junit.version&gt;4.12&lt;/junit.version&gt;&lt;spring.version&gt;4.2.4.RELEASE&lt;/spring.version&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;$&#123;junit.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; 需要注意使用前查看两个包相关版本能否兼容使用 创建测试类我使用的是JUnitGenerator自动生成的测试文件，后面再加入相关的 加载配置文件的注解，最后的代码是这样的：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687import com.devframe.entity.FarmEntity;import com.devframe.service.FarmService;import org.junit.Test;import org.junit.Before; import org.junit.After;import org.junit.runner.RunWith;import org.springframework.test.annotation.Rollback;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;import org.springframework.transaction.annotation.Transactional;import javax.annotation.Resource;import java.util.List;/** * FarmServiceImpl Tester. * * @author Zhang Kai * @since &lt;pre&gt;10/16/2017&lt;/pre&gt; * @version 1.0 */@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &#123;"classpath:spring/applicationContext-base.xml"&#125;)public class FarmServiceImplTest &#123; @ResourceFarmService service;@Beforepublic void before() throws Exception &#123; &#125; @Afterpublic void after() throws Exception &#123; &#125; /** * * Method: setBaseDao(FarmDao dao) * */ @Testpublic void testSetBaseDao() throws Exception &#123; //TODO: Test goes here... &#125; /** * * Method: findByOrgids(String pageindex, String pagesize, String where) * */ @Testpublic void testFindByOrgids() throws Exception &#123; //TODO: Test goes here... &#125; /** * * Method: updateFarm(FarmEntity farmEntity) * */ @Test@Transactional@Rollback(false)public void testUpdateFarm() throws Exception &#123; //TODO: Test goes here... String sql = "UPDATE \"AGRI_FARM\" SET \"REMARK\"='备注'"; service.executeUpdate(sql); String sql1 = "SELECT * FROM \"AGRI_FARM\""; List&lt;FarmEntity&gt; list = service.getBySql(sql1); System.out.println(list.get(0).getRemark());&#125; /** * * Method: exist(String name) * */ @Testpublic void testExist() throws Exception &#123; //TODO: Test goes here... &#125; &#125; 测试结果（表里面只有一条数据，简单写下，平时千万不要这样写，哈哈） 证明测试成功了 把rollback改成 true ,默认就是为true123456789101112131415161718@Resourceprivate FarmDao dao;/** * * Method: updateFarm(FarmEntity farmEntity) * */ @Test@Transactional//@Rollback(true)public void testUpdateFarm() throws Exception &#123; //TODO: Test goes here... dao.setRemarkValue("备注44"); String sql1 = "SELECT * FROM \"AGRI_FARM\""; List&lt;FarmEntity&gt; list = service.getBySql(sql1); System.out.println(list.get(0).getRemark());&#125; 测试结果 我update 的值是 “备注44” 查询出来的是 “备注11” ，后来一想这样自己写得有点傻了，其实这个方法写的没有一点用，现在只能证明数据库还没更改，但是事务还没结束嘛，肯定没入库，就不要介意了，就是这个意思了，测试完成看下数据变了没有，可以验证成功。 需要注意 的是不能使用自己写的事务，不然会覆盖掉spring 容器的Transactional，导致测试的事务不能回滚，直接保存到数据库中的。 之前一直被这个问题卡住了，设置了@Rollback(true)都不能成功回滚事务，睡了一觉才知道，这个executeUpdate方法中自己写了一个事务，12345678910111213141516/** * 删除表中的数据通过条件 * * @param sql：删改命令 * @return 执行是否成功 */@Transactionalpublic boolean executeUpdate(String sql) &#123; EntityManager em = emf.createEntityManager(); em.getTransaction().begin(); Query query = em.createNativeQuery(sql); int count = query.executeUpdate(); em.getTransaction().commit(); em.close(); return count &gt; 0;&#125; 就是这样的。改成自己再Dao层重新写了个测试方法。可以的了。到此结束了。 参考文章 http://blog.csdn.net/shan9liang/article/details/40452469]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JUnit</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven Scope定义值说明]]></title>
    <url>%2Fmaven-scope.html</url>
    <content type="text"><![CDATA[maven依赖关系中Scope的作用Dependency Scope 在POM 4中，中还引入了，它主要管理依赖的部署。目前可以使用5个值： compile，缺省值，适用于所有阶段，会随着项目一起发布。 provided，类似compile，期望JDK、容器或使用者会提供这个依赖。如servlet.jar。 runtime，只在运行时使用，如JDBC驱动，适用运行和测试阶段。 test，只在测试时使用，用于编译和运行测试代码。不会随项目发布。 system，类似provided，需要显式提供包含依赖的jar，Maven不会在Repository中查找它。 说明依赖范围控制哪些依赖在哪些classpath 中可用，哪些依赖包含在一个应用中。让我们详细看一下每一种范围： compile （编译范围）compile是默认的范围；如果没有提供一个范围，那该依赖的范围就是编译范围。编译范围依赖在所有的classpath 中可用，同时它们也会被打包。 provided （已提供范围）provided 依赖只有在当JDK 或者一个容器已提供该依赖之后才使用。例如，如果你开发了一个web 应用，你可能在编译 classpath 中需要可用的Servlet API 来编译一个servlet，但是你不会想要在打包好的WAR 中包含这个Servlet API；这个Servlet API JAR 由你的应用服务器或者servlet 容器提供。已提供范围的依赖在编译classpath （不是运行时）可用。它们不是传递性的，也不会被打包。 runtime （运行时范围）runtime 依赖在运行和测试系统的时候需要，但在编译的时候不需要。比如，你可能在编译的时候只需要JDBC API JAR，而只有在运行的时候才需要JDBC驱动实现。 test （测试范围）test范围依赖 在一般的编译和运行时都不需要，它们只有在测试编译和测试运行阶段可用。 system （系统范围）system范围依赖与provided 类似，但是你必须显式的提供一个对于本地系统中JAR 文件的路径。这么做是为了允许基于本地对象编译，而这些对象是系统类库的一部分。这样的构件应该是一直可用的，Maven 也不会在仓库中去寻找它。如果你将一个依赖范围设置成系统范围，你必须同时提供一个 systemPath 元素。注意该范围是不推荐使用的（你应该一直尽量去从公共或定制的 Maven 仓库中引用依赖）。 总结 默认的依赖范围是complie test范围指的是测试范围有效，在编译和打包时都不会使用这个依赖，为test的jar不会传递依赖项目； compile范围指的是编译范围有效，在编译和打包时都会讲依赖存储进去； provided依赖，在编译和测试的过程有效，最后生成var包时不会加入，诸如：servlet——api，因为servlet-api，tomcat等web服务器已经存在了，如果再打包会冲突； runtime在运行的时候依赖，在编译的时候不依赖； 参考博客 http://blog.csdn.net/ld513508088/article/details/23827945]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20171015]]></title>
    <url>%2F20171015.html</url>
    <content type="text"><![CDATA[每次看到你发的那些难过的句子， 我也感觉心快要化了， 你曾经说过， 不谈恋爱了就不会有烦恼了， 那现在我真的不希望你谈恋爱了，幸福真是个大鬼头，我从没有拥有过，也都对它失望了。 姑娘，你一定要好好照顾自己， 我在想好的女生都是被这样被逼的不想谈恋爱了吗， 在这段时间里，曾经天真活泼的你，瞬间就变得忧郁，有脾气了， 可能很多人认为你变了，不认识了吧。 虽然了解的你不多，但是我想你根本没变吧，只是善于伪装吧，伪装得太好，让别人看不出伤疤，看不到疼痛。 姑娘，真的没必要不要这样了，你说 心比长相好，懂比爱重要。我想一个对的人最起码不会让身边得人这么的难受，我想我虽然一直抱有幻想，但我可能也不是你生命中那个对的人，因为，我也伤害过你，现在留下的只有伤口和已经上锁的心。你这么优秀，没有什么错过的青春，错过的爱情，只是没遇到对的，总有一天，你可以等到那个对的人，宠着你的人，不让你难过的人，愿生活有诗，有梦，有远方，还有一个懂你、爱你的可心人。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Intellij使用JUnitGenerator V2.0自动生成单元测试代码]]></title>
    <url>%2Fjunitgenerator.html</url>
    <content type="text"><![CDATA[单元测试平时开发的时候是大有打交道了，使用Intellij后，发现有这个自动生成Junit 4 单元测试代码的插件，就是要说的 JUnitGenerator。 安装工具首先我的Intellij 版本是201702 settings -&gt; 搜索 JUnitGenerator 下载V2.0版本，安装插件，重启Intellij 设置安装完插件，我们就可以进行自动生成单元测试代码了。在要测试的类的页面，使用快捷键 Alt + Insert ，安装了JUnitGenerator 插件就会出现这个JUnit Test 选项，我们选择Junit 4 这个时候虽然能生成测试代码，但是你会发现，它生成的位置不是我们需要的，没有生成到test source 文件夹下，所以需要设置下它的生成目录， 打开首先我的Intellij的 settings -&gt; Other Settings -&gt; 选第一个。其中 Output Path 是设置我们自动生成的测试文件的位置，需要重新设置下到${SOURCEPATH}/../../test/java/${PACKAGE}/${FILENAME} 然后就是最后的日期格式乱码，点开JUnit 4 选项卡，将date 改成 today，里面是模板，可以根据自己的需求自己改，毕竟，测试代码的命名就没那么严格了。 环境我们使用的是Junit 4 的，肯定得先引入Junit 的依赖包，在pom.xml中加入它得依赖：12345&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt;&lt;/dependency&gt; 不然生成出来的代码会报错的，找不到Jar包。。 改了上面的，应该就没什么问题。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Intellij</tag>
        <tag>JUnitGenerator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Intellij 打包maven 项目，忽略单元测试代码]]></title>
    <url>%2Finstall-skip-test.html</url>
    <content type="text"><![CDATA[使用Eclipse 的maven 打包部署项目，以前都是直接直接勾选 Skip Tests 使用好像 Intellij 没有这个选项，只能使用maven 的命令 来进行这个操作，可以在项目的根目录直接1mvn install -DskipTests 或者1mvn install -Dmaven.test.skip=true 或者直接在 Intellij 中Install 的时候 带上参数，点开 Intellij中右侧 的 MAVEN PROJECT -&gt; Lifecycle -&gt; install -&gt;右键选择 Create… -&gt; 在 install 后面加上参数 -DskipTests 再去执行 SUCCESS!再去看看项目，单元测试代码没有打包。 更新，发现了Intellij，有 Skip Tests 选项 上面的小选项卡里的功能以前并没有注意到，仔细看了看，主要的还是跟Eclipse maven相似，只是源码可以自动下载，更强大了。。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[他真的很喜欢你]]></title>
    <url>%2Freally-love.html</url>
    <content type="text"><![CDATA[他真的很喜欢你，认真且怂，从一而终。 “何谓孤寂？”“清风，艳日，无笑意。”“可否具体？”“左拥，右抱，无情欲。”“可否再具体？”“不得你。” “何为思念？”“日月，星辰，旷野雨落。”“可否具体？”“山川，江流，烟袅湖泊。”“可否再具体？”“万物是你，无可躲。 “何为无救？”“良药、妙方，无可医。”“可否具体？”“扁鹊、华佗，俱无策。”“可否再具体？”“念你成疾。” “何谓求索？”“落霞，朝阳，七千里。”“可否具体？”“夏雨，冬雪，九万顷。”“可否再具体？”“追寻你。” “何谓伴侣？”“柴米，油盐，木栅栏。”“可否具体？”“粗茶，淡饭，执子手。”“可否再具体？”“和你。” “何谓漂泊？”“飞蓬，飘萍，无根底。”“可否具体？”“只鹤，孤雁，寒塘独下迟。”“可否再具体？”“南游，东出，客愁，旅思，离乡千万里。”“可否更具体？”“春行，秋度，杳杳无归期。”“仍是不解。”“浪迹云游，何处寻你。” “何谓难得？”“落虹，繁星，山间风。”“可否具体？”“雾凇，凤翎，黄粱梦。”“可否再具体？”“伴你而生，有始无终。” “何谓欢喜？”“清风，晓月，伴星辰。”“可否具体？”“一见，再见，已倾心。”“可否再具体？”“余光皆是你。” “何谓欣悦？”“四海，三山，两心。”“可否具体？”“两人，三餐，四季。”“可否再具体？”“与你。” “何谓愁？”“江湖，灯市，檐下躲雨。”“可否具体？”“孤舟，青衫，长亭垂柳。”“可否再具体？”“所见是你，无可避。” “何谓美人？”“纤手，漾眸，柔腰肢。”“可否具体？”“橘子香气。”“可否再具体？”“汝。” “何谓忧？”“无笑，无乐，郁积于心。”“可否具体？”“思你，念你，不得见你。”“可否再具体？”“你已无意。” “何谓空寂？”“抬头，艳阳，流云里。”“可否具体？”“飘摇，流浪，无归期。”“可否再具体？”“没等到你。” “何为习性？”“清茶，浊酒，和音伴。”“可否具体？”“跋山，涉水，曲随行。”“可否再具体？”“予你。” “何为等待？”“不知几分红颜悴，多少相思碎。”“可否详言？”“花开花落两不知，惟介音无回。”“可否甚解？”“一叶一追寻，待一人与归。” “何为距离？”“白云，大地，止相望。”“可否具体？”“树木，微风，终轻拂。”“可否再具体？”“你与我。” “何为思兮？”“惦念，不语，乱了心。”“可否具体？”“失神差可拟。”“可否再具体？”“哪里都是你。” “何谓心安？”“同月沽酌，千诗可叙”“可否具体？”“红色屋顶，白色窗棂。”“可否再具体？”“身边有你。” “何为心寒？”“白雪、冷雨，冻寒骨。”“可否具体？”“深夜、凌晨，无可分。”“可否再具体？”“你，已弃。” “何为归途？”“夜鸟 荒路 漫漫无期。”“可否具体 ？”“碎言 华灯 喧嚣无际。”“可否再具体？”“一诗 一酌 不觉千里。”“仍是不解。”“与你，四处为安。” “何谓笑意？”“单车，白衣，晴空万里”“可否具体？”“天台，茉莉，七月初七”“可否再具体？”“花裙，背影，安然静谧”“可否更具体？”“一看到你” “何谓卑微？”“清水，野草，无艳色。”“可否具体？”“爱情，亲情，无回报。”“可否再具体？”“入尘埃。” “何为知己？”“相视，不语，已了然”“可否具体？”“浮华万物皆可抛”“可否再具体？”“愿得你” 内容来自网易云《浮生》下面的热门的评论 侵删]]></content>
      <categories>
        <category>那些很美的句子</category>
      </categories>
      <tags>
        <tag>他真的很喜欢你</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java客户端使用Jedis操作Redis]]></title>
    <url>%2Fcatch-jedis.html</url>
    <content type="text"><![CDATA[写在前面搭建好redis ，这是我们需要在java中操作它，在这里我使用jedis ，这次主要使用redis，存储信息，到时间超时，并且自动删除超时信息，累计数据List，达到一定数量，入库，删除，所以这个时候为了数据安全，删除完，才去写入新数据，需要写一个简单的分布式锁。 编码准备，导入Jar包首先在pox.xml加入所需要的Jar 包： 1234567&lt;jedis.version&gt;2.9.0&lt;/jedis.version&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;$&#123;jedis.version&#125;&lt;/version&gt; &lt;/dependency&gt; 编写连接工具类首先编写工具类去连接redis：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;import redis.clients.jedis.JedisPoolConfig;import java.io.Serializable;/** * @ClassName: RedisUtil * @Description: redis工具类 * @author zhangkai * @date 2017年9月26日 下午3:20:29 * */public class RedisUtil implements Serializable&#123; private static final long serialVersionUID = -1149678082569464779L; //Redis服务器IP private static String addr; //Redis的端口号 private static int port; //访问密码 private static String auth; //可用连接实例的最大数目，默认值为8； //如果赋值为-1，则表示不限制；如果pool已经分配了maxActive个jedis实例，则此时pool的状态为exhausted(耗尽)。 private static int maxActive; //控制一个pool最多有多少个状态为idle(空闲的)的jedis实例，默认值也是8。 private static int maxIdle; //等待可用连接的最大时间，单位毫秒，默认值为-1，表示永不超时。如果超过等待时间，则直接抛出JedisConnectionException； private static int maxWait; @SuppressWarnings("unused") private static int timeOut; //在borrow一个jedis实例时，是否提前进行validate操作；如果为true，则得到的jedis实例均是可用的； private static boolean testOnBorrow; public static Jedis jedis;//非切片额客户端连接 public static JedisPool jedisPool;//非切片连接池 // public static ShardedJedis shardedJedis;//切片额客户端连接 // public static ShardedJedisPool shardedJedisPool;//切片连接池 static &#123; addr = PropertyUtil.get("redis.addr"); auth = PropertyUtil.get("redis.auth"); port = Integer.parseInt(PropertyUtil.get("redis.port")); maxIdle = Integer.parseInt(PropertyUtil.get("redis.maxIdle")); maxActive = Integer.parseInt(PropertyUtil.get("redis.maxActive")); maxWait = Integer.parseInt(PropertyUtil.get("redis.maxWait")); timeOut = Integer.parseInt(PropertyUtil.get("redis.timeOut")); testOnBorrow = PropertyUtil.get("redis.testOnBorrow").equals("true") ? true :false; initialPool(); &#125; public RedisUtil()&#123; initialPool(); jedis = getJedis(); &#125; /** * 初始化非切片池 */ private static void initialPool() &#123; // 池基本配置 JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(maxActive); config.setMaxIdle(maxIdle); config.setMaxWaitMillis(maxWait); config.setTestOnBorrow(testOnBorrow); jedisPool = new JedisPool(config, addr, port); &#125; /** * 获取Jedis实例 * @return */ public synchronized static Jedis getJedis() &#123; try &#123; if (jedisPool != null) &#123; jedis = jedisPool.getResource(); jedis.auth(auth);//认证 return jedis; &#125; else &#123; return null; &#125; &#125; catch (Exception e) &#123; Log.error(e); return null; &#125; &#125; /** * 释放jedis资源 * @param jedis */ public static void returnResource(final Jedis jedis) &#123; if (jedis != null) &#123; jedis.close(); &#125; &#125;&#125; 配置文件12345678910# Redis Settingsredis.addr=192.168.19.200redis.port=6379redis.auth=masterredis.maxIdle=300redis.maxActive=1024redis.maxWait=10000redis.timeOut=10000redis.testOnBorrow=false 使用连接上redis我们就可以使用jedis操作我们的redis，直接写业务 登陆，保存会话12345678910111213141516@Override public void login(String ucid) &#123; Jedis jedisindex = getJedis(); String key = "login" + ucid; try &#123; //设置登陆时常保存到30m，每次操作都会过来重新存下，重新刷新时间; jedisindex.expire(key, 1800); //TODO code &#125; catch (Exception e) &#123; LOGGER.error(e.getMessage(), e); &#125; finally &#123; returnResource(jedisindex); &#125; &#125; 使用redis完成分布式锁当一个用户满60条数据，进行数据入库，使用分布式锁12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * xxxxxxx * * @param key * @param track * 满到60个 TIDD add */ private void addTrack(String ucid, String track, Jedis jedisindex) &#123; try &#123; Boolean lockFlag = false; while (!lockFlag) &#123; lockFlag = lock("lock" + ucid, jedisindex); //上锁 if (!lockFlag) continue; jedisindex.lpush(ucid, track); long len = jedisindex.llen(ucid); //历史轨迹中总点数 int pointNum = Integer.valueOf(PropertyUtil.get("POINT_NUM")); if (pointNum &lt; 1) return; if (len &gt;= pointNum) &#123; addHistoryTrack(ucid, jedisindex.lrange(ucid, 0, pointNum - 1), jedisindex, pointNum); &#125; unlock("lock" + ucid, jedisindex); //释放锁 &#125; &#125; catch (Exception e) &#123; LOGGER.error(e.getMessage(), e); &#125; &#125; private static final int LOCK_TIMEOUT = 1; //加锁超时时间 单位秒 意味着加锁期间内执行完操作 如果未完成会有并发现象 /** * 上锁 */ @Override public Boolean lock(String lock, Jedis jedisindex) &#123; // 1. 通过SETNX试图获取一个lock boolean success = false; long value = System.currentTimeMillis() + LOCK_TIMEOUT * 1000 + 1; long acquired = jedis.setnx(lock, String.valueOf(value)); jedisindex.expire(lock, LOCK_TIMEOUT);//设置1秒超时 ,到时候自动释放锁 //SETNX成功，则成功获取一个锁 if (acquired == 1) success = true; return success; &#125; /** * 解锁 */ @Override public void unlock(String lock, Jedis jedisindex) &#123; jedisindex.del(lock); &#125; 总结： 使用jedis操作redis，使用的是spring 框架，可以使用Spring Data Redis ,更符合java spring框架依赖注入的特性，使用上大同小异。 使用多线程操作redis 不要把 jedis 存入到ThreadLocal 或各种全局变量中， 可能出现冲突。需要重新从jedisPool获取jedis，然后用完关闭连接就行。 学习： 以后了解对jedis关于事务、管道和分布式的使用。 常用命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990911）连接操作命令 quit：关闭连接（connection） auth：简单密码认证 help cmd： 查看cmd帮助，例如：help quit 2）持久化 save：将数据同步保存到磁盘 bgsave：将数据异步保存到磁盘 lastsave：返回上次成功将数据保存到磁盘的Unix时戳 shundown：将数据同步保存到磁盘，然后关闭服务 3）远程服务控制 info：提供服务器的信息和统计 monitor：实时转储收到的请求 slaveof：改变复制策略设置 config：在运行时配置Redis服务器 4）对value操作的命令 exists(key)：确认一个key是否存在 del(key)：删除一个key type(key)：返回值的类型 keys(pattern)：返回满足给定pattern的所有key randomkey：随机返回key空间的一个 keyrename(oldname, newname)：重命名key dbsize：返回当前数据库中key的数目 expire：设定一个key的活动时间（s） ttl：获得一个key的活动时间 select(index)：按索引查询 move(key, dbindex)：移动当前数据库中的key到dbindex数据库 flushdb：删除当前选择数据库中的所有key flushall：删除所有数据库中的所有key 5）String set(key, value)：给数据库中名称为key的string赋予值value get(key)：返回数据库中名称为key的string的value getset(key, value)：给名称为key的string赋予上一次的value mget(key1, key2,…, key N)：返回库中多个string的value setnx(key, value)：添加string，名称为key，值为value setex(key, time, value)：向库中添加string，设定过期时间time mset(key N, value N)：批量设置多个string的值 msetnx(key N, value N)：如果所有名称为key i的string都不存在 incr(key)：名称为key的string增1操作 incrby(key, integer)：名称为key的string增加integer decr(key)：名称为key的string减1操作 decrby(key, integer)：名称为key的string减少integer append(key, value)：名称为key的string的值附加value substr(key, start, end)：返回名称为key的string的value的子串 6）List rpush(key, value)：在名称为key的list尾添加一个值为value的元素 lpush(key, value)：在名称为key的list头添加一个值为value的 元素 llen(key)：返回名称为key的list的长度 lrange(key, start, end)：返回名称为key的list中start至end之间的元素 ltrim(key, start, end)：截取名称为key的list lindex(key, index)：返回名称为key的list中index位置的元素 lset(key, index, value)：给名称为key的list中index位置的元素赋值 lrem(key, count, value)：删除count个key的list中值为value的元素 lpop(key)：返回并删除名称为key的list中的首元素 rpop(key)：返回并删除名称为key的list中的尾元素 blpop(key1, key2,… key N, timeout)：lpop命令的block版本。 brpop(key1, key2,… key N, timeout)：rpop的block版本。 rpoplpush(srckey, dstkey)：返回并删除名称为srckey的list的尾元素，并将该元素添加到名称为dstkey的list的头部 7）Set sadd(key, member)：向名称为key的set中添加元素member srem(key, member) ：删除名称为key的set中的元素member spop(key) ：随机返回并删除名称为key的set中一个元素 smove(srckey, dstkey, member) ：移到集合元素 scard(key) ：返回名称为key的set的基数 sismember(key, member) ：member是否是名称为key的set的元素 sinter(key1, key2,…key N) ：求交集 sinterstore(dstkey, (keys)) ：求交集并将交集保存到dstkey的集合 sunion(key1, (keys)) ：求并集 sunionstore(dstkey, (keys)) ：求并集并将并集保存到dstkey的集合 sdiff(key1, (keys)) ：求差集 sdiffstore(dstkey, (keys)) ：求差集并将差集保存到dstkey的集合 smembers(key) ：返回名称为key的set的所有元素 srandmember(key) ：随机返回名称为key的set的一个元素 8）Hash hset(key, field, value)：向名称为key的hash中添加元素field hget(key, field)：返回名称为key的hash中field对应的value hmget(key, (fields))：返回名称为key的hash中field i对应的value hmset(key, (fields))：向名称为key的hash中添加元素field hincrby(key, field, integer)：将名称为key的hash中field的value增加integer hexists(key, field)：名称为key的hash中是否存在键为field的域 hdel(key, field)：删除名称为key的hash中键为field的域 hlen(key)：返回名称为key的hash中元素个数 hkeys(key)：返回名称为key的hash中所有键 hvals(key)：返回名称为key的hash中所有键对应的value hgetall(key)：返回名称为key的hash中所有的键（field）及其对应的value]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>redis</tag>
        <tag>jedis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于升级有道云笔记v6.0.0.1]]></title>
    <url>%2Fyoudao-note.html</url>
    <content type="text"><![CDATA[升级后有道云笔记确实有很大的改变，界面变得大方简洁了许多，但是左下角的广告还是在，免费版就不要介意了，网上又办法去掉它。反应速度快上不少，而且最爱的markdown语法看起来反应又快了，以前输入上了百行，拖动就有点卡了，难受得很。细心的人估计发现了，右下角多了一个图标，对的新版本多了三种模式：三栏模式、精简模式和编辑模式。试了一下，很优秀的一个功能。 当然更新是好事，但是我出现了个奇怪的问题，单击导航栏的目录，竟然不能预览文章。 就是直接说无预览，非要我进入编辑模式，才能看到文章。 无奈，网上搜也没搜到，只好去撩客服了。 清空就好了，重新登陆账户信息，浪费了不少时间了。。希望有道云笔记能越做越好吧。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Youdao Note</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CENTOS 7 中报错 java.net.ConnectException Connection refused]]></title>
    <url>%2Ftomcat-error01.html</url>
    <content type="text"><![CDATA[再centos7 中正常启动tomcat 9，但是发现项目都不能正常访问，去关闭tomcat 却报错，如下：123456789101112131415161718192021222324252627[root@localhost ~]# /opt/apache-tomcat-9.0.0.M22/bin/shutdown.sh Using CATALINA_BASE: /opt/apache-tomcat-9.0.0.M22Using CATALINA_HOME: /opt/apache-tomcat-9.0.0.M22Using CATALINA_TMPDIR: /opt/apache-tomcat-9.0.0.M22/tempUsing JRE_HOME: /opt/jdk1.8.0_131/jreUsing CLASSPATH: /opt/apache-tomcat-9.0.0.M22/bin/bootstrap.jar:/opt/apache-tomcat-9.0.0.M22/bin/tomcat-juli.jar十月 12, 2017 7:08:00 下午 org.apache.catalina.startup.Catalina stopServer严重: Could not contact [localhost:[8005]]. Tomcat may not be running.十月 12, 2017 7:08:00 下午 org.apache.catalina.startup.Catalina stopServer严重: Catalina.stop: java.net.ConnectException: 拒绝连接 (Connection refused) at java.net.PlainSocketImpl.socketConnect(Native Method) at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) at java.net.Socket.connect(Socket.java:589) at java.net.Socket.connect(Socket.java:538) at java.net.Socket.&lt;init&gt;(Socket.java:434) at java.net.Socket.&lt;init&gt;(Socket.java:211) at org.apache.catalina.startup.Catalina.stopServer(Catalina.java:478) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.catalina.startup.Bootstrap.stopServer(Bootstrap.java:408) at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:497) 发现这种奇怪的问题，去检查端口，发现根本没有tomcat进程的端口：1234567891011121314151617181920[root@localhost bin]# netstat -tnlpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22122 0.0.0.0:* LISTEN 63455/fdfs_trackerd tcp 0 0 0.0.0.0:3690 0.0.0.0:* LISTEN 2855/svnserve tcp 0 0 0.0.0.0:6379 0.0.0.0:* LISTEN 127481/redis-server tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1396/sshd tcp 0 0 0.0.0.0:5432 0.0.0.0:* LISTEN 183014/postgres tcp 0 0 0.0.0.0:23000 0.0.0.0:* LISTEN 64278/fdfs_storaged tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 2229/master tcp 0 0 0.0.0.0:8001 0.0.0.0:* LISTEN 98427/mosquitto tcp 0 0 0.0.0.0:8002 0.0.0.0:* LISTEN 72040/nginx: master tcp 0 0 0.0.0.0:8004 0.0.0.0:* LISTEN 109896/vsftpd tcp6 0 0 :::8009 :::* LISTEN 104964/java tcp6 0 0 :::6379 :::* LISTEN 127481/redis-server tcp6 0 0 :::22 :::* LISTEN 1396/sshd tcp6 0 0 :::5432 :::* LISTEN 183014/postgres tcp6 0 0 ::1:25 :::* LISTEN 2229/master tcp6 0 0 :::8001 :::* LISTEN 98427/mosquitto tcp6 0 0 127.0.0.1:8005 :::* LISTEN 104964/java 只好重新启动但是，还是启动后，还是没成功访问到项目，日志里也看不到什么多余的错误信息。 只好把项目删除了，再去启动tomcat，启动成功后，再去把war 包丢进webapps中，发现项目居然能成功访问，搞半天，没搞明白，估计还是项目有点问题，不能正常启动，直接把tomcat 弄死了。先记录下，以后有时间深入了解下。。 启动：1234567[root@localhost bin]# startup.sh Using CATALINA_BASE: /opt/apache-tomcat-9.0.0.M22Using CATALINA_HOME: /opt/apache-tomcat-9.0.0.M22Using CATALINA_TMPDIR: /opt/apache-tomcat-9.0.0.M22/tempUsing JRE_HOME: /opt/jdk1.8.0_131/jreUsing CLASSPATH: /opt/apache-tomcat-9.0.0.M22/bin/bootstrap.jar:/opt/apache-tomcat-9.0.0.M22/bin/tomcat-juli.jarTomcat started. 监视端口进程：12[root@localhost bin]# netstat -tnlp|grep 8000tcp6 0 0 :::8000 :::* LISTEN 104964/java]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[easyui完成日期验证，控制日期的输入范围]]></title>
    <url>%2Feasyui-validate-datebox.html</url>
    <content type="text"><![CDATA[今天改前端问题时候遇到了这个问题，其实easyui还好，看官网例子，也可以解决我们的问题，但是现实业务中却是要考虑到各方面的，要做到更全。 123456789101112131415&lt;div style="height: 100%; width: 200px; margin-left: 4px; display: inline-block;"&gt; &lt;div class="Title"&gt; &lt;div class="Icon icon-calendar"&gt;&lt;/div&gt; &lt;span class="Text"&gt;上传时间&lt;/span&gt; &lt;/div&gt; &lt;div style="width: 120px; height: 38px; line-height: 38px; display: inline-block; float: left; margin-left: 5px;"&gt; &lt;input id="uploadtime1" class="easyui-datebox" data-options="width:120,height:24,editable:false" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div style="height: 38px; width: 146px; margin-left: 4px; display: inline-block;"&gt; &lt;div style="width: 12px; height: 100%; display: inline-block; line-height: 38px; text-align: center; float: left; margin-left: 2px;"&gt;至&lt;/div&gt; &lt;div style="width: 120px; height: 100%; line-height: 38px; display: inline-block; margin-left: 12px; float: left;"&gt; &lt;input id="uploadtime2" class="easyui-datebox" data-options="width:120,height:24,editable:false,validType:'validateDate[\'#uploadtime1\']'" /&gt; &lt;/div&gt; &lt;/div&gt; 123456789$.extend($.fn.validatebox.defaults.rules, &#123; validateDate: &#123; validator: function (value, param) &#123; var start = $(param[0]).datetimebox('getValue'); //获取开始时间 return value &gt;= start; //有效范围为当前时间大于开始时间 &#125;, message: '结束日期应不能小于开始日期!' //匹配失败消息 &#125;&#125;); 效果图：这种方法使用的是easyui的验证，提醒错误错误信息的样式比较好，而且不用手动输入，当然也又有缺点，就是，当用户先输入结束日期，再输入开始日期，就不好去验证了。可以使用例外一种方式控制，官网上看到的，就是控制输入12345678910$(function()&#123; $('#dd').datebox().datebox('calendar').calendar(&#123; validator: function(date)&#123; var now = new Date(); var d1 = new Date(now.getFullYear(), now.getMonth(), now.getDate()); var d2 = new Date(now.getFullYear(), now.getMonth(), now.getDate()+10); return d1&lt;=date &amp;&amp; date&lt;=d2; &#125; &#125;); &#125;); 效果图：只能选择设置区域的日期，其余的不能选择。 需要注意的是date-box需要加上editable:false这个属性，不能让手动输入，只能选择。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Web前端</tag>
        <tag>easyui</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用postman测试上传文件接口，正确提交文件数据]]></title>
    <url>%2Fpostman-upload.html</url>
    <content type="text"><![CDATA[今天使用POSTMAN测试文件上传，不太会用这个东东，刚开始发现这个binary是用来上传文件的，以为用这个没错，但是使用的时候报错信息如下： 12345678910111213141516171819202122232425262728293031&lt;html&gt;&lt;head&gt;&lt;title&gt;Apache Tomcat/7.0.37 - Error report&lt;/title&gt;&lt;style&gt;&lt;!--H1 &#123;font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:22px;&#125; H2 &#123;font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:16px;&#125; H3 &#123;font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:14px;&#125; BODY &#123;font-family:Tahoma,Arial,sans-serif;color:black;background-color:white;&#125; B &#123;font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;&#125; P &#123;font-family:Tahoma,Arial,sans-serif;background:white;color:black;font-size:12px;&#125;A &#123;color : black;&#125;A.name &#123;color : black;&#125;HR &#123;color : #525D76;&#125;--&gt;&lt;/style&gt; &lt;/head&gt;&lt;body&gt;&lt;h1&gt;HTTP Status 500 - Request processing failed; nested exception is org.springframework.web.multipart.MultipartException: The current request is not a multipart request&lt;/h1&gt;&lt;HR size="1" noshade="noshade"&gt;&lt;p&gt;&lt;b&gt;type&lt;/b&gt; Exception report&lt;/p&gt;&lt;p&gt;&lt;b&gt;message&lt;/b&gt; &lt;u&gt;Request processing failed; nested exception is org.springframework.web.multipart.MultipartException: The current request is not a multipart request&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;description&lt;/b&gt; &lt;u&gt;The server encountered an internal error that prevented it from fulfilling this request.&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;exception&lt;/b&gt; &lt;pre&gt;org.springframework.web.util.NestedServletException: Request processing failed; nested exception is org.springframework.web.multipart.MultipartException: The current request is not a multipart request org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:981) org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:871) javax.servlet.http.HttpServlet.service(HttpServlet.java:647) org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:845) javax.servlet.http.HttpServlet.service(HttpServlet.java:728) org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:121) org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) com.devframe.util.CorsFilter.doFilter(CorsFilter.java:23)&lt;/pre&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;root cause&lt;/b&gt; &lt;pre&gt;org.springframework.web.multipart.MultipartException: The current request is not a multipart request org.springframework.web.method.annotation.RequestParamMethodArgumentResolver.assertIsMultipartRequest(RequestParamMethodArgumentResolver.java:216) org.springframework.web.method.annotation.RequestParamMethodArgumentResolver.resolveName(RequestParamMethodArgumentResolver.java:177) org.springframework.web.method.annotation.AbstractNamedValueMethodArgumentResolver.resolveArgument(AbstractNamedValueMethodArgumentResolver.java:90) org.springframework.web.method.support.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:78) org.springframework.web.method.support.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:162) org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:129) org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110) org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:814) org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:737) org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:959) org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:893) org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:969) org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:871) javax.servlet.http.HttpServlet.service(HttpServlet.java:647) org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:845) javax.servlet.http.HttpServlet.service(HttpServlet.java:728) org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:121) org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) com.devframe.util.CorsFilter.doFilter(CorsFilter.java:23)&lt;/pre&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;note&lt;/b&gt; &lt;u&gt;The full stack trace of the root cause is available in the Apache Tomcat/7.0.37 logs.&lt;/u&gt;&lt;/p&gt;&lt;HR size="1" noshade="noshade"&gt;&lt;h3&gt;Apache Tomcat/7.0.37&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt; 项目使用的是springMVC的 MultipartFile 接收的，服务端识别不出来文件。项目中使用的 js 的FormDate上传的，以前使用的 form 表单提交enctype=&quot;multipart/form-data&quot;这两种方法可以解决这个问题，但是postman中不知道怎么设置，刚好还是发现postman中又form-data这中方法提交，仔细一看原来可以选择file类型的参数，尴尬：但是还是报错，仔细检查了参数，发现，postman中Headers设置了 Content-Type 使用form-data提交数据的时候不需要这个属性，删除。做好上面的准备，上传完成。 1234567891011121314&#123; "statusCode": 200, "message": "完成", "data": [ &#123; "name": "722f95b1-261e-4f42-b7fb-45552e01b9f2", "byname": "v2-f26272e386f127af2e9263c83082b4a2_b.jpg", "extname": ".jpg", "type": "图片", "size": 25, "path": "外网地址，不方便透露了" &#125; ]&#125; 终于完成了。。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>postman</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript和jQuery中forEach和each的用法，以及各种遍历的使用]]></title>
    <url>%2Fjs-array.html</url>
    <content type="text"><![CDATA[今天做个选择出id前缀为imgpreviwe的img标签，给它们个背景图片，直接想都没想，forEach调了半天，没调出来，才知道用错了方法。。哈哈，以前的东西忘得差不多了，重新学习一遍。。 正确的是这样写，使用each：123$("[id^='imgpreviwe']", $(".MachineEdit", Dev.App.FillPanel.Target)).each(function (index) &#123; $(this).attr("src", "image/authorization/default.jpg"); &#125;); 下面来重新学习一遍： 首先声明一个数组：1var array = ["z", "s", "y", "l", "v"]; 首先来个最简单的遍历：123for (var i = 0, len = array.length; i &lt; len; i++)&#123; console.log(array[i]); &#125; 运行结果是：12345zsyiv 再来看下forEach：1array.forEach(console.log); 运行结果： 12345z 0 (5) [&quot;z&quot;, &quot;s&quot;, &quot;y&quot;, &quot;l&quot;, &quot;v&quot;]s 1 (5) [&quot;z&quot;, &quot;s&quot;, &quot;y&quot;, &quot;l&quot;, &quot;v&quot;]y 2 (5) [&quot;z&quot;, &quot;s&quot;, &quot;y&quot;, &quot;l&quot;, &quot;v&quot;]l 3 (5) [&quot;z&quot;, &quot;s&quot;, &quot;y&quot;, &quot;l&quot;, &quot;v&quot;]v 4 (5) [&quot;z&quot;, &quot;s&quot;, &quot;y&quot;, &quot;l&quot;, &quot;v&quot;] 其实结果是一样的。。 了解到forEach的源码：123456/**@param &#123;function(T=, number=, Array.&lt;T&gt;=)&#125; callback@param &#123;*&#125; [thisArg]@return &#123;void&#125;*/Array.prototype.forEach = function(callback,thisArg) &#123;&#125;; 后来发现它的使用：123array.forEach(function(value,index,array)&#123; console.log(index + " : " + value + " ~ " + array); &#125;); value 是遍历的值 index 索引 array 数组本身运行结果：123450 : z ~ z,s,y,l,v1 : s ~ z,s,y,l,v2 : y ~ z,s,y,l,v3 : l ~ z,s,y,l,v4 : v ~ z,s,y,l,v map：map即是 “映射”的意思 用法与 forEach 相似：123array.map(function(value,index,array)&#123; console.log(index + " : " + value + " ~ " + array); &#125;); 使用each来遍历数组： 123$.each(array, function (index, value) &#123; console.log(index + " : " + value); &#125;) 结果：123450 : z 1 : s2 : y3 : l 4 : v 回归正题了，上面我们使用的是$().each()，处理Dom对象：1234$(“input[name=’type’]”).each(function(index)&#123; if($(this).attr(‘checked’)==true)&#123; //code &#125; index 为索引找到所有input dom的 name 属性为 type ， 看下jQuery each源码：1234567891011121314151617181920each: function( obj, callback ) &#123; var length, i = 0; if ( isArrayLike( obj ) ) &#123; length = obj.length; for ( ; i &lt; length; i++ ) &#123; if ( callback.call( obj[ i ], i, obj[ i ] ) === false ) &#123; break; &#125; &#125; &#125; else &#123; for ( i in obj ) &#123; if ( callback.call( obj[ i ], i, obj[ i ] ) === false ) &#123; break; &#125; &#125; &#125; return obj; &#125; 看到别人写到，jQuery里的each方法是通过js里的call方法来实现的。call这个方法很奇妙，其实官方的说明是：“调用一个对象的一个方法，以另一个对象替换当前对象。”网上更多的解释是变换上下文环境，也有说是改变上下文this指针。call([thisObj[,arg1[, arg2[, [,.argN]]]]]) 参数thisObj可选项。将被用作当前对象的对象。 arg1, arg2, , argN可选项。将被传递方法参数序列。 说明call 方法可以用来代替另一个对象调用一个方法。call 方法可将一个函数的对象上下文从初始的上下文改变为由 thisObj 指定的新对象。 引用网上有一个很经典的例子:123456789function add(a,b)&#123; alert(a+b);&#125;function sub(a,b)&#123; alert(a-b);&#125;add.call(sub,3,1); 用 add 来替换 sub，add.call(sub,3,1) == add(3,1) ，所以运行结果为：alert(4); 感觉有点厉害了。 注意： js 中的函数其实是对象，函数名是对 Function 对象的引用。 需要注意的Javascript还有个for/in - 循环遍历对象的属性功能 ：遍历对象属性，把属性名和属性值都提出来12345678910(function testForIn() &#123; var obj = &#123; name: "zhangkai", color: 'green', movie: '阿甘正传', &#125; for (var key in obj)&#123; console.log(key + " : " + obj[key]); &#125; &#125;)(); 结果: 123name : zhangkaicolor : greenmovie : 阿甘正传 同样的for in 也能遍历数组:123for (var i in array) &#123; console.log(array[i]); &#125; 结果也是正常的，但是有时候，会打印出数组的函数function，遍历的时候不推荐使用这个。 当然还有while 遍历，那些就不仔细写了。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
        <tag>jQuery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一叶知秋]]></title>
    <url>%2Ftrend.html</url>
    <content type="text"><![CDATA[今天晚上在小区里面慢跑，突然一个东西掉到我眼镜架上，塞在里面了，尬，拿下来一看，看到的是一片树叶。时间过得真快，已经秋天了，今年国庆八天长假，也过完，我想，今后，再得过多少年，才有八天长假。 事情一直在发生，故事永远也写不完，我想我现在想什么，也许在眺望着什么，犹豫着什么，患得患失着什么。在每一刻，它都是好的。也许有一天，我老了，不再去疯了，就这么平静得下去。 我想我现在还是这么个人吧，一直以来也是，对身边的事情都是依依不舍的，但是我没有停留，紧跟着前进，真是想去浪迹天涯呀，但是那是不可能的，我有自己的牵挂与责任，我还是放不下，总有一天，我会老去，总是不想放过，但是时常会放弃自己的一些事情，为难着自己，不愿意离开。 也许是秋天总是会给人带来一丝惆怅的心情吧，不知不觉的，你就会触景生情，这个时候千万别拍照，别去看镜子，你会发现，不知不觉，多了一份沧桑，心里有一些焦灼，慢慢的会影响你的心绪。走的时候，又会浑然不知。 我想我现在还是正值好时光的年纪，即使不能清高，也要活出自我，最后像树叶一样洒脱的离开，因为，我想我正在它夏天的这个时候，还没到，还没到，还能享受最热烈的阳光。 恍惚，秋分早已过，不用在意太多孰是孰非，早就没留退路，只能这样不顾一切，而你是否能明白了。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我想温暖这个有你的世界]]></title>
    <url>%2Fwarm-the-world.html</url>
    <content type="text"><![CDATA[平时一个人最喜欢听的故事，很暖心，分享出来，好好睡觉，嗯，晚安。 每天晚上，当月亮升起的时候，月亮之子就会降临地面。他是一个普通的小子。深夜里，他会独自一个人，无忧无虑的在月光下散步。天亮前，他就会消失。没有什么目的性，他与这个世界没有什么联系。他只是以这样一种简单的姿态，在特定的时候，存在于这个世界。 在一个寒冷的夜晚，他像往常一样在皎洁的月光下散步。这时，他在路边看到了一个昏倒的小女孩。于是他把小女孩抱在怀里，带到一棵大树下，在周围点燃了一堆篝火。也许是篝火的温暖，也许是月亮之子的怀抱的温暖，不一会儿，小女孩就醒了过来。小女孩惊讶的问，你是谁啊？月亮之子撒谎道，我只是一个路过的行人，看到你昏迷，就带你过来烤烤火。你好一些了吗？小女孩本能的往月亮之子的怀里挤了挤，然后说，我没事，就是有一些累，睡一觉就好了。月亮之子抱紧她说，那就睡吧。天亮了再赶路。 半夜的时候，小女孩又醒了一次，她指着那堆篝火说真好看，就像跳舞的小精灵，据说跳舞的小精灵的脚丫是火焰做的，只有内心最纯净的人才能看得到那舞蹈。月亮之子给小女孩讲了好多小故事，小女孩很开心，她说恶魔其实是个乖孩子，因为它没有伤害过任何人。她又说见习死神一定是天使变的，原来天使有时候也会撒谎。小女孩躺在月亮之子的怀里，抬头望着漫天繁星，开始数星星……没过多久，她再一次睡着了。 天快亮的时候，月亮之子把外衣披在了小女孩的身上，然后往篝火里加了一些木柴，准备离开。可是他舍不得，也不放心。他知道小女孩白天的时候会继续赶路，可是天气越来越冷。他不知道自己还能做些什么。他马上就要消失了。 天亮了，小女孩醒了过来。她发现盖在自己身上的衣服，她知道这是那个路人留给她的，而路人自己已经启程了。 相遇和离别，有时候是一件很简单的事。没有什么特殊的理由。因为每个人都有自己的目的地。 小女孩离开那堆篝火，回到自己的路上，忽然被眼前的景象震住了。 路的两旁，是整整齐齐的两排篝火，通红的篝火，如同两条火龙一直延伸向地平线。 我想温暖你，不管我在哪里。如果有一天我会离开你，那就让我温暖这个有你的世界。因为我要你知道，即使你看不到我，也可以感受到我的温暖。 文章来自知乎：晚安小故事：月亮之子/ 我想温暖这个有你的世界 音乐：小星星 -张靓颖]]></content>
      <categories>
        <category>分享</category>
      </categories>
      <tags>
        <tag>故事</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[log4j WARN No appenders could be found for logger]]></title>
    <url>%2Flog-error.html</url>
    <content type="text"><![CDATA[项目的日志以前没设置好，打印出来的东西一团糟。需要把项目的Log文件改一下，改好测试了，没问题，commit，结果突然发现项目启动不了，瞬间吓坏，倒退了，哈哈，机制。报错一大堆： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114严重: The web application [/devframe-server] created a ThreadLocal with key of type [org.springframework.core.NamedThreadLocal] (value [Transactional resources]) and a value of type [java.util.HashMap] (value [&#123;&#123; CreateTime:"2017-10-08 16:24:04", ActiveCount:1, PoolingCount:0, CreateCount:100, DestroyCount:99, CloseCount:1, ConnectCount:2, Connections:[ ]&#125;[]=org.springframework.jdbc.datasource.ConnectionHolder@71579f16, org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean@7998ca6f=org.springframework.orm.jpa.EntityManagerHolder@1fd59301&#125;]) but failed to remove it when the web application was stopped. Threads are going to be renewed over time to try and avoid a probable memory leak.十月 08, 2017 4:24:25 下午 org.apache.catalina.loader.WebappClassLoader checkThreadLocalMapForLeaks严重: The web application [/devframe-server] created a ThreadLocal with key of type [org.springframework.core.NamedThreadLocal] (value [Current AOP proxy]) and a value of type [com.devframe.service.impl.DeviceServiceImpl$$EnhancerBySpringCGLIB$$905a00fd] (value [com.devframe.service.impl.DeviceServiceImpl@b16530c]) but failed to remove it when the web application was stopped. Threads are going to be renewed over time to try and avoid a probable memory leak.十月 08, 2017 4:24:25 下午 org.apache.catalina.loader.WebappClassLoader checkThreadLocalMapForLeaks严重: The web application [/devframe-server] created a ThreadLocal with key of type [org.springframework.core.NamedThreadLocal] (value [Actual transaction active]) and a value of type [java.lang.Boolean] (value [true]) but failed to remove it when the web application was stopped. Threads are going to be renewed over time to try and avoid a probable memory leak.十月 08, 2017 4:24:25 下午 org.apache.catalina.loader.WebappClassLoader checkThreadLocalMapForLeaks严重: The web application [/devframe-server] created a ThreadLocal with key of type [org.springframework.core.NamedThreadLocal] (value [Transaction synchronizations]) and a value of type [java.util.LinkedHashSet] (value [[]]) but failed to remove it when the web application was stopped. Threads are going to be renewed over time to try and avoid a probable memory leak.十月 08, 2017 4:24:25 下午 org.apache.catalina.loader.WebappClassLoader checkThreadLocalMapForLeaks严重: The web application [/devframe-server] created a ThreadLocal with key of type [org.springframework.core.NamedThreadLocal] (value [Current AOP method invocation]) and a value of type [org.springframework.aop.framework.ReflectiveMethodInvocation] (value [ReflectiveMethodInvocation: public abstract java.util.List com.devframe.dao.DeviceDao.findBySerialnumber(java.lang.String); target is of class [org.springframework.data.jpa.repository.support.SimpleJpaRepository]]) but failed to remove it when the web application was stopped. Threads are going to be renewed over time to try and avoid a probable memory leak.十月 08, 2017 4:24:25 下午 org.apache.catalina.loader.WebappClassLoader checkThreadLocalMapForLeaks严重: The web application [/devframe-server] created a ThreadLocal with key of type [org.springframework.core.NamedThreadLocal] (value [Current transaction name]) and a value of type [java.lang.String] (value [com.devframe.service.impl.DeviceServiceImpl.findBySerialnumber]) but failed to remove it when the web application was stopped. Threads are going to be renewed over time to try and avoid a probable memory leak.十月 08, 2017 4:24:25 下午 org.apache.catalina.loader.WebappClassLoader checkThreadLocalMapForLeaks严重: Unable to determine string representation of value of type [org.springframework.transaction.interceptor.TransactionAspectSupport.TransactionInfo]java.lang.NullPointerException at org.springframework.transaction.interceptor.TransactionAspectSupport$TransactionInfo.toString(TransactionAspectSupport.java:624) at org.apache.catalina.loader.WebappClassLoader.checkThreadLocalMapForLeaks(WebappClassLoader.java:2520) at org.apache.catalina.loader.WebappClassLoader.checkThreadLocalsForLeaks(WebappClassLoader.java:2454) at org.apache.catalina.loader.WebappClassLoader.clearReferences(WebappClassLoader.java:1995) at org.apache.catalina.loader.WebappClassLoader.stop(WebappClassLoader.java:1901) at org.apache.catalina.loader.WebappLoader.stopInternal(WebappLoader.java:662) at org.apache.catalina.util.LifecycleBase.stop(LifecycleBase.java:232) at org.apache.catalina.core.StandardContext.stopInternal(StandardContext.java:5526) at org.apache.catalina.util.LifecycleBase.stop(LifecycleBase.java:232) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:160) at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1559) at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1549) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)十月 08, 2017 4:24:25 下午 org.apache.catalina.loader.WebappClassLoader checkThreadLocalMapForLeaks严重: The web application [/devframe-server] created a ThreadLocal with key of type [org.springframework.core.NamedThreadLocal] (value [Current aspect-driven transaction]) and a value of type [org.springframework.transaction.interceptor.TransactionAspectSupport.TransactionInfo] (value [Unknown]) but failed to remove it when the web application was stopped. Threads are going to be renewed over time to try and avoid a probable memory leak.十月 08, 2017 4:24:25 下午 org.apache.coyote.AbstractProtocol start信息: Starting ProtocolHandler ["http-bio-8081"]十月 08, 2017 4:24:25 下午 org.apache.catalina.loader.WebappClassLoader loadClass信息: Illegal access: this web application instance has been stopped already. Could not load org.hibernate.engine.transaction.internal.jta.JtaStatusHelper. The eventual following stack trace is caused by an error thrown for debugging purposes as well as to attempt to terminate the thread which caused the illegal access, and has no functional impact.java.lang.IllegalStateException at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1599) at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1558) at org.hibernate.engine.transaction.internal.TransactionCoordinatorImpl.afterTransaction(TransactionCoordinatorImpl.java:142) at org.hibernate.engine.transaction.internal.jdbc.JdbcTransaction.afterTransactionCompletion(JdbcTransaction.java:138) at org.hibernate.engine.transaction.spi.AbstractTransactionImpl.rollback(AbstractTransactionImpl.java:213) at org.hibernate.jpa.internal.TransactionImpl.rollback(TransactionImpl.java:108) at org.springframework.orm.jpa.JpaTransactionManager.doRollback(JpaTransactionManager.java:544) at org.springframework.transaction.support.AbstractPlatformTransactionManager.processRollback(AbstractPlatformTransactionManager.java:853) at org.springframework.transaction.support.AbstractPlatformTransactionManager.rollback(AbstractPlatformTransactionManager.java:830) at org.springframework.transaction.interceptor.TransactionAspectSupport.completeTransactionAfterThrowing(TransactionAspectSupport.java:503) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:285) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:655) at com.devframe.service.impl.DeviceServiceImpl$$EnhancerBySpringCGLIB$$905a00fd.findBySerialnumber(&lt;generated&gt;) at com.devframe.util.mqtt.TimingPublish.run(TimingPublish.java:241) at com.devframe.service.impl.MqttServerImpl.callBackChoose(MqttServerImpl.java:108) at com.devframe.util.mqtt.ServerMQTT.messageArrived(ServerMQTT.java:161) at org.eclipse.paho.client.mqttv3.internal.CommsCallback.deliverMessage(CommsCallback.java:499) at org.eclipse.paho.client.mqttv3.internal.CommsCallback.handleMessage(CommsCallback.java:402) at org.eclipse.paho.client.mqttv3.internal.CommsCallback.run(CommsCallback.java:206) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)十月 08, 2017 4:24:25 下午 org.apache.catalina.loader.WebappClassLoader loadClass信息: Illegal access: this web application instance has been stopped already. Could not load org.eclipse.paho.client.mqttv3.internal.MessageCatalog. The eventual following stack trace is caused by an error thrown for debugging purposes as well as to attempt to terminate the thread which caused the illegal access, and has no functional impact.java.lang.IllegalStateException at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1599) at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1558) at org.eclipse.paho.client.mqttv3.MqttException.getMessage(MqttException.java:225) at org.eclipse.paho.client.mqttv3.MqttException.toString(MqttException.java:233) at java.lang.String.valueOf(String.java:2994) at java.io.PrintStream.println(PrintStream.java:821) at java.lang.Throwable$WrappedPrintStream.println(Throwable.java:748) at java.lang.Throwable.printStackTrace(Throwable.java:655) at java.lang.Throwable.printStackTrace(Throwable.java:643) at java.lang.Throwable.printStackTrace(Throwable.java:634) at com.devframe.util.mqtt.ServerMQTT.connectionLost(ServerMQTT.java:144) at org.eclipse.paho.client.mqttv3.internal.CommsCallback.connectionLost(CommsCallback.java:292) at org.eclipse.paho.client.mqttv3.internal.ClientComms.shutdownConnection(ClientComms.java:423) at org.eclipse.paho.client.mqttv3.internal.CommsCallback.run(CommsCallback.java:220) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)十月 08, 2017 4:24:38 下午 org.apache.catalina.loader.WebappClassLoader loadClass信息: Illegal access: this web application instance has been stopped already. Could not load org.apache.commons.pool2.impl.EvictionConfig. The eventual following stack trace is caused by an error thrown for debugging purposes as well as to attempt to terminate the thread which caused the illegal access, and has no functional impact.java.lang.IllegalStateException at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1599) at org.apache.catalina.loader.WebappClassLoader.loadClass(WebappClassLoader.java:1558) at org.apache.commons.pool2.impl.GenericObjectPool.evict(GenericObjectPool.java:743) at org.apache.commons.pool2.impl.BaseGenericObjectPool$Evictor.run(BaseGenericObjectPool.java:1036) at java.util.TimerThread.mainLoop(Timer.java:555) at java.util.TimerThread.run(Timer.java:505) 根据上面查找问题，刚开始一直以为是 mqtt 出现错误了，检查完全没问题，而且最近只是修改了其他的内容，一想到我刚刚改了log4j，估计是它除了错误，但是上面的错误信息完全没给我有用的提示信息，只能知道web root 都没能启动，就去各个spring配置文件看，但是没发现有配置log4j的位置，最后功夫不负有心人终于在web.xml看到了一段话 12345678&lt;!-- 启动Log4j --&gt; &lt;context-param&gt; &lt;param-name&gt;log4jConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:log4j.properties&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.util.Log4jConfigListener&lt;/listener-class&gt; &lt;/listener&gt; 跟我目前路径不一致，改好后，成功启动。。。莫名其妙了。 网上查了下，日志出现错误，找不到log4j.properties报错是12log4j:WARN No appenders could be found for logger (org.apache.ibatis.logging.LogFactory). log4j:WARN Please initialize the log4j system properly. 那就不得而知了。 总算解决了。。 总结： 部署的项目在WEB-INF/classes/路径下加上文件 log4j.properties ,开发中，我使用的是maven构建项目的，所以，在resources 文件下加入 log4j.properties 就可以了。 这样下去启动下去仍然会报错，Web开发的时候，spring容器启动去读取这个log4j的配置文件的时候，找不到它，所以要在 web.xml 中重新配置文件位置：12345678&lt;!-- 启动Log4j --&gt; &lt;context-param&gt; &lt;param-name&gt;log4jConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:log4j.properties&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.util.Log4jConfigListener&lt;/listener-class&gt; &lt;/listener&gt;]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>log4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我想分享你的悲伤]]></title>
    <url>%2Fshare-sadness.html</url>
    <content type="text"><![CDATA[我想分享你的悲伤我想分享你的悲伤， 我要成为故事中的小丑， 将悲伤写进喜剧中。 我想分享你的悲伤， 我会强颜为笑， 带上面具， 安慰你。 我想分享你的悲伤 但我不能将悲伤带给你， 因为哄你开心， 才是我的责任， 即便是伤痕累累， 你一笑， 我便好。 我想分享你的悲伤， 永远微笑， 不贪婪。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jQuery实现多文件上传并预览]]></title>
    <url>%2Fmultiple-file-upload.html</url>
    <content type="text"><![CDATA[自己做了个文件上传，样式有些简陋，功能还需以后完善。中间遇到了一些问题，在这里记录下。 样式1234567&lt;div style="height: 82px; width: 100%; border-bottom: 1px solid #ddd;padding-top: 5px"&gt; &lt;div style="width: 80px; height: 82px;float: left;text-align: right; line-height: 72px;"&gt;反馈图片&lt;/div&gt; &lt;a href="javascript:;" class="file"&gt;选择文件 &lt;input type="file" accept="image/png,image/gif,image/jpg,image/jpeg" id="files" name="files" multiple /&gt; &lt;/a&gt; &lt;div id="preview"&gt;&lt;/div&gt; &lt;/div&gt; 1234567891011121314151617181920212223242526272829.file &#123; float: left; position: relative; display: block; background: #03afD9; border: 1px solid #99D3F5; border-radius: 4px; margin-left: 5px; padding: 4px 12px; overflow: hidden; color: white; text-decoration: none; text-indent: 0; line-height: 20px; margin-top: 20px;&#125;.file input &#123; position: absolute; font-size: 100px; right: 0; top: 0; opacity: 0;&#125;.file:hover &#123; background: #95B8E7; border-color: #78C3F3; color: white; text-decoration: none;&#125; 脚本1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//下面用于多图片上传预览功能 function setImagePreviews(docObj) &#123; var preview = $("#preview", $(".MachineEdit", Dev.App.FillPanel.Target)); preview.html(""); fileList = docObj.files; if (fileList.length &gt; 3)&#123; return; &#125; for (var i = 0; i &lt; fileList.length; i++) &#123; if (!checkType(fileList[i].name))&#123; preview.html(""); break; &#125; preview.append("&lt;div style='float:left;cursor:pointer;margin-left: 3px;' &gt;&lt;img id='img" + i + "' /&gt; &lt;/div&gt;"); var imgObjPreview = $("#img"+i, $(".MachineEdit", Dev.App.FillPanel.Target)); if (fileList &amp;&amp; fileList[i]) &#123; //火狐下，直接设img属性 imgObjPreview.css("display","block"); //控制缩略图大小 imgObjPreview.width(70); imgObjPreview.height(70); //imgObjPreview.src = docObj.files[0].getAsDataURL(); //火狐7以上版本不能用上面的getAsDataURL()方式获取，需要一下方式 imgObjPreview.attr("src", window.URL.createObjectURL(fileList[i])); &#125; else &#123; //IE下，使用滤镜 docObj.select(); var imgSrc = document.selection.createRange().text; var localImagId = $("#img"+i, $(".MachineEdit", Dev.App.FillPanel.Target)); //必须设置初始大小 localImagId.width(70); localImagId.height(70); //图片异常的捕捉，防止用户修改后缀来伪造图片 imgObjPreview.css("display", "none"); document.selection.empty(); &#125; &#125; return true; &#125; /*检测照片格式*/ function checkType(image)&#123; var extStart = image.lastIndexOf("."); var ext = image.substring(extStart, image.length).toUpperCase(); if ( ext != ".PNG" &amp;&amp; ext != ".GIF" &amp;&amp; ext != ".JPG" &amp;&amp; ext != ".JPEG") &#123; dialog.Alert("图片限于png，gif，jpeg，jpg格式！", "error"); return false; &#125; return true; &#125; 调用方式123$("#files", $(".MachineEdit", Dev.App.FillPanel.Target)).bind("change",function () &#123; setImagePreviews(this); &#125;); 效果展示： 上传的时候使用的是FormData 12345678910111213141516171819202122232425262728//以上省略 var form = new FormData(); //注意参数数组的时候使用多次append就行了 for (var i = 0, len = fileList.length; i &lt; len; i++) &#123; form.append("files", fileList[i]); &#125; form.append("orgid", selectorgid); form.append("cautionid", selectAl); form.append("fkder",Dev.cookie.user.truename); $.ajax(&#123; type: "POST", url: '~~省略~~', data: form, contentType: false, processData: false, //注意一定要设置为false success: function (response) &#123; if (!Dev.IsNull(response) &amp;&amp; response.statusCode == 200) &#123; dialog.Alert(msg.addSuccess, "success"); &#125; else &#123; dialog.Alert(msg.addFailed, "error"); &#125; &#125;, error: function (e) &#123; dialog.Alert(msg.netout, "error"); &#125; &#125;) processData的默认值是true。用于对data参数进行序列化处理。 后台java后台使用的是springMVC，相同的可以参考。12345678910@RequestMapping(value = "/***", method = RequestMethod.POST) public HttpResponse&lt;CautionFeedBackEntity&gt; addFile(@RequestParam(value="files",required=false)MultipartFile[] files, CautionFeedBackEntity entity) &#123; try &#123; ~~~处理~~~ return new HttpResponse&lt;CautionFeedBackEntity&gt;(ResponseStatusCode.C200); &#125; catch (Exception e) &#123; Log.error("错误飘过~~~~"); return new HttpResponse&lt;CautionFeedBackEntity&gt;(ResponseStatusCode.C400); &#125; &#125; 需要注意的是 MultipartFile[] 需要设置 @RequestParam 参数。 总结 html优化。 脚本后期还需添加点击删除功能，并且还要更新input-file里的内容。 js中处理图片的过程，还需做更多的控制（文件大小，伪文件）。 使用fastDFS存储。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Web前端</tag>
        <tag>JavaScript</tag>
        <tag>jQuery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[这些只属于武汉的浪漫，看完幸福感爆棚]]></title>
    <url>%2Fwh-romance.html</url>
    <content type="text"><![CDATA[无意中看到个长图，感觉到身边的城市这边美，平时没什么时间去发现，倒是有点小小的遗憾吧，记下，有机会一定要转转/ y。 就是希望以后有个人能一起去我们想去的地方。。。]]></content>
      <categories>
        <category>分享</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>武汉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我想她，是那么的美好吧]]></title>
    <url>%2Fmiss-you.html</url>
    <content type="text"><![CDATA[我想她，是那么的美好吧。 文字注定是矫情的，所以没什么好忌惮的了。 不知道不觉就想起她，很难过，放不下。这么多年还记得她，不是因为长相，她长相清秀，但是没那么出众，可能因为她别样清脆的声音，但我也不是声控，可能是因为别的，总之，还在意她。 人就是这么奇怪，有时候遇到什么东西就容易出神，青春期的男生可能总是浮想翩翩，就是经常失神吧，我现在大概还是这个样子了，愣。 跟她说过的话不多吧，见面了的时候我也不敢跟她打招呼，因为我很内向，而且还是个很慢热的人，平时话也非常少，我了解的人也不多，实在是一个再也普通不过的人了。 但是在我眼中的她干净，就像不沾人间烟土的仙子。人很聪明，没什么心机，可以跟其他人玩的很合得来。 我觉得她最大的特点就是明媚了，为什么会用这个词了，应该来源于她当时的网名。人烦恼的时候总是会仰望天空，但是天空中也有阴云。看到她的眼睛，感觉就是一直散发着光，是真的明媚，而且带着淡淡的忧伤，那双眼睛总是清澈的，是我迄今为止见过的最漂亮的眼睛；说话的时候就像歌曲，安静优雅而又绵长。 就这样，抓走了我的心。后来做了傻事，表白了她，想当初太年轻了，她很懂事，果断拒绝了我。我当时很颓废，回想当初不应该那样的，后来高考完后，她又加了我，不知道当时是什么自尊心在作祟，居然没想到去追回她，什么高考失利都是借口，自己大概当时有些失望，是想放弃的吧，因为自己也是一个懦夫，不敢再次面对，若干年后，没任何理由去再次去拥有吧。 后来上了大学应该简单联系了几句，但是没多说，我也忘了，曾经一度真的以为我忘了，但是qq还是一直存在我这里，特别关注，平时闲着没事就喜欢翻翻她的空间，但是也不想留下痕迹，简单看下她再干什么，去她去过的地方，看她想看的电影。看到她的照片，她还是以前那个样子，每次看到，心中会有暖意吧，偷偷的存下。直到毕业工作来到了武汉这个城市，不尽然的又想去找她，但是她的心已经对你上了一把锁了，你该用什么去打开它了，没感情经历的我该拿什么去追回她了。 回想当初，自己这个人真的是有点烂了，什么也没付出就像拿到什么，如果当初没能戳穿就好了，即使能远远的看着她，也是一件多么美好的事情啊。我想现在懂了，可能已经太晚了，自己已经不可能撩动她的心了，已经过了那个年纪了，这么长时间，早已经物是人非了，有可能，我这一辈子再也不能见到她了吧，但是只要还能想起她，看到她的消息，心中还是泛起了涟漪。反正现在人都这么烂了，只能用真心去等候吧。 希望在最美好的年华遇到美好的人，然而是遇到美好的人，美好的年华却迟迟的错过了！虽然没经历过什么刻骨铭心的事情，但我不会忘记的，谢谢她，让我想变成更好的人。 愿她以后一直明媚，不再忧伤吧。 真的很美好！都要加油了。 最终还是没能抓住她，让别人抓走了她的心。但是看到她现在纠结的感情问题，心都要快化了。很想去看看她，但犹豫她是不想见到我吧，弄巧成拙后，朋友也做不成。 是我真有点情绪了，我还是有些犹豫，只是我这个人就是这样的直吧，EQ不在线。确实啊，但是，喜欢的确实好辛苦啊，追一个人很久不回应该怎么办，苦笑，明知道是傻，还能怎么办了，从没退路的我，不知道游离在何处，发现真的好累，不曾想过什么多余的，可能我还是像从前那么单纯吧。 别人都说，想清楚了，没人会说自己的感情是最特别的，哪个人不深情，最终留给自己的才是最重要的。我想是这段时间打扰得厉害了，于人于己都不好，她幸福的时刻，不忍心再打扰下去了。看到她现在的空间和微博，尽是些伤感的句子，很想让她开心，但是我发现我并不能办到，在她面前真的感觉到好卑微，有些患得患失，情绪化了，真的错了，我是一个只能让她更难受的人，或许真的不是对的人，因为这个样子她并不是我想要的。 虽然我也很不想放弃，但是这样下去对谁都不好，真的好想戒了，就这样静静地看着吧，悄无声息。 希望她能幸福吧，走过很多的路，也做过很多努力，很静静的告诉自己，耐心的等待。 我相信一定能遇到下一个对的人，现在能做的唯有努力提升自己，才能在对的时间不错过，耐心等待，不将就，不奢求。择一城，遇一人，终老。 那个我想见却还在等的人，如果能握紧就不要放手了。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用java将gps时转换为utc时间方法]]></title>
    <url>%2Fgps2utc.html</url>
    <content type="text"><![CDATA[gps时间系统 GPS时间系统采用原子时AT1秒长作时间基准，秒长定义为铯原子CS133基态的两个超精细能级间跃迁辐射振荡9192631170周所持续的时间，时间起算的原点定义在1980年1月6日世界协调时UTC0时，启动后不跳秒，保证时间的连续。以后随着时间积累，GPS时与UTC时的整秒差以及秒以下的差异通过时间服务部门定期公布。精密导航和测量的需要，GPS建立了专用的时间系统。该系统可简写为GPS由GPS主控站的原于钟控制，规定GPS与协调时的时刻于t980年1月6日o时相一致。其后随着时间的积累两者之间的差别将表现为秒的整倍数。 gps周 GPS周（GPS Week）是GPS系统内部所采用的时间系统。时间零点定义的为：1980年1月5日夜晚与1980年1月6日凌晨之间0点。最大时间单位是周（一周：604800秒）。每1024周（即7168天）为一循环周期。第一个GPS周循环点为1999年8月22日0时0分0秒。即从这一刻起，周数重新从0开始算起。星期记数规则是：Sunday为0，Monday为1，以此类推，依次记作0~6，GPS周记数（GPS Week Number）为“GPS周 星期记数”。 使用java将gps时转换为utc时间方法看到了gps时间系统大概明白了 gps时由整周（7天）计数，与周内秒计数两部分组成。转换为utc时间可以从1980年1月6日0时,基本思路计算出总共的秒数，然后通过计算总秒数包含了多少整年，整年减掉后取余，计算年内多少整月，依次类推就可以计算出最后utc时刻的年月日时分秒.毫秒值了。 转换过程中需要主要的年中的闰年处理，还有GPS时与utc时的闰秒问题，如果是转换为北京时间要求时区的问题需要考虑。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107package com.devframe.util.mqtt;import java.util.Date;/** * @ClassName: GPS2UTC * @Description: gps时间转成utc+8:00 北京时间* @author zhangkai * @date 2017年9月25日 下午3:08:07 * */public class GPS2UTC &#123; private java.util.Date date; private static int[] monthday = new int[]&#123;0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31&#125;; private static int TIME_DAY_MS = 3600*24*1000; /* * @week gps周 * @tow gps周内秒（单位毫秒） * @leaps 闰秒数 */ @SuppressWarnings("deprecation") public GPS2UTC(int week, int tow, int leaps) &#123; int totalday; int year = 1980; int month; int day; totalday = week * 7; totalday += 5; // 如果需要减去闰秒 if (leaps != 0 &amp;&amp; week &gt; 0) &#123; if (tow &lt; leaps * 1000) &#123; totalday--; tow = TIME_DAY_MS - leaps * 1000 + tow; &#125; else &#123; tow = tow - leaps * 1000; &#125; &#125; while (totalday &gt;= 366) &#123; totalday -= 365; if (isLeapYear(year)) &#123; totalday -= 1; &#125; year++; &#125; if(isLeapYear(year)) &#123; monthday[2] = 29; &#125; else &#123; monthday[2] = 28; &#125; for (month = 1; month &lt;= 12; month++) &#123; if (totalday &lt; monthday[month]) &#123; break; &#125; totalday -= monthday[month]; &#125; day = totalday; day++; while (tow &gt; TIME_DAY_MS) &#123; tow -= TIME_DAY_MS; day++; if (day &gt; monthday[month]) &#123; day = 1; month++; if (month &gt; 12) &#123; month = 1; year++; &#125; &#125; &#125; tow /= 10; //int msecond = tow % 100; tow /= 100; int second = tow % 60; tow /= 60; int minute = tow % 60; int hour = tow / 60; //转成Utc时候 北京时间UTC+8:00 year -= 1900; month -= 1; hour += 8; date = new Date(year, month,day,hour,minute,second); &#125; /** * 判断闰年 * @param year * @return */ private boolean isLeapYear(int year) &#123; if (((year % 4 == 0) &amp;&amp; (year % 100 != 0)) || (year % 400 == 0)) return true; else return false; &#125; public Date getDate() &#123; return date; &#125;&#125; 其实可以把时区参数放到函数中，为什么要减去1900年，这要说到java中new Date这个方法的定义，1234567891011121314151617@Deprecated public Date(int year, int month, int date, int hrs, int min, int sec) &#123; int y = year + 1900; // month is 0-based. So we have to normalize month to support Long.MAX_VALUE. if (month &gt;= 12) &#123; y += month / 12; month %= 12; &#125; else if (month &lt; 0) &#123; y += CalendarUtils.floorDivide(month, 12); month = CalendarUtils.mod(month, 12); &#125; BaseCalendar cal = getCalendarSystem(y); cdate = (BaseCalendar.Date) cal.newCalendarDate(TimeZone.getDefaultRef()); cdate.setNormalizedDate(y, month + 1, date).setTimeOfDay(hrs, min, sec, 0); getTimeImpl(); cdate = null; &#125; 看出来年是按照1900基数来算的。 通过上面的算法可以将gps时间转换成北京时间]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WIN10家庭版安装Doby 4]]></title>
    <url>%2Fdoby4-install.html</url>
    <content type="text"><![CDATA[笔记本电脑的音效确实好差劲啊，无聊还是准备安装了一个杜比装X，效果还是不错的，家庭版安装过程中，跟以前专业版有所不同。 下载http://pan.baidu.com/s/1cdIQpo 密码 k8sa 下载好解压， 安装 进入解压的文件夹中直接执行安装程序.exe文件，记住不要修改软件的安装的路径，让软件自行解压到C:\DRIVERS\WIN\DOLBY，最后记住取消勾勾再点finish。我们会在C盘的安装目录里看到如下的文件: WIN10电脑有个蛋疼的驱动自动更新，它会自动下载和更新我们电脑上的相关驱动，我们需要取消这个功能，步骤： 控制面板\所有控制面板项\系统\高级系统设置\硬件\设备安装设置选择否保存设置 通过上面的设置，系统不会自动更新我们的驱动了， 现在需要重启，注意不是一般的重启，我们需要禁用驱动程序强制签名，为什么会这样，我想应该是微软系统还没收录这类的驱动程序，（ps:以前玩腾讯游戏也是，WIN10已更新把腾讯驱动给屏蔽了，全挂了）回归正题，按住shirt键，再去点击计算机重启按钮，进入疑难解答这一项，再点启动设置，电脑重启后，会让我们选择一个列表的东西，我们直接按键盘 7键 禁用驱动程序强制签名 的选项。 然后，进入我们第一步安装问价的路径 C:\DRIVERS\WIN\DOLBY 64位系统进入 X64文件夹中运行安装 DTCP 安装完成后，可以看到电脑右下角有杜比的图标，放音乐有频谱，表明杜比接管声卡驱动成功了。 贴张音效图 最后 安装时候不需要卸载原来的声卡，安装时候不需要卸载原来的声卡，安装时候不需要卸载原来的声卡，重要的说三遍。 WIN10家庭版相比专业版没有策略组，不能去设置设置安装限制，但是还是能正常安装，我想不需要设置 （禁止安装未由其他策略设置描述的设备设置），所以专业版也可以使用这个方式安装。 台式电脑要注意了，杜比不支持前置声卡接口。 有厂商制定的声卡或者软件，可能有一些兼容问题，我的HP笔记本就是静音没有键盘灯提示了。 最后，渣渣笔记本的扬声器，随便淘宝买个50块以内的音响就完爆了，哈哈，提升硬件才是硬道理。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>doby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[请告诉女儿：嫁人就嫁心机男]]></title>
    <url>%2Fthinking-boy.html</url>
    <content type="text"><![CDATA[本来是昨天听FM听到这篇文章的，文章非常好，虽然自己也没感情经历，突然感觉自己这么是个直男好吓人啊😭，就算是一段认识吧，分享下这个文章，也不转载了，（哭。 直接挂个链接吧。 文章作者： 国馆 原文链接： https://www.douban.com/note/638049932/]]></content>
      <categories>
        <category>分享</category>
      </categories>
      <tags>
        <tag>感情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Travis CI 持续集成]]></title>
    <url>%2FTravisCI.html</url>
    <content type="text"><![CDATA[Travis CI 持续集成到这一步，你其实已经可以很简便的使用 Hexo 来写博客了，可人是一种永远不满足的动物。使用 Hexo 来写博客有一个问题就是，我只能在安装了 Hexo 的计算机上写东西，然后 hexo generate 再 hexo deploy 到托管服务器。如果我想在没有安装 Hexo 的电脑上写博客呢？如果我想随时随地修改，或者写一下博客呢？当然一个简单办法就是把自己博客的源文件也托管到 Github，每次都把源文件 clone 下来，然后安装 Hexo，再构建发布就好了。可是这样做的话，始终不太优雅。那可以搞一个远程的服务器，把构建博客的事情交给服务器，每次要写博客的时候连接到服务器上去就行了。可既然我们把博客都托管到了 Github，为甚么博客的构建还需要服务呢？不行，这样还是不够优雅。如果有什么服务能够代替上述的那个服务器就好了，答案是确实有的——持续集成。 什么是持续集成 持续集成（Continuous Integration）是一种软件开发实践。 在持续集成中，团队成员频繁集成他们的工作成果，一般每人每天至少集成一次，也可以多次。 每次集成会经过自动构建（包括自动测试）的检验，以尽快发现集成错误。 什么是 Travis CI Travis CI 是目前新兴的开源持续集成构建项目，它与 jenkins，GO 的很明显的特别在于采用 yaml 格式，同时它是在线的服务，不像 jenkins 需要你本地搭建服务器，简洁清新独树一帜。目前大多数的 Github 项目都已经移入到 Travis CI 的构建队列中，据说Travis CI 每天运行超过 4000 次完整构建。对于做开源项目或者 Github 的使用者，如果你的项目还没有加入 Travis CI 构建队列，那么我真的想对你说 OUT 了。 Travis 和 Hexo为什么我们要选择 Travis 呢，因为它和 Github 集成的程度非常高，对于 Github 上的开源项目，可以免费在 Travis 上构建（我们是不是该为免费的互联网精神干杯🍻），而非开源的私有项目想在 Travis 上构建价格还是非常感人的。我先把在 Travis 上进行自动构建的思路说一下： 我们在在 Github 的博客仓库里新建一个 blog-source 分支，然后把博客的源码托管到这个分支 每当我们在本地写好了博文之后，把修改 push 到该分支 Travis 上可以对这个项目的 blog-source 分支设置钩子，每当检测到 push 的时候就去仓库 clone 源代码 Travis 执行构建脚本 Travis 把构建结果通过 push 部署到 master 分支或者 Coding.net 的仓库里 在这样的自动化流程下，我们唯一需要做的事情就是 push 我们的博文到源代码分支，其他的事情交给 Travis，当然，这一流程是需要我们配置的。 配置 Travis注册 TravisTravis CI 不需要单独注册，直接使用 GitHub 账号登录就可以了。上官网 会发现有 Sign in with GitHub（使用GitHUb登录）和 Sign Up（注册），其实这俩做的事情都一样，就是用 GitHub 账号登录。登录后界面会显示你的 GitHub Repository，默认全部全部没有勾选，选择你的博客的 Repository 后完成第一步，如图：如果你没有看到自己的项目，请点击右上角的 Sync with Github。 安装 Travis CML在进行下面的步骤之前，我们需要先安装 Travis 的 CML，因为后面的部署需要我们加密的自己的 SSH 私钥和 Github、Coding.net 通信。安装过程请看 Travis CML Installation：首先必须有 Ruby 1.9.3 以上，检查了版本之后，安装 Travis，检查版本即可： 123ruby -vgem install travis -v 1.8.4 --no-rdoc --no-ritravis version 如上，如果出现 1.8.2 这样的版本信息，则说明 Travis CI Command Line Client 安装成功。之后进行登录，执行：1travis login 按照提示登录就好了。 配置 Travis在博客根目录下添加 Travis CI 所需要的配置文件 .travis.yml，配置文件内容和一些说明如下： 1234567891011121314151617181920212223242526272829303132333435language: node_jsnode_js: stable# assign build branchesbranches: only: - blog-source# cache this directorycache: directories: - node_modules# S: Build Lifecyclebefore_install: - openssl aes-256-cbc -K $encrypted_a0b7f0848317_key -iv $encrypted_a0b7f0848317_iv -in ./.travis/id_rsa.enc -out ~/.ssh/id_rsa -d - chmod 600 ~/.ssh/id_rsa - eval $(ssh-agent) - ssh-add ~/.ssh/id_rsa - cp .travis/ssh_config ~/.ssh/config - npm install -g hexo-cli # 安装 hexo - git clone -b mod https://github.com/quentin-chen/hexo-theme-even.git themes/eveninstall: - npm install # 安装 package.json 中的插件script: - hexo generateafter_success: - git config --global user.name &quot;Quentin_Chen&quot; - git config --global user.email &quot;quentin.chen@foxmail.com&quot; - sed -i&apos;&apos; &quot;/^ *repo/s~github\.com~$&#123;githubToken&#125;@github.com~&quot; _config.yml - hexo deploy# E: Build LifeCycle 我逐步来讲解一下每一个配置项的意思。123456789101112language: node_jsnode_js: stable# assign build branchesbranches: only: - blog-source# cache this directorycache: directories: - node_modules 这里指定了构建的环境是 Node.js，版本是当前稳定版本。设置的 WebHook 钩子只检测 blog-source 分支的 push 变动。另外我们把 node_modules 文件夹放入缓存，这样可以大大节约每次构建的时间（2min -&gt; 30s）。 12345678before_install: - openssl aes-256-cbc -K &lt;you_key&gt; -iv &lt;your_iv&gt; -in ./.travis/id_rsa.enc -out ~/.ssh/id_rsa -d - chmod 600 ~/.ssh/id_rsa - eval $(ssh-agent) - ssh-add ~/.ssh/id_rsa - cp .travis/ssh_config ~/.ssh/config - npm install -g hexo-cli # 安装 hexo - git clone &lt;theme_repo&gt; themes/&lt;theme&gt; 其实每次 Travis 构建的时候，相当于创建了一个干净的虚拟机，除了 Git 等必须的工具，甚至连 Node.js 的环境都是现安装的。所以我们在构建自己的博客之前，需要做一些环境的准备。其中 2-6 行是用来配置 SSH 私钥的，这样才能让 Github 和 Coding.net 知道你的身份。这一部分我们后面再说。第 7 行是在 Travis 中安装 Hexo 环境，第 8 行是安装主题。 关于主题这里，如果你对自己的主题做了修改（包括配置文件），那么应该把自己修改过的主题托管到 Github，这里填的 &lt;theme_repo&gt; 应是你自己地址。 12345678910install: - npm install # 安装 package.json 中的插件script: - hexo generateafter_success: - git config --global user.name &quot;&lt;You Name&gt;&quot; - git config --global user.email &quot;&lt;email&gt;&quot; - hexo deploy 这一部分，就是在 Travis 上模拟部署过程。因为要使用 Git，所以要提前配置好 Committer 的信息。生成私钥加密文件 什么是私钥？私钥就是密钥对（密钥对指一对公钥和私钥），我们在使用 Github 的时候，首先需要在 Github 上配置公钥，这是最基础的。那么，存在我们本地的私钥就是你的个人身份标示，如果你的项目 git 地址配置的是 git@github.com:username/projectname.git（相对的还有 https://github.com/username/projectname.git）， 当你在对 Repository 在一些操作（比如 push 等），则需要私钥进行身份验证了（这是自动验证的，如果是使用 https 的配置，则需要提供用户名和密码）。我们在 Travis CI 上自动部署代码，就牵扯到了 push 操作，那么就需要提供私钥了。 为什么生成私钥加密文件？ 将私钥直接放在项目里，那么人人都能看到。私钥的泄露将会发生一系列的问题，比如有坏人拿你的私钥直接操作你的 git 项目，你能干啥他也能干啥（原理上面讲了），这咋整？我们需要对私钥进行加密。Travis 提供了加密文件的支持，什么意思呢？我们可以对文件（这里指私钥）在本地进行加密，然后把加密过后的文件放在项目里，那么别人就无法获取里面的真实内容。然后我们在让 Travis 执行脚本的时候，在读取加密文件之前对文件进行解密（使用的解密密码提前在 Travis 上配置好了），这样就可以达到不将文件内容暴露，并且让 Travis 获取到真实内容的目的了，大概的时序图如下：开始吧，我们首先把自己的在博客的根目录下建立 .travis 文件夹来存放相关的资料：1mkdir .travis &amp;&amp; cd .travis 把本地的私钥复制一份过来，用 Travis 加密，然后删除（切记加密完了一定要删除原始密钥！！！）：123cp ~/.ssh/id_rsa .travis encrypt-file id_rsarm id_rsa 现在 ls 命令查看一下 .travis 目录应该只有 id_rsa.enc 这一个文件才对。然后我们再在当前目录下新建一个 ssh_config 用来配置 Travis 上的 SSH Client。 12345Host * User git StrictHostKeyChecking no IdentityFile ~/.ssh/id_rsa IdentitiesOnly yes 现在，我们在 Travis 网站，博客项目的设置（项目右上角）里可以看到两个用于解密私钥的环境变量： 把这两个环境变量名复制到上面的 .travis.yaml 文件里替换相应部分：12before_install: - openssl aes-256-cbc -K &lt;you_key&gt; -iv &lt;your_iv&gt; -in ./.travis/id_rsa.enc -out ~/.ssh/id_rsa -d 这样，全部的配置就完成了。 Tips： Github 还支持 Application Token 的方式来认证身份，比使用 SSH 私钥要更简便，但考虑到 Coding.net 并不支持，我还是选择普适的方法。有兴趣的同学可以自己研究一下，就当做课后作业吧:D。 完成工作流在进行工作流之前我们来检查一下我们现在工作目录和所有必须的东西：123456789101112131415161718.├── .travis*│ ├── id_rsa.enc│ └── ssh_config├── _config.yml*├── db.json*├── node_modules├── package.json*├── scaffolds*├── source*│ ├── CNAME*│ ├── _posts│ ├── about│ ├── categories│ ├── img│ ├── media│ └── tags└── themes 我用星号标记的文件和文件夹都是十分重要的，确保 Git 覆盖了这些文件和目录，然后我们把目录 push 到 github/blog-source 仓库分支。Travis WebHook 立马就会检测到 push，然后开始构建了： 上图是一次成功的构建，我们可以点开 Job log 看一下构建过程的 Log 文件，特别是构建没有成功的话，我们更要仔细阅读，找准问题，对症下药。构建成功以后再去刷新你的网页，是不是已经是最新的了呢？ 以上是利用 Travis 实现全自动部署 文章作者写的非常详细，我就完全复制转载过来了，非常感谢。 原文作者: Kun Chen 原文链接：http://kchen.cc/2016/11/12/hexo-instructions/ 侵删]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>Travis CI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[随便写点]]></title>
    <url>%2Fto-self.html</url>
    <content type="text"><![CDATA[想起曾今为了买电脑，每天都要去看下评测，总是感觉那是个莫大的荣誉，可是现在，都不愿意摸电脑了，哈哈，朋友圈、空间这些东西不再玩了，牢骚也不再去分享了。感觉人都要变老了，没那么大精力去玩了。 看看镜子里的自己，可能没感觉，还是这么的年轻，突然拿起以前刚入大学的照片，真是一个天上，一个地下，现在人也变黑了，感觉脸上的棱角也要抹平了。世界的一切都没有变，只是我变了，变老了，生命从来都不等人，朋友们现在都开始展示自己的高调生活了，手机、车子还有房子了，现在自己虽然说刚毕业，义务所有，一切还需要自己打拼。我也想成为了不起的人，但是你想成为的人，也会失去大把周围的美丽的风景。 可能从小到大，我都是个很闷的人吧，可能还很小气，不想跟别人分享任何东西吧，却往往忽视了这个世界上关心我的人了。对的，不管什么什么时候，都不能忘记曾经对自己好的人，即使只是一餐饭，还是一声关心问候，甚至只是一句玩笑话。应该留点时间给老爸老妈了，他们的头发都开始白了。现在在武汉工作，尽可能的近一点，方便一点吧，多点时间回家吧。 我想，自己已经早已经过了那个年少的年纪了，不能再不顾后果的做一件事情，即使是自己多么喜爱，多么不想放弃的一件事，一个东西，还是一个人。最美好的时光，莫过于再一个人的年少，无知者无畏。“花有重开日，人无再少年。” 虽然想成熟了，但是自己也没经历过什么大事，心里还是那个满心忐忑的少年吧，嗯，其实我也没变什么，还是那么简单：去做自己喜欢做的事情，去爱自己想爱的人。 年轻可能是现在我剩下最好的礼物可，不能浪费了，前面的时光我放弃了很多的东西，如今追回来虽然好难，但是我是不会轻易言弃的。不管在经历着什么，都要记得每一天，认认真真的，不要去放弃了。 我这个人的圈子很小，没什么朋友，很闷，也很慢热，，遇到苦难了，想坚持，也想放弃，不想逗留。曾经也想改变性格，但是实在是很无力，反而让自己很难受，反正这是上天给予我的礼物，现在我的工作和生活也不必在乎这个性格的弊端，我已经接受了。 说过生活要晶莹剔透柔软善良，想对待第一次自己喜欢的人儿一样去对待它。没有好坏，没有歧视，只用想去付出，然后得到。 我总是这么的心急，只要一切都来得及。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《苦橙》-- 歌词]]></title>
    <url>%2Fmelangolo.html</url>
    <content type="text"><![CDATA[以前听的一首很美的歌，欣赏下歌词。 苦橙林力尧越沉默 越用心包裹忽略 越多难过 容易更乐活可终究 郁结如核的感受还是被自己品尝出浅薄不甘被冷落心甘情愿被你利用榨尽真心难怪换被丢弃的理由其实我也知道我并不算成熟所以更渴望能有风雨的承受无奈连光都照不够也没有人来收获只能自己结果和坠地的疼痛其实我也知道我是有些懦弱表里不一的坚强难道也有错我只是不愿意一直妥协昧心到腐朽成色不足的苦橙难道注定就不如那些罐头讨喜地被拥有 越肺腑 越失心袒露他们 都多事故 而我多冲动学不会 深加工过的笑容就留给他们礼貌地对我你也别内疚反正我被笑过很多卖相不好又怎么能怪人不识货其实我也知道我并不算成熟所以更渴望能有风雨的承受无奈连光都照不够也没有人来收获只能自己结果和坠地的疼痛其实我也知道我是有些懦弱表里不一的坚强难道也有错我只是不愿意一直妥协昧心到腐朽成色不足的苦橙难道注定就不如那些罐头讨喜地被拥有你别内疚反正现在我已想通卖相不好也许才有真心等候]]></content>
      <categories>
        <category>那些很美的句子</category>
      </categories>
      <tags>
        <tag>歌词</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《浮生》-- 歌词]]></title>
    <url>%2Ffloating-life.html</url>
    <content type="text"><![CDATA[今天听到这首歌，第一次听到它，我感觉无穷的想念都涌出来了，说真的，我哭了。 浮生刘莱斯无人与我把酒分无人告我夜已深无人问我粥可暖无人与我立黄昏他真的很喜欢你 像风走了八千里他真的很喜欢你 像阵雨下到了南极他真的很想念你 像珊瑚沉在海底他真的很喜欢你 不问归期不远万里他真的很喜欢你 像盲人看一出哑剧他真的很喜欢你 像第一首诗不尽人意他真的很喜欢你 像太阳自转无论朝夕他真的很喜欢你 千言万语乐此不疲 他真的很喜欢你 像春雨下得淅淅沥沥他真的很喜欢你 像夏日聒噪的蝉鸣他真的很想念你 像秋叶落得悄无声息他真的很喜欢你 想冬天的雪沁在心里他真的很喜欢你 像狗本性难移他真的很喜欢你 所以他可以一直没脸没皮他真的很想念你 无时不刻不在想你他真的很喜欢你 所以他把你捧在手心他真的很喜欢你 所以固执地排比比喻他真的很喜欢你 虽然他的感情实在细腻他真的很想念你 真的无时不刻不再想你他真的很喜欢你 不想浪费时间的一点一滴他真的 很喜欢你他真的 很喜欢你他真的 很想念你他真的 很喜欢你 很喜欢很喜欢你有人与我把酒分有人告我夜已深有人问我粥可暖有人与我立黄昏有人待我诚且真有人忧我细无声有人知我冷与暖有人伴我度余生]]></content>
      <categories>
        <category>那些很美的句子</category>
      </categories>
      <tags>
        <tag>歌词</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[不眠]]></title>
    <url>%2Fnever-sleeping.html</url>
    <content type="text"><![CDATA[一直在想起你，反反复复告诉自己不要打扰你了，其实我总是这么的固执，一次次骗自己，但还是没能停下颤抖的手，向你发送了一个憨笑的表情。 每次发送一条消息，有时候要想半天，怎么能去撩动你的心，虽然大多数的时候没能得到回应，但每次发完我得内心，总是还是很期待的，不知道这种感觉是从什么时候开始的，是多年前的高中，还是现在， 我想，不期待太多的回应，但愿一切安好吧，我想，我还是太懦弱了，虽然想追回你，照顾你，但我真不知道该用什么来追回你，可能我这个人真有点烂了，没付出过什么，也没做过什么刻骨铭心的事情，只有等待，等待就等于没有结果。 一个又一个夜晚吧，一次又一次的念，我的生活就是这样的吧，做自己想做的事，买想买的东西，去和喜欢的人聊聊天，很快乐，虽然很打扰，但是抱歉，我很自私。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gzip stdin not in gzip format的错误]]></title>
    <url>%2Fgzip-error.html</url>
    <content type="text"><![CDATA[出现这个错误，觉得很奇怪，网上全部都说是去掉文件后缀.gz，要不就是使用-xvf，不要加上参数z。但是这种方法不能解决我的错误。 1234567[root@localhost opt]# tar -xvf redis-3.2.4.tar.gzgzip: stdin: not in gzip formattar: Child returned status 1tar: Error is not recoverable: exiting now[root@localhost opt]# file redis-3.2.4.tar.gz redis-3.2.4.tar.gz: HTML document, UTF-8 Unicode text 语 法：file [-beLvz][-f &lt;名称文件&gt;][-m &lt;魔法数字文件&gt;...][文件或目录...] 可以看出来，我们下载下来的文件并不是我们想要的，弄了半天，它只是一个html页面，气死人是吧。 补充说明：通过file指令，我们得以辨识该文件的类型。 参 数： -b 列出辨识结果时，不显示文件名称。 -c 详细显示指令执行过程，便于排错或分析程序执行的情形。 -f &lt;名称文件&gt; 指定名称文件，其内容有一个或多个文件名称呢感，让file依序辨识这些文件，格式为每列一个文件名称。 -L 直接显示符号连接所指向的文件的类别。 -m &lt;魔法数字文件&gt; 指定魔法数字文件。 -v 显示版本信息。 -z 尝试去解读压缩文件的内容。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redies安装]]></title>
    <url>%2Fredis.html</url>
    <content type="text"><![CDATA[安装下载直接去官网下载最新版的，前面使用wget下载半天下载下来的全是错误文件，浪费了大把时间，最重要的是浪费心情。 Redis官网(redis.io) 解压1[root@localhost bin]# tar xzf redis-4.0.2.tar.gz 编译进入解压的文件中 1cd redis-4.0.2 编译123makecd srcmake install PREFIX=/usr/local/redis 文件管理新建文件夹1mkdir -p /usr/local/redis/etc 移动config文件 1mv ./redis.conf /usr/local/redis/etc/ 启动Redis服务1/usr/local/redis/bin/redis-server 前台运行中 想要后台运行修改配置文件1vim /usr/local/redis/etc/redis.conf 将daemonize的值改为yes 后台运行命令1 /usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf 查看端口12[root@localhost bin]# netstat -tunpl | grep 6379 tcp 0 0 127.0.0.1:6379 0.0.0.0:* LISTEN 5769/./redis-server 启动成功。 客户端登陆12345[root@localhost bin]# /usr/local/redis/bin/redis-cli 127.0.0.1:6379&gt; set foo barOK127.0.0.1:6379&gt; get foo"bar" 关闭服务1/usr/local/redis/bin/redis-cli shutdown redis开机自启 vim /etc/rc.local底部添加 /usr/local/redis/bin/redis-server /usr/local/redis/etc/redis-conf 了解123456789redis-benchmark：redis性能测试工具 redis-check-aof：检查aof日志的工具 redis-check-dump：检查rdb日志的工具 redis-cli：连接用的客户端 redis-server：redis服务进程 剩下就是配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849daemonize：如需要在后台运行，把该项的值改为yes pdifile：把pid文件放在/var/run/redis.pid，可以配置到其他地址 bind：指定redis只接收来自该IP的请求，如果不设置，那么将处理所有请求，在生产环节中最好设置该项 port：监听端口，默认为6379 timeout：设置客户端连接时的超时时间，单位为秒 loglevel：等级分为4级，debug，revbose，notice和warning。生产环境下一般开启notice logfile：配置log文件地址，默认使用标准输出，即打印在命令行终端的端口上 database：设置数据库的个数，默认使用的数据库是0 save：设置redis进行数据库镜像的频率 rdbcompression：在进行镜像备份时，是否进行压缩 dbfilename：镜像备份文件的文件名 dir：数据库镜像备份的文件放置的路径 slaveof：设置该数据库为其他数据库的从数据库 masterauth：当主数据库连接需要密码验证时，在这里设定 requirepass：设置客户端连接后进行任何其他指定前需要使用的密码 maxclients：限制同时连接的客户端数量 maxmemory：设置redis能够使用的最大内存 appendonly：开启appendonly模式后，redis会把每一次所接收到的写操作都追加到appendonly.aof文件中，当redis重新启动时，会从该文件恢复出之前的状态 appendfsync：设置appendonly.aof文件进行同步的频率 vm_enabled：是否开启虚拟内存支持 vm_swap_file：设置虚拟内存的交换文件的路径 vm_max_momery：设置开启虚拟内存后，redis将使用的最大物理内存的大小，默认为0 vm_page_size：设置虚拟内存页的大小 vm_pages：设置交换文件的总的page数量 vm_max_thrrads：设置vm IO同时使用的线程数量]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于SEO]]></title>
    <url>%2Fseo.html</url>
    <content type="text"><![CDATA[简介 SEO是由英文Search Engine Optimization缩写而来， 中文意译为“搜索引擎优化”！SEO是指通过对网站进行站内优化和修复(网站Web结构调整、网站内容建设、网站代码优化和编码等)和站外优化，从而提高网站的网站关键词排名以及公司产品的曝光度。通过搜索引擎查找信息是当今网民们寻找网上信息和资源的主要手段。(来自百度百科) 关于谷歌站长平台Google Search Console在国内使用谷歌大家都懂的，这里就说下谷歌收录我们的网站 登陆谷歌站长平台，验证我们的网站的所有权，推荐使用html验证，方便。 然后提交我们的sitemap.xml站点地图，谷歌爬虫就会自动去抓取我们的网站了。 网站提交到谷歌大约一到两天就会被收录，速度是相当快的。 关于百度站长平台在国内的网站，离开了百度，就可以回去玩泥巴了。 所以，在国内的网站优先做好百度这边的相关优化，相对于谷歌，百度这边的东西稍微复杂点，需要花点时间研究下。 链接提交百度上分为两种链接提交方式，当然你可以都是用，或者使用其中一种。 自动提交自动提交又分三种方式，一样的你也可以都使用。 主动推送调用百度给我们生成的接口，在我们推送网页到服务器的时候，可以自动提交我们的网站到百度站长平台。（推荐） 自动推送1234567891011121314&lt;script&gt;(function()&#123; var bp = document.createElement('script'); var curProtocol = window.location.protocol.split(':')[0]; if (curProtocol === 'https') &#123; bp.src = 'https://zz.bdstatic.com/linksubmit/push.js'; &#125; else &#123; bp.src = 'http://push.zhanzhang.baidu.com/push.js'; &#125; var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(bp, s);&#125;)();&lt;/script&gt; 在我们需要推送的网页上加上这个js脚本，每次打开这个网页，都会自动将网页推送给百度。 sitemap提交我们的sitemap.xml，百度爬虫可以自动抓取我们的网站。 手动提交故名思意，把我们的网页都填上去，手动提交。相对上面的自动提交，就显得比较麻烦。 robots百度上的说明： 使用说明1、robots.txt可以告诉百度您网站的哪些页面可以被抓取，哪些页面不可以被抓取。2、您可以通过Robots工具来创建、校验、更新您的robots.txt文件，或查看您网站robots.txt文件在百度生效的情况。3、Robots工具目前支持48k的文件内容检测，请保证您的robots.txt文件不要过大，目录最长不超过250个字符。 很容易理解，不知道怎么生成，可以去网站百度robots有自动生成的站长工具。 优化网站按道理说目录结构越简单，爬虫越容易抓取。 网页尾缀改成.html 国内网站不要挂在Github Page上面，百度爬虫抓取不到。 给非友情链接的出站链接添加 “nofollow” 标签，爬虫会从你网站跑出去，再也回不来了，加上这个标签，爬虫不回去爬取这个链接，便签避免不必要的PR输出。 网站关键字keywords 网站简介 description 网站 title 关键字出现在title标题里是有利于seo优化的，前提是你的目标关键词已经确定好。如果确定好的话，尽可能让它们在title标题尽量靠前，同时标题总字数注意控制在80个字符以内，切勿堆砌关键字。title的标点符号：关键词分割符号英文半角逗号，_ | ;品牌与关键词分割符号 - 周末了，休息了。这个国庆要加班，难受。。。 update20171002 哈哈 今日头条销售威胁 这个新闻看了下， 9月30日消息，近日某锁具商家老板表示，遭到今日头条销售威胁，如果继续在百度投放广告，而不在今日头条投放广告，将让自己团队的人一起点击直到商家百度余额为负。据该商家老板的录音，近日，他接到今日头条销售电话，“你们百度这边还有多少余额啊？我看看要不要再点一下。你这边真的不考虑一下其他平台吗？”在老板表示不考虑其他平台后，该销售称刚才已经让团队每个人都点一下了，大概一千个人吧，可能让该商家百度的余额等一会是负的。“所以说没事呀，不是挺好的嘛，你做（百度）嘛！你做！我们点嘛！做，一直做得你做到什么时候我们点到什么时候。”随后，在威胁商家后，该销售向推荐今日头条，不过并未多加介绍，直接向商家表示，现在把微信加一下，把我的账号发给你，然后你打一下款就好了。 如果在以前，对这个事件可能感觉到不可思议，但是，目前，百度凤巢 推广后，导致这个国内互联网竞价有点变化，以前都是看谁出的钱多，谁往上，现在还要看质量，网页排版，体验有很大影响。所以现在要竞价更高，而且还是在背后计算，才能出结果。 据说莆田系医院的广告，点一次，需要付1000以上，可怕，大家为了正义keyi 多点点，当然每天每个IP只生效一次，就是那种带金色V的。 update20171009 关于博客长时间没更新后，导致收录量降低的问题 总结就是博客质量不行咯，扎心了/。当然坚持更新下，估计还是会回来的，真是心累，百度这种算法要累死人。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>SEO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高四位，低四位]]></title>
    <url>%2Fbyte.html</url>
    <content type="text"><![CDATA[问题今天做业务的时候，遇到个问题，做协议的消息处理中，有个档位类型，分高四位是一种档位，低四位是例外的一种档位，当时看到需求一阵懵，百度了下，才了解了下，才清楚。 其实这个就是4个位加上四个位，刚好一个字节，就是一个byte，例如00011000，我们需要把它拆开。 实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * @ClassName: GearsType * @Description: 档位类型 * @author zhangkai * @date 2017年9月23日 下午2:16:23 * */enum GearsType &#123; //空挡 G00((byte)0, "空档", true), //高4位档 G01((byte)1, "倒车档", true), G02((byte)2, "低速档", true), G03((byte)4, "中速档", true), G04((byte)8, "高速挡", true), //低4位档 G05((byte)1, "1档", false), G06((byte)2, "2档", false), G07((byte)4, "3档", false), G08((byte)8, "4档", false); private Byte name; private String value; private Boolean flag; /** * @param name * @param value * @param flag */ private GearsType(Byte name, String value, Boolean flag) &#123; this.name = name; this.value = value; this.flag = flag; &#125; /** * 获取档位 * @param string * @return */ public static String getValue(String string) &#123; Byte index = Byte.parseByte(string); if (index == G00.name) &#123; return G00.value; &#125; byte high = (byte) ((index &amp; 0xf0) &gt;&gt; 4);// 高四位 byte low = (byte) (index &amp; 0x0f);// 低四位 String highResult = null; String lowResult = null; for (GearsType g : GearsType.values()) &#123; // 高四位 if (g.flag &amp;&amp; g.name == high &amp;&amp; highResult == null) &#123; highResult = g.value; // 低四位 &#125; else if (!g.flag &amp;&amp; g.name == low &amp;&amp; lowResult == null) &#123; lowResult = g.value; &#125; &#125; return highResult == null || lowResult == null ? null : highResult + "/" + lowResult; &#125;&#125; 学习0xf0 是 8位 ：1111 0000使用位与操作符&amp;，再将它右移4位，就可以得到高四位了，同理可以得到低四位。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20170917]]></title>
    <url>%2F20170917.html</url>
    <content type="text"><![CDATA[今天是周日，作为个程序员，就不要在这个好日子出去浪了，安心，最该就是要注意养好身体，哈哈，因为上班确实有点累。 但是，但是了，个人生活也不能太糟蹋了，都说程序员的生活就像只无头的苍蝇，邋遢的很，这句话，说点就有点不对了，我今天就要来个大扫除了，毕竟，这个狗窝我还得住好长一段日子。 一大早做个早餐吃下，就把被褥，都扔进洗衣机了，接下来搞卫生了，突然发现门上有只壁虎，但是，它已经憋成一坨了。。难受，很明显，它被门真的夹坏了。只能小心清理下它的身体，祈祷不要怪我啊啊啊，我不是有意的。 只能说经历这个就遭报应了啊，拿起简单划个快递箱子半天划不开，结果弄完，发现手上一滩血，bbb，受伤了，手上两道口子，刚才没发觉，剪刀什么时候这么快，完全没知觉。。。 现在都感觉后怕了。。明天还能去上班吗？]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven错误 Plugin execution not covered by lifecycle configuration org.codehaus.mo...]]></title>
    <url>%2Fmaven-error-one.html</url>
    <content type="text"><![CDATA[导geoserver源码时发现，我的maven项目pom.xml有几个都报错了，一时没解决记录下。 环境 eclipse - 4.61 maven 3.3.9 项目 geoserver 源码 2.11.2 出现错误正常import源码maven项目报错1234Multiple annotations found at this line:- maven-enforcer-plugin ...- Plugin execution not covered by lifecycle configuration: org.codehaus.mojo:aspectj-maven-plugin:1.3.1:compile (execution: default, phase: compile) 解决方案123456789&lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; ... &lt;/plugin&gt; &lt;plugin&gt; ... &lt;/plugin&gt; .... &lt;/plugins&gt; &lt;/pluginManagement&gt;&lt;/build&gt; 标签外再套一个 &lt;pluginManagement&gt; 标签]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MQTT在JAVA中使用]]></title>
    <url>%2Fjava-mqtt.html</url>
    <content type="text"><![CDATA[介绍 由于项目中需求，多个客户机终端不断发送位置给服务机，服务机根据消息，准确判断信息，并返回响应，回复该客户机。 在这里我们的服务机，不但要订阅所有客户机的主题，还要根据客户机消息做出相应的响应，服务机同时充当客户机使用，客户机也推送主题消息，充当服务器。 关键问题： 服务器怎么区分各个客户机 主题配置方面的问题，不可能每个机器配个主题 通信方面，选择哪种消息级别 环境配置使用maven项目，刚好在仓库导包了，可以使用（推荐）12345&lt;dependency&gt; &lt;groupId&gt;org.eclipse.paho&lt;/groupId&gt; &lt;artifactId&gt;org.eclipse.paho.client.mqttv3&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt; &lt;/dependency&gt; 仓库没有包，直接去网上下，可以直接导包到Lib中编写服务器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798package com.devframe.mqtt.test;import org.eclipse.paho.client.mqttv3.MqttClient;import org.eclipse.paho.client.mqttv3.MqttConnectOptions;import org.eclipse.paho.client.mqttv3.MqttException;import org.eclipse.paho.client.mqttv3.persist.MemoryPersistence;/** * @ClassName: ServerMQTT * @Description: 服务器接收多个客户端的主题，同时要像客户端反馈* @author zhangkai * @date 2017年9月12日 下午12:52:01 * */public class ServerMQTT &#123; // 连接参数 private final static String CONNECTION_STRING = "tcp://192.168.19.200:8001"; //host private final static boolean CLEAN_START = true; //是否清空session，false保留 private final static short KEEP_ALIVE = 30;// 低耗网络，但是又需要及时获取数据，心跳30*1.5s private final static short KEEP_TIME_OUT = 10; //连接超时 private final static String CLIENT_ID = "master";// 客户端标识 private final static int[] QOS_VALUES = &#123; 0 &#125;;// 对应主题的消息级别 private final static String[] TOPICS = &#123; "agri/#"&#125;; //匹配agri/下所有的主题 private final String userName = "agri"; private final String passWord = "admin@123"; private MqttConnectOptions options; private MqttClient mqttClient; /** * 构造函数 * * @throws MqttException */ public ServerMQTT() throws MqttException &#123; &#125; /** * 发送消息 * @param topic 主题 * @param message 消息 * @param qos 消息级别&#123;0,1,2&#125; * @param retained 是否是实时发送的消息(false=实时，true=服务器上保留的消息) */ public void sendMessage(String topic, String message, int qos, boolean retained) &#123; try &#123; //断开重连 if (mqttClient == null || !mqttClient.isConnected()) &#123; connect(); &#125; // 发布消息 mqttClient.publish(topic, message.getBytes(), qos, retained); &#125; catch (MqttException e) &#123; e.printStackTrace(); &#125; &#125; /** * 重新连接服务 */ private void connect() &#123; try &#123; mqttClient = new MqttClient(CONNECTION_STRING, CLIENT_ID, new MemoryPersistence()); // MQTT的连接设置 options = new MqttConnectOptions(); // 设置是否清空session,这里如果设置为false表示服务器会保留客户端的连接记录，这里设置为true表示每次连接到服务器都以新的身份连接 options.setCleanSession(CLEAN_START); // 设置连接的用户名 options.setUserName(userName); // 设置连接的密码 options.setPassword(passWord.toCharArray()); // 设置超时时间 单位为秒 options.setConnectionTimeout(KEEP_TIME_OUT); // 设置会话心跳时间 单位为秒 服务器会每隔1.5*30秒的时间向客户端发送个消息判断客户端是否在线，但这个方法并没有重连的机制 options.setKeepAliveInterval(KEEP_ALIVE); // 设置回调 mqttClient.setCallback(new PushCallback()); mqttClient.connect(options); mqttClient.subscribe( TOPICS , QOS_VALUES); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * 启动入口 * * @param args * @throws MqttException */ public static void main(String[] args) throws MqttException &#123; ServerMQTT server = new ServerMQTT(); server.connect(); &#125;&#125; 客户机123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120package com.devframe.mqtt.test;import java.util.concurrent.Executors;import java.util.concurrent.ScheduledExecutorService;import java.util.concurrent.TimeUnit;import org.eclipse.paho.client.mqttv3.MqttClient;import org.eclipse.paho.client.mqttv3.MqttConnectOptions;import org.eclipse.paho.client.mqttv3.MqttException;import org.eclipse.paho.client.mqttv3.MqttSecurityException;import org.eclipse.paho.client.mqttv3.persist.MemoryPersistence;public class ClientMQTT implements Runnable &#123; // 连接参数 private final static String CONNECTION_STRING = "tcp://192.168.19.200:8001"; // host private final static boolean CLEAN_START = true; // 是否清空session，false保留 private final static short KEEP_ALIVE = 30;// 低耗网络，但是又需要及时获取数据，心跳30*1.5s private final static short KEEP_TIME_OUT = 10; // 连接超时 private final static String CLIENT_ID = "client1";// 客户端标识 private final static int[] QOS_VALUES = &#123; 0 &#125;;// 对应主题的消息级别 private final static String PUBLISH_TOPIC = "agri/index1"; private final static String[] RECEIVE_TOPIC = &#123;"agri/index1/back"&#125;; private MqttClient client; private MqttConnectOptions options; private final String userName = "agri"; private final String passWord = "admin@123"; private ScheduledExecutorService scheduler; // 重新连接 public void startReconnect() &#123; scheduler = Executors.newSingleThreadScheduledExecutor(); scheduler.scheduleAtFixedRate(new Runnable() &#123; public void run() &#123; if (!client.isConnected()) &#123; try &#123; client.connect(options); &#125; catch (MqttSecurityException e) &#123; e.printStackTrace(); &#125; catch (MqttException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;, 0 * 1000, 10 * 1000, TimeUnit.MILLISECONDS); &#125; /** * 发送消息 * * @param topic * 主题 * @param message * 消息 * @param qos * 消息级别&#123;0,1,2&#125; * @param retained * 是否是实时发送的消息(false=实时，true=服务器上保留的最后消息) */ public void sendMessage(String topic, String message, int qos, boolean retained) &#123; try &#123; if (client == null || !client.isConnected()) &#123; connect(); &#125; // 发布消息 client.publish(topic, message.getBytes(), qos, retained); &#125; catch (MqttException e) &#123; e.printStackTrace(); &#125; &#125; /** * 重新连接服务 */ private void connect() &#123; try &#123; client = new MqttClient(CONNECTION_STRING, CLIENT_ID, new MemoryPersistence()); // MQTT的连接设置 options = new MqttConnectOptions(); // 设置是否清空session,这里如果设置为false表示服务器会保留客户端的连接记录，这里设置为true表示每次连接到服务器都以新的身份连接 options.setCleanSession(CLEAN_START); // 设置连接的用户名 options.setUserName(userName); // 设置连接的密码 options.setPassword(passWord.toCharArray()); // 设置超时时间 单位为秒 options.setConnectionTimeout(KEEP_TIME_OUT); // 设置会话心跳时间 单位为秒 服务器会每隔1.5*30秒的时间向客户端发送个消息判断客户端是否在线，但这个方法并没有重连的机制 options.setKeepAliveInterval(KEEP_ALIVE); // 设置回调 client.setCallback(new PushCallback()); client.connect(options); client.subscribe(RECEIVE_TOPIC, QOS_VALUES); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; // TODO 每秒一次向服务端发送消息 try &#123; int i = 0; while (true) &#123; sendMessage(PUBLISH_TOPIC, "hello,topic" + i, 0, false); i++; Thread.sleep(1000); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) throws MqttException &#123; ClientMQTT client = new ClientMQTT(); Thread thread = new Thread(client, "th1"); thread.start(); &#125;&#125; 测试的时候就是把客户机复制了几个，主题和clientid改下，clientid不能一样，不然不能登陆。 回调类发送完消息，Service需要在这里处理，着我们先做的事情啦。123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.devframe.mqtt.test;import org.eclipse.paho.client.mqttv3.IMqttDeliveryToken; import org.eclipse.paho.client.mqttv3.MqttCallback; import org.eclipse.paho.client.mqttv3.MqttMessage; /** * @ClassName: PushCallback * @Description: 发布消息的回调类 * * 必须实现MqttCallback的接口并实现对应的相关接口方法CallBack 类将实现 MqttCallBack。 * 每个客户机标识都需要一个回调实例。在此示例中，构造函数传递客户机标识以另存为实例数据。 * 在回调中，将它用来标识已经启动了该回调的哪个实例。 必须在回调类中实现三个方法： * * public void messageArrived(MqttTopic topic, MqttMessage * message)接收已经预订的发布。 * * public void connectionLost(Throwable cause)在断开连接时调用。 * * public void deliveryComplete(MqttDeliveryToken token)) * 接收到已经发布的QoS 0、 QoS 1 或 QoS 2 消息的传递令牌时调用。 由 MqttClient.connect * 激活此回调。 * @author zhangkai * @date 2017年9月12日 上午11:30:44 * */public class PushCallback implements MqttCallback &#123; public void connectionLost(Throwable cause) &#123; // TODO 连接丢失后，一般在这里面进行重连 System.out.println("连接断开，可以做重连"); &#125; public void deliveryComplete(IMqttDeliveryToken token) &#123; System.out.println("deliveryComplete---------" + token.isComplete()); &#125; public void messageArrived(String topic, MqttMessage message) throws Exception &#123; // TODO subscribe后得到的消息会执行到这里面，后续工作将在这里进行 System.out.println("接收消息主题 : " + topic); System.out.println("接收消息Qos : " + message.getQos()); System.out.println("接收消息内容 : " + new String(message.getPayload())); &#125; &#125; 总结 使用前缀通配符的方式加上特殊码区分各个机器的主题。 根据不同业务的需求，需要合理的选择不同级别的消息。 实际使用中一般把发消息的参数 retained 设为 false ，这个参数的说明是:设为true之后把消息保存到本地，每一次去订阅该主题的subscriber都会收到，每次订阅的时候都会收到，导致很多重复多余的消息。 如果在使用的过程中不小心将它设置成true，怎么去清除这个存着的消息了，mqtt本身没这个功能；解决办法：向该topic重新publish数据，RETAIN=TRUE，Payload为空。 所以，刚开始做这个都得时候就是设置成true，包括上面的测试代码，还没改过来，业务代码已经全部改好了。不然没次去连接mqtt的时候，都会订阅到一大片消息，电脑跑到卡得不行，哈哈。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>MQTT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mosquitto用户名密码配置]]></title>
    <url>%2Fmqtt-user.html</url>
    <content type="text"><![CDATA[介绍由于需要把mqtt部署到外网上面去，所以需要关闭匿名登陆，采取用户认证模式，而且还可能需要把主题加密。 配置参数说明配置参数在/etc/mosquitto/mosquitto.conf中， 123allow_anonymous 允许匿名登陆password_file 账号密码文件acl_file 访问控制列表 配置123456789101112131415[root@localhost mosquitto]# vim mosquitto.conf # Place your local configuration in /etc/mosquitto/conf.d/pid_file /var/run/mosquitto.pidpersistence truepersistence_location /var/lib/mosquitto/#log_dest file /var/log/mosquitto/mosquitto.loginclude_dir /etc/mosquitto/conf.dallow_anonymous falsepassword_file /etc/mosquitto/pwfileacl_file /etc/mosquitto/aclfileport 8001 查看用户12[root@localhost mosquitto]# cat pwfile agri:$6$NprvJLB/CkEomWGy$gNj5Mr6Wf+2Xz16P6dIZYD/ladZZtyKQMJ/tdpy7WLepj5akpPB+hF8zolrNd5IacbsAxXDWX1vS5I9Pj4fnCA== 添加用户1mosquitto_passwd -c /etc/mosquitto/pwfile wuwii 设置好密码 添加Topic和用户的关系12345678910111213141516[root@localhost ~]# vim /etc/mosquitto/aclfile# This affects access control for clients with no username.#topic read $SYS/## This only affects clients with username "roger".#user roger#topic foo/bar#user zhanguser zhangtopic read mtopic/#user zhangtopic write mtopic/## This affects all clients.# pattern write $SYS/broker/connection/%c/state 重启测试12[root@localhost mosquitto]# /etc/init.d/mosquitto restartRestarting mosquitto (via systemctl): [ 确定 ] ps:添加用户的时候会出现覆盖的问题，再看。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>MQTT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 下安装mosquitto]]></title>
    <url>%2Finstall-mosquitto.html</url>
    <content type="text"><![CDATA[简介 MQTT（Message Queuing Telemetry Transport，消息队列遥测传输）是IBM开发的一个即时通讯协议，有可能成为物联网的重要组成部分。该协议支持所有平台，几乎可以把所有联网物品和外部连接起来，被用来当做传感器和制动器（比如通过Twitter让房屋联网）的通信协议。 特点 MQTT协议是为大量计算能力有限，且工作在低带宽、不可靠的网络的远程传感器和控制设备通讯而设计的协议，它具有以下主要的几项特性：1、使用发布/订阅消息模式，提供一对多的消息发布，解除应用程序耦合；2、对负载内容屏蔽的消息传输；3、使用 TCP/IP 提供网络连接；4、有三种消息发布服务质量：“至多一次”，消息发布完全依赖底层 TCP/IP 网络。会发生消息丢失或重复。这一级别可用于如下情况，环境传感器数据，丢失一次读记录无所谓，因为不久后还会有第二次发送。“至少一次”，确保消息到达，但消息重复可能会发生。“只有一次”，确保消息到达一次。这一级别可用于如下情况，在计费系统中，消息重复或丢失会导致不正确的结果。5、小型传输，开销很小（固定长度的头部是 2 字节），协议交换最小化，以降低网络流量；6、使用 Last Will 和 Testament 特性通知有关各方客户端异常中断的机制； 安装与配置准备在/etc/yum.repos.d/目录中新建一个mosquitto.repo文件 12345678910111213[home_oojah_mqtt]name=mqtt (CentOS_CentOS-7)type=rpm-mdbaseurl=http://download.opensuse.org/repositories/home:/oojah:/mqtt/CentOS_CentOS-7/gpgcheck=1gpgkey=http://download.opensuse.org/repositories/home:/oojah:/mqtt/CentOS_CentOS-7//repodata/repomd.xml.keyenabled=1 执行 yum search all mosquitto12345678910111213[root@localhost ~]# yum search all mosquitto已加载插件：fastestmirrorLoading mirror speeds from cached hostfile * epel: mirrors.ustc.edu.cn============================================================================================================= 匹配：mosquitto ==============================================================================================================mosquitto-clients.x86_64 : Mosquitto command line publish/subscribe clientsmosquitto-debuginfo.x86_64 : Debug information for package mosquittomosquitto-devel.x86_64 : Development files for mosquittomosquitto.x86_64 : An Open Source MQTT v3.1/v3.1.1 Brokerlibmosquitto-devel.x86_64 : MQTT C client library development fileslibmosquitto1.x86_64 : MQTT C client librarylibmosquittopp-devel.x86_64 : MQTT C++ client library development fileslibmosquittopp1.x86_64 : MQTT C++ client library 安装mosquitto客户端执行 yum install -y mosquitto-clients.x86_64 1[root@localhost ~]# yum install -y mosquitto-clients.x86_64 安装mosquitto服务执行命令 yum install mosquitto.x86_64 1[root@localhost ~]# yum -y install mosquitto.x86_64 修改mosquitto.conf文件文件在/etc/mosquitto/mosquitto.conf下面是可以选择的参数 在 /etc/mosquitto/mosquitto.conf.example 中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128# ================================================================= # General configuration # ================================================================= # 客户端心跳的间隔时间 #retry_interval 20 # 系统状态的刷新时间 #sys_interval 10 # 系统资源的回收时间，0表示尽快处理 #store_clean_interval 10 # 服务进程的PID #pid_file /var/run/mosquitto.pid # 服务进程的系统用户 #user mosquitto # 客户端心跳消息的最大并发数 #max_inflight_messages 10 # 客户端心跳消息缓存队列 #max_queued_messages 100 # 用于设置客户端长连接的过期时间，默认永不过期 #persistent_client_expiration# =================================================================# Default listener# =================================================================# 服务绑定的IP地址#bind_address# 服务绑定的端口号#port 1883# 允许的最大连接数，-1表示没有限制#max_connections -1# cafile：CA证书文件# capath：CA证书目录# certfile：PEM证书文件# keyfile：PEM密钥文件#cafile#capath#certfile#keyfile# 必须提供证书以保证数据安全性#require_certificate false# 若require_certificate值为true，use_identity_as_username也必须为true#use_identity_as_username false# 启用PSK（Pre-shared-key）支持#psk_hint# SSL/TSL加密算法，可以使用“openssl ciphers”命令获取# as the output of that command.#ciphers# =================================================================# Persistence# =================================================================# 消息自动保存的间隔时间#autosave_interval 1800# 消息自动保存功能的开关#autosave_on_changes false# 持久化功能的开关persistence true# 持久化DB文件#persistence_file mosquitto.db# 持久化DB文件目录#persistence_location /var/lib/mosquitto/# =================================================================# Logging# =================================================================# 4种日志模式：stdout、stderr、syslog、topic# none 则表示不记日志，此配置可以提升些许性能log_dest none# 选择日志的级别（可设置多项）#log_type error#log_type warning#log_type notice#log_type information# 是否记录客户端连接信息#connection_messages true# 是否记录日志时间#log_timestamp true# =================================================================# Security# =================================================================# 客户端ID的前缀限制，可用于保证安全性#clientid_prefixes# 允许匿名用户#allow_anonymous true# 用户/密码文件，默认格式：username:password#password_file# PSK格式密码文件，默认格式：identity:key#psk_file# pattern write sensor/%u/data# ACL权限配置，常用语法如下：# 用户限制：user &lt;username&gt;# 话题限制：topic [read|write] &lt;topic&gt;# 正则限制：pattern write sensor/%u/data#acl_file# =================================================================# Bridges# =================================================================# 允许服务之间使用“桥接”模式（可用于分布式部署）#connection &lt;name&gt;#address &lt;host&gt;[:&lt;port&gt;]#topic &lt;topic&gt; [[[out | in | both] qos-level] local-prefix remote-prefix]# 设置桥接的客户端ID#clientid # 桥接断开时，是否清除远程服务器中的消息 #cleansession false # 是否发布桥接的状态信息 #notifications true # 设置桥接模式下，消息将会发布到的话题地址 # $SYS/broker/connection/&lt;clientid&gt;/state #notification_topic # 设置桥接的keepalive数值 #keepalive_interval 60 # 桥接模式，目前有三种：automatic、lazy、once #start_type automatic # 桥接模式automatic的超时时间 #restart_timeout 30 # 桥接模式lazy的超时时间 #idle_timeout 60 # 桥接客户端的用户名 #username # 桥接客户端的密码 #password # bridge_cafile：桥接客户端的CA证书文件 # bridge_capath：桥接客户端的CA证书目录 # bridge_certfile：桥接客户端的PEM证书文件 # bridge_keyfile：桥接客户端的PEM密钥文件 #bridge_cafile #bridge_capath #bridge_certfile #bridge_keyfile # 自己的配置可以放到以下目录中 include_dir /etc/mosquitto/conf.d 启动服务1mosquitto -c /etc/mosquitto/mosquitto.conf -d 12[root@localhost mosquitto]# /etc/init.d/mosquitto startRestarting mosquitto (via systemctl): [ 确定 ] 重启12[root@localhost mosquitto]# /etc/init.d/mosquitto restartRestarting mosquitto (via systemctl): [ 确定 ] 主要还是根据需求来配置好用户和加密，用的时候需要了解mqtt协议。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>MQTT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[心]]></title>
    <url>%2Fheart00.html</url>
    <content type="text"><![CDATA[不知道现在你过得到底怎么样，看到你的签名又换了“心比长相好，懂比爱重要”。 当一个假文艺青年、一个又对你敏感的人看到这句话的时候。我想你可能经历了这段失败的感情真的伤得很深吧。 想照顾你的人很多吧，真的本该消失的人不该再来出现了，我也迷茫了，感觉这段时间忘的东西好快，过的没感觉，没心没肺了。 但是姑娘，最懂你的是自己啊，自己想什么就勇敢做吧，不要记挂在别人身上，也不用太在意别人感受，即使再大的事情还是需要自己来抗，如果听到身边的人一句安慰就溃不成军的话，那还有什么意义了。希望你能坚强，冲动和任性的事情也要少做呀！ 但是姑娘不要自我怀疑，不要慌张，你很优秀，一定会嫁给爱情的。越是着急，就越容易受伤。除了爸妈，不必在乎催促你的人，大多数的他们的知识随口问问而已，他们只关心你结没结婚，谈没谈恋爱，真的不必放在心上。 希望你能努力生活，丰富自己，愿生活有诗，有梦，有远方，还有一个懂你、爱你的可心人。 愿大家都越变越好。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Geotools做个最简单叠加分析]]></title>
    <url>%2Fgeotools-over-analyze.html</url>
    <content type="text"><![CDATA[简介最近需要利用Geotools开发一些业务需求，今天刚开始搞。本来说是跟跟最新版的geoserver中的geotools一个版本，我的geoserver版本如下 geotools版本是17.2就屁颠的去项目的pom.xml配置了123456789101112131415161718&lt;geotools.version&gt;17.2&lt;/geotools.version&gt;&lt;!-- Provides support for PostGIS. Note the different groupId --&gt; &lt;dependency&gt; &lt;groupId&gt;org.geotools.jdbc&lt;/groupId&gt; &lt;artifactId&gt;gt-jdbc-postgis&lt;/artifactId&gt; &lt;version&gt;$&#123;geotools.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.geotools&lt;/groupId&gt; &lt;artifactId&gt;gt-cql&lt;/artifactId&gt; &lt;version&gt;$&#123;geotools.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.geotools&lt;/groupId&gt; &lt;artifactId&gt;gt-opengis&lt;/artifactId&gt; &lt;version&gt;$&#123;geotools.version&#125;&lt;/version&gt; &lt;/dependency&gt; 出了点×结果，一直报错这几个包下不下来，我使用的是国内的阿里云镜像。刚开始我还以为是阿里云仓库没这几个包，换成了国外的节点，结果也下不了。网上去看了下最新的17.2全有，不知道为什么突然下不了。弄了好半天，坑死了有木有啊。后来想到我不是做了geoserver的开发了吗？也是maven项目，知道geoserver使用的geotools开发的，那它的jar包是从哪里来的。打开geoserver 源码一看，结果一看人家用的是 18-SNAPSHOT做事还是冒失了点，我应该去仓库看下我的版本号，最后搞得一头包。好了，解决了包得问题直接干活敲代码，很简单 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159import java.io.IOException;import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Map;import org.geotools.data.DataStore;import org.geotools.data.DataStoreFinder;import org.geotools.data.postgis.PostgisNGDataStoreFactory;import org.geotools.data.simple.SimpleFeatureCollection;import org.geotools.data.simple.SimpleFeatureSource;import org.geotools.feature.FeatureIterator;import org.geotools.filter.text.cql2.CQL;import org.geotools.filter.text.cql2.CQLException;import org.geotools.geometry.jts.JTSFactoryFinder;import org.opengis.feature.simple.SimpleFeature;import org.opengis.filter.Filter;import com.vividsolutions.jts.geom.Geometry;import com.vividsolutions.jts.geom.GeometryFactory;import com.vividsolutions.jts.io.ParseException;import com.vividsolutions.jts.io.WKTReader;/** * @ClassName: GeotoolsUtils * @Description: Geotools tools solution* @author zhangkai * @date 2017年9月7日 下午3:15:53 * */public class GeotoolsUtils &#123; private static DataStore pgDatastore; /** * 连接数据库 * @param dbtype postgresql * @param host 主机 * @param port 端口 * @param database 数据库 * @param userName * @param password */ private static void conn(String dbtype, String host, String port, String database, String userName, String password) &#123; Map&lt;String, Object&gt; params = new HashMap&lt;String, Object&gt;(); params.put(PostgisNGDataStoreFactory.DBTYPE.key, dbtype); params.put(PostgisNGDataStoreFactory.HOST.key, host); params.put(PostgisNGDataStoreFactory.PORT.key, new Integer(port)); params.put(PostgisNGDataStoreFactory.DATABASE.key, database); params.put(PostgisNGDataStoreFactory.SCHEMA.key, "public"); params.put(PostgisNGDataStoreFactory.USER.key, userName); params.put(PostgisNGDataStoreFactory.PASSWD.key, password); try &#123; pgDatastore = DataStoreFinder.getDataStore(params); if (pgDatastore != null) &#123; System.out.println("系统连接到位于：" + host + "的空间数据库" + database + "成功！"); &#125; else &#123; System.out.println("系统连接到位于：" + host + "的空间数据库" + database + "失败！请检查相关参数"); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); System.out.println("系统连接到位于：" + host + "的空间数据库" + database + "失败！请检查相关参数"); &#125; &#125; /** * 条件查询 * @param filterStr sql条件 * @param layerName 图层名 * @return * @throws IOException */ public static ArrayList&lt;SimpleFeature&gt; queryMethod(String filterStr, String layerName) throws IOException &#123; SimpleFeatureSource featureSource =pgDatastore.getFeatureSource(layerName); ArrayList&lt;SimpleFeature&gt; featureList = new ArrayList&lt;SimpleFeature&gt;(); if(featureSource==null) return featureList; try &#123; SimpleFeatureCollection result = null; if (!StringUtils.isEmpty(filterStr)) &#123; Filter filter; // filterStr : convert 'SQL' into 'CQL' filter = CQL.toFilter(filterStr); result = featureSource.getFeatures(filter); &#125; else &#123; result = featureSource.getFeatures(); &#125; FeatureIterator&lt;SimpleFeature&gt; itertor = result.features(); while (itertor.hasNext()) &#123; SimpleFeature feature = itertor.next(); featureList.add(feature); &#125; itertor.close(); return featureList; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (CQLException e) &#123; e.printStackTrace(); &#125; return null; &#125; /** * 判断一个点在一个面里 * @param point * @param polygon * @return */ public static boolean containsPonit(Geometry point, Geometry polygon) &#123; return polygon.contains(point); &#125; /** * 查询地块，判断一个点是否在面里（可能多个面） * @param filterStr 查询条件 * @param layerName 图层名 * @param point 点位置 * @return */ public static boolean MultitudeContainsPonit(String filterStr, String layerName, Geometry point) &#123; boolean result = false; List&lt;Geometry&gt; listGeometry = getGeometryByCondition(filterStr, layerName); for (Geometry geometry : listGeometry) &#123; result = containsPonit(point, geometry); if (result) &#123; return result; &#125; &#125; return result; &#125; /** * 根据条件查询该图层中的geometry * @param filterStr 查询条件 * @param layerName 图层名字 * @return */ public static List&lt;Geometry&gt; getGeometryByCondition(String filterStr, String layerName) &#123; List&lt;Geometry&gt; result = new ArrayList&lt;Geometry&gt;(); ArrayList&lt;SimpleFeature&gt; list = null; try &#123; list = queryMethod(filterStr, layerName); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; for (SimpleFeature feature : list) &#123; Geometry geo = (Geometry) feature.getDefaultGeometry(); result.add(geo); &#125; return result; &#125; 测试 简单测试下123456789101112131415public static void main(String[] args) throws IOException, ParseException &#123; conn("postgis", "192.168.19.200", "5432", "agrigisdb", "postgres", "postgres"); //String wktPoly = "MultiPOLYGON (((30 10, 40 40, 20 40, 10 20, 30 10)))"; //wkt格式 String wktPoint = "POINT (50 50)"; WKTReader reader = new WKTReader(JTSFactoryFinder.getGeometryFactory()); GeometryFactory geometryFactory = JTSFactoryFinder.getGeometryFactory(null); Geometry point = reader.read(wktPoint); //Geometry poly = reader.read(wktPoly); if (MultitudeContainsPonit("\"mc\"='武汉市'", "xzqxian", point)) &#123; System.out.println("叠加了"); &#125; else &#123; System.out.println("没叠加了"); &#125; pgDatastore.dispose(); &#125; 还是太心急，被个小问题差点Over了，我都准备最蠢的办法，直接下包，蠢哭了，我已经下下来了，80+M。记录下。加油。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Geotools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于难产孕妇跳楼事件]]></title>
    <url>%2Fyunfu-event.html</url>
    <content type="text"><![CDATA[看到新闻，难产孕妇跳楼身亡，真的很难想象，这个产妇经历了什么，才选择了这么个结果，一尸两命。 可能传统的文化，在大多数人眼里，顺产对孩子比较好吧。 整个事情我可能不是很了解，但是这是这个家庭的悲剧，也是社会的一个反射。一个女人，怀孕了都不能决定自己的命运，是在多么绝望的情况下，才跳下楼。 反思就不多说，每个人都清楚。 记录，改变就是最好的。]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[叫魂]]></title>
    <url>%2Fjiao-hun-awakening.html</url>
    <content type="text"><![CDATA[最近人的心很杂乱，总是回忆起以前的种种，加上今天是中元节，想起了以前的一件事，正式说法应该是叫魂。 大约十三四岁的时候，严冬，我记得冷得厉害，我生了一场重病，高烧39度，吊针了一周都没退下去，而且人还难受得厉害了。有时候还会呻吟。老人们都见的世道多，说我有可能见鬼了，弄不好小命都可能保不住了。很无奈，母亲带我去村里的一个老奶奶家里。当时我很奇怪，把我带到一个黑漆漆的屋子里，开了灯，被吓到，就是跟看恐怖片一样，满墙都是各种奇怪的字画、条幅。很快，老奶奶一算，说是我被鬼吓的，掉了魂，是被村里的池塘里淹死的小孩下的（那个池塘就在上学的路上，确实淹死过小孩），后来问我有没有在池塘边摔倒过，这个倒是记得太清楚了。随后，她烧起纸钱，让我去烧香、磕头，最后是喝水拌下纸钱留下的灰，晚上还得去池塘边烧纸。如此，第二天病真的基本好了。不过，却给我留下别的后遗症了，有时候会想，这世间真的有鬼神吗？ 我也不知道这些奇奇怪怪的事情应该怎么解释，但是那位老奶奶确实帮助不少人治好了疑难杂症，不乏一些从城里专门过来拜访的人。但，我只知道这个应该是祖祖辈辈传下来的，也只要那些稀奇古怪的人在这些特殊的场合才会有人使用的吧。 虽然事情过了很长时间，但是我也从没忘记这些事情，后来在网上查到，说这个事情是–叫魂。 还说到这些人都要受耻，因为他们泄露了大秘密，需要忏悔，所有对别人的好，都要降罪到自己身上。 多年前，那位老奶奶也去世了，听说各地来的人很多。听我妈说，信佛的人不能跟他们走太近。 往事如风，生活中处处充满了不一样的故事，虽然这个事情没人能够解释它，但是它却是确确实实存在的啊。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>奇异</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[枚举的封装设计]]></title>
    <url>%2Fenumeration-package-design.html</url>
    <content type="text"><![CDATA[enum 的全称为 enumeration， 是 JDK 1.5 中引入的新特性，存放在 java.lang 包中。虽然功能少，但是实际开发中还是非常方便的。 12345678910111213141516171819202122232425public enum MenuType &#123;// 注意：枚举成员命名，请使用英文大写形式 /** * 目录 */ CATALOG(0), /** * 菜单 */ MENU(1), /** * 按钮 */ BUTTON(2); private int value; // 私有的构造方法 private MenuType(int value) &#123; this.value = value; &#125; public int getValue() &#123; return value; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748static enum Operation &#123; GETCAPABILITIES &#123; public int getCode() &#123; return 0; &#125; &#125;, DESCRIBEFEATURETYPE &#123; public int getCode() &#123; return 0; &#125; &#125;, GETFEATURE&#123; public int getCode() &#123; return 1; &#125; &#125; , LOCKFEATURE&#123; public int getCode() &#123; return 2; &#125; &#125; , TRANSACTION_INSERT &#123; public int getCode() &#123; return 4; &#125; &#125;, TRANSACTION_UPDATE &#123; public int getCode() &#123; return 8; &#125; &#125;, TRANSACTION_DELETE &#123; public int getCode() &#123; return 16; &#125; &#125;, TRANSACTION_REPLACE &#123; public int getCode() &#123; return 32; &#125; &#125;; abstract public int getCode(); &#125; public static void main(String[] args) &#123; System.out.println(Operation.TRANSACTION_INSERT.getCode()); &#125;]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>枚举</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分享：李开复：我的爱情故事]]></title>
    <url>%2Fkaifu-love-story.html</url>
    <content type="text"><![CDATA[最好的爱情，并不是终日互相对视，而是共同眺望远方，相伴而行。他们眺望着的，始终是同一个方向。 李开复：我的爱情故事]]></content>
      <categories>
        <category>分享</category>
      </categories>
      <tags>
        <tag>李开复</tag>
        <tag>感情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于npm install hexo出错]]></title>
    <url>%2Fhexo_install_error.html</url>
    <content type="text"><![CDATA[出现问题 最近跳槽换公司后，又要重新在公司电脑上搭个hexo blog环境，从github上拷贝下自己的源码后，执行npm install hexo 突然报错了。 node -v8.4.0x64 123456789101112131415161718192021222324PS D:\zhangkai\WorkSpace\Git\hexo&gt; npm install hexo&gt; dtrace-provider@0.8.3 install D:\zhangkai\WorkSpace\Git\hexo\node_modules\dtrace-provider&gt; node scripts/install.jsnpm ERR! path D:\zhangkai\WorkSpace\Git\hexo\node_modules\fsevents\node_modulesnpm ERR! code EPERMnpm ERR! errno -4048npm ERR! syscall scandirnpm ERR! Error: EPERM: operation not permitted, scandir 'D:\zhangkai\WorkSpace\Git\hexo\node_modes'npm ERR! &#123; Error: EPERM: operation not permitted, scandir 'D:\zhangkai\WorkSpace\Git\hexo\node_dules'npm ERR! stack: 'Error: EPERM: operation not permitted, scandir \'D:\\zhangkai\\WorkSpace\\Gitevents\\node_modules\'',npm ERR! errno: -4048,npm ERR! code: 'EPERM',npm ERR! syscall: 'scandir',npm ERR! path: 'D:\\zhangkai\\WorkSpace\\Git\\hexo\\node_modules\\fsevents\\node_modules' &#125;npm ERR!npm ERR! Please try running this command again as root/Administrator.npm ERR! A complete log of this run can be found in:npm ERR! C:\Users\server\AppData\Roaming\npm-cache\_logs\2017-08-31T02_56_34_677Z-debug.log 看上面的问题就是path有问题，去电脑找这个目录找啊找，完全没有，坑爹啊。由于我目前完全不懂node.js和npm只好问候百度大爷。 找到问题 解决查看当前的npm版本12PS D:\zhangkai\WorkSpace\Git\hexo&gt; npm -v5.3.0 更新到最新版，使用taobao镜像1234PS D:\zhangkai\WorkSpace\Git\hexo&gt; npm install -g cnpm --registry=http://registry.npm.taobao.orgC:\Users\server\AppData\Roaming\npm\cnpm -&gt; C:\Users\server\AppData\Roaming\npm\node_modules\cnpm\bin\cnpm+ cnpm@5.1.1added 643 packages in 84.276s 如果想更新到指定版本，运行指令 1npm -g install npm@2.9.1 重新查看npm版本号12PS D:\zhangkai\WorkSpace\Git\hexo&gt; npm -v5.3.0 ps:版本完全没变化，心凉了，还是试试吧。重新执行，成功解决 1234567891011PS D:\zhangkai\WorkSpace\Git\hexo&gt; npm install hexo&gt; dtrace-provider@0.8.5 install D:\zhangkai\WorkSpace\Git\hexo\node_modules\dtrace-provider&gt; node scripts/install.jsnpm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.1.2 (node_modules\fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.1.2: wanted &#123;"os":"darwin","arch":"any"&#125; (current: &#123;"os":"win32","arch":"x64"&#125;)+ hexo@3.3.8added 122 packages and updated 9 packages in 40.962s ps:虽然版本号没变，但是起码解决了问题，ok，又可以愉快玩耍了（警告什么的都不是事）。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下如何修改用户默认目录]]></title>
    <url>%2Flinux_user_default_path.html</url>
    <content type="text"><![CDATA[提出问题 在ftp服务器中，ftp登陆的用户只能在自己的文件夹下活动，现在我需要改这个用户的所属文件位置。 解决 使用root用户，执行命令 12345678910111213141516171819202122232425262728293031[root@localhost ~]# cat /etc/passwdroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/syncshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltmail:x:8:12:mail:/var/spool/mail:/sbin/nologinoperator:x:11:0:operator:/root:/sbin/nologingames:x:12:100:games:/usr/games:/sbin/nologinftp:x:14:50:FTP User:/var/ftp:/sbin/nologinnobody:x:99:99:Nobody:/:/sbin/nologinsystemd-bus-proxy:x:999:997:systemd Bus Proxy:/:/sbin/nologinsystemd-network:x:192:192:systemd Network Management:/:/sbin/nologindbus:x:81:81:System message bus:/:/sbin/nologinpolkitd:x:998:996:User for polkitd:/:/sbin/nologintss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologinpostfix:x:89:89::/var/spool/postfix:/sbin/nologinsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologinkaim:x:1000:1000:kaim:/home/kaim:/bin/bashuser1:x:1001:1001::/home/user1:/bin/bashrpc:x:32:32:Rpcbind Daemon:/var/lib/rpcbind:/sbin/nologinrpcuser:x:29:29:RPC Service User:/var/lib/nfs:/sbin/nologinnfsnobody:x:65534:65534:Anonymous NFS User:/var/lib/nfs:/sbin/nologintest2:x:1002:50::/opt/test_ftp:/sbin/nologintest1:x:1003:50::/opt/test_ftp:/sbin/nologintest3:x:1004:50::/opt/test_ftp:/sbin/nologintest4:x:1005:50::/opt/test_ftp:/sbin/nologintest5:x:1006:50::/opt/test5_ftp:/sbin/nologin 直接修改目录名保存就可以，记得分配权限。 附：添加，修改用户参数12345678/usr/sbin/adduser -d /opt/test_ftp -g ftp -s /sbin/nologin test2上面的命令是添加一个 名称为 test2的用户。命令解析：使用命令(adduser)添加test2用户,不能登录系统(-s /sbin/nologin),自己的文件夹在(-d /opt/test_ftp)),属于组ftp(-g ftp).usermod -s /sbin/nologin test //限定用户test不能telnetusermod -s /sbin/bash test //用户test恢复正常usermod -d /test test //更改用户test的主目录为/test]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux上搭建ftp服务器]]></title>
    <url>%2Fvsftpd.html</url>
    <content type="text"><![CDATA[摘要 vsftpd 是“very secure FTP daemon”的缩写，安全性是它的一个最大的特点。vsftpd 是一个 UNIX 类操作系统上运行的服务器的名字，它可以运行在诸如 Linux、BSD、Solaris、 HP-UNIX等系统上面，是一个完全免费的、开放源代码的ftp服务器软件，支持很多其他的 FTP 服务器所不支持的特征。比如：非常高的安全性需求、带宽限制、良好的可伸缩性、可创建虚拟用户、支持IPv6、速率高等。 vsftpd是一款在Linux发行版中最受推崇的FTP服务器程序。特点是小巧轻快，安全易用。（来自百度百科） 安装vsftpd检测是否已经安装vsftpd。12[root@localhost ~]# rpm -qa | grep vsftpd[root@localhost ~]# 什么都不显示就没有安装 安装vsftpd使用yum安装1[root@localhost ~]# yum -y install vsftpd 使用rpm安装1[root@localhost local]# rpm -ivh vsftpd-3.0.2-21.el7.x86_64.rpm 启动服务12[root@localhost local]# service vsftpd startRedirecting to /bin/systemctl start vsftpd.service 查看服务状态12345678910111213[root@localhost local]# service vsftpd statusRedirecting to /bin/systemctl status vsftpd.service● vsftpd.service - Vsftpd ftp daemon Loaded: loaded (/usr/lib/systemd/system/vsftpd.service; disabled; vendor preset: disabled) Active: active (running) since 三 2017-08-30 15:28:18 CST; 15min ago Process: 4295 ExecStart=/usr/sbin/vsftpd /etc/vsftpd/vsftpd.conf (code=exited, status=0/SUCCESS) Main PID: 4296 (vsftpd) CGroup: /system.slice/vsftpd.service └─4296 /usr/sbin/vsftpd /etc/vsftpd/vsftpd.conf8月 30 15:28:18 localhost.localdomain systemd[1]: Starting Vsftpd ftp daemon...8月 30 15:28:18 localhost.localdomain systemd[1]: Started Vsftpd ftp daemon.Hint: Some lines were ellipsized, use -l to show in full. Active: active (running) 启动状态，可以使用 现在我们就可以匿名访问了vsftpd添加用户vsftpd添加用户FTP用户一般是不能登录系统的,只能进入FTP服务器自己的目录中,这是为了安全.这样的用户就叫做虚拟用户了.实际上并不是真正的虚拟用户,只是不能登录SHELL了而已,没能力登录系统. 添加用户命令1/usr/sbin/adduser -d /opt/test_ftp -g ftp -s /sbin/nologin test2 上面的命令是添加一个 名称为 test2的用户。 命令解析：使用命令(adduser)添加test2用户,不能登录系统(-s /sbin/nologin),自己的文件夹在(-d /opt/test_ftp)),属于组ftp(-g ftp). 为该用户设置密码1[root@localhost local]# passwd test2 现在重启服务我们就可以使用test2直接访问我们的 /opttest_ftp目录了 给用户权限上传下载，修改虽然用户能够进行查看，但是还没有权限上传、下载和修改 授权1[root@localhost local]# chmod 755 /opt/test_ftp 编辑配置文件一般创建一个ftp 用户，作为管理员只希望它只能访问其自己的所属目录的，是不会让他选择其他目录的。 ####设置ftp用户的权限 在安装好ftp时，在 /etc/vsftpd目录下可以看到vsftpd的配置文件vsftpd.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135[root@localhost vsftpd]# vim vsftpd.conf # Example config file /etc/vsftpd/vsftpd.conf## The default compiled in settings are fairly paranoid. This sample file# loosens things up a bit, to make the ftp daemon more usable.# Please see vsftpd.conf.5 for all compiled in defaults.## READ THIS: This example file is NOT an exhaustive list of vsftpd options.# Please read the vsftpd.conf.5 manual page to get a full idea of vsftpd's# capabilities.## Allow anonymous FTP? (Beware - allowed by default if you comment this out).anonymous_enable=YES## Uncomment this to allow local users to log in.# When SELinux is enforcing check for SE bool ftp_home_dirlocal_enable=YES## Uncomment this to enable any form of FTP write command.write_enable=YES## Default umask for local users is 077. You may wish to change this to 022,# if your users expect that (022 is used by most other ftpd's)local_umask=022## Uncomment this to allow the anonymous FTP user to upload files. This only# has an effect if the above global write enable is activated. Also, you will# obviously need to create a directory writable by the FTP user.# When SELinux is enforcing check for SE bool allow_ftpd_anon_write, allow_ftpd_full_accessanon_upload_enable=YES## Uncomment this if you want the anonymous FTP user to be able to create# new directories.anon_mkdir_write_enable=YES## Activate directory messages - messages given to remote users when they# go into a certain directory.dirmessage_enable=YES## Activate logging of uploads/downloads.xferlog_enable=YES## Make sure PORT transfer connections originate from port 20 (ftp-data).connect_from_port_20=YES## If you want, you can arrange for uploaded anonymous files to be owned by# a different user. Note! Using "root" for uploaded files is not# recommended!#chown_uploads=YES#chown_username=whoever## You may override where the log file goes if you like. The default is shown# below.#xferlog_file=/var/log/xferlog## If you want, you can have your log file in standard ftpd xferlog format.# Note that the default log file location is /var/log/xferlog in this case.xferlog_std_format=YES## You may change the default value for timing out an idle session.idle_session_timeout=600## You may change the default value for timing out a data connection.data_connection_timeout=120## It is recommended that you define on your system a unique user which the# ftp server can use as a totally isolated and unprivileged user.#nopriv_user=ftpsecure## Enable this and the server will recognise asynchronous ABOR requests. Not# recommended for security (the code is non-trivial). Not enabling it,# however, may confuse older FTP clients.#async_abor_enable=YES## By default the server will pretend to allow ASCII mode but in fact ignore# the request. Turn on the below options to have the server actually do ASCII# mangling on files when in ASCII mode.# Beware that on some FTP servers, ASCII support allows a denial of service# attack (DoS) via the command "SIZE /big/file" in ASCII mode. vsftpd# predicted this attack and has always been safe, reporting the size of the# raw file.# ASCII mangling is a horrible feature of the protocol.ascii_upload_enable=YESascii_download_enable=YES## You may fully customise the login banner string:ftpd_banner=Welcome to blah FTP service.## You may specify a file of disallowed anonymous e-mail addresses. Apparently# useful for combatting certain DoS attacks.#deny_email_enable=YES# (default follows)#banned_email_file=/etc/vsftpd/banned_emails## You may specify an explicit list of local users to chroot() to their home# directory. If chroot_local_user is YES, then this list becomes a list of# users to NOT chroot().# (Warning! chroot'ing can be very dangerous. If using chroot, make sure that# the user does not have write access to the top level directory within the# chroot)chroot_local_user=YESchroot_list_enable=YES# (default follows)chroot_list_file=/etc/vsftpd/chroot_list# vsftpd：500 OOPS: vsftpd: refusing to run with writable root inside chroot ()错误的解决方法allow_writeable_chroot=YES ## You may activate the "-R" option to the builtin ls. This is disabled by# default to avoid remote users being able to cause excessive I/O on large# sites. However, some broken FTP clients such as "ncftp" and "mirror" assume# the presence of the "-R" option, so there is a strong case for enabling it.#ls_recurse_enable=YES# When "listen" directive is enabled, vsftpd runs in standalone mode and▽ listens on IPv4 sockets. This directive cannot be used in conjunction# with the listen_ipv6 directive.listen=YES## This directive enables listening on IPv6 sockets. By default, listening# on the IPv6 "any" address (::) will accept connections from both IPv6# and IPv4 clients. It is not necessary to listen on *both* IPv4 and IPv6# sockets. If you want that (perhaps because you want to listen on specific# addresses) then you must run two copies of vsftpd with two configuration# files.# Make sure, that one of the listen options is commented !!# listen_ipv6=YESpam_service_name=vsftpduserlist_enable=YEStcp_wrappers=YESanon_other_write_enable=YES#anon_root=/opt/test_ftp#guest_enable=YES#guest_username=test2virtual_use_local_privs=YES 用户访问权限及路径限制： 如果 userlist_deny=NO：只允许userlist_file文件中的用户可访问ftp；如果 userlist_deny=YES：userlist_file文件中列举的用户不能通过ftp访问系统。userlist_enable是该功能的开关。我们的系统配置如下：123userlist_enable=YESuserlist_deny=NOuserlist_file=/etc/vsftpd/user_list 把需要登录的用户加入到/etc/vsftpd/user_list文件中，一个用户一行。如果我们不需要把登陆的用户限制在主目录下需要一下配置：进入主配置文件中chroot_list_enable=YES创建用户文件/etc/vsftpd/chroot_list1vim /etc/vsftpd/chroot_list 将不需要限制的用户添加进去，我们只有一个test2，一行一个用户名ps: 这些用户将能访问全部有权限的文件。 设置权限12345678910111213[root@localhost vsftpd]# getsebool -a|grep ftpftpd_anon_write --&gt; offftpd_connect_all_unreserved --&gt; off pd_connect_db --&gt; off▽tpd_full_access --&gt; offftpd_use_cifs --&gt; offftpd_use_fusefs --&gt; offftpd_use_nfs --&gt; offftpd_use_passive_mode --&gt; offhttpd_can_connect_ftp --&gt; offhttpd_enable_ftp_server --&gt; offtftp_anon_write --&gt; offtftp_home_dir --&gt; off 开启 anon_write 和full_access12[root@localhost vsftpd]# setsebool allow_ftpd_anon_write 1[root@localhost vsftpd]# setsebool allow_ftpd_full_access 1 重启ftp服务1[root@localhost vsftpd]# service vsftpd restart 测试 注：测试连接软件是FileZilla，windows访问 ftp://[ip] update 20170901 使用FileZilla创建中文文件夹Linux乱码首先出现这个问题的原因是WINDOWS采用的是GBK编码方式，而Linux采用的是UTF-8首先设置好FileZilla的编码方式为zh_CN在将 /etc/locale.conf 中的LANG修改为&quot;zh_CN.UTF-8&quot;12[root@localhost ~]# vim /etc/locale.conf LANG="zh_CN.UTF-8" 这个修改可以有效解决windows客户端使用ftp协议上传中文文件到Linux乱码的问题。其实最根本的解决方法是客户端上传的文件经过ftp软件能与服务器统一编码方式，具体百度吧c#、java的都有。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 静态IP设置]]></title>
    <url>%2Fsetting_static_ip.html</url>
    <content type="text"><![CDATA[最近使用linux做服务器共享，需要设置静态IP，整理了一下。 获取网卡信息在root用户下，输入命令ifconfig123456789101112131415161718[root@localhost ~]# ifconfigens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.19.128 netmask 255.255.255.0 broadcast 192.168.19.255 inet6 fe80::2938:ef28:162e:9ffd prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:93:06:e9 txqueuelen 1000 (Ethernet) RX packets 77 bytes 7911 (7.7 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 67 bytes 11943 (11.6 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 1 (Local Loopback) RX packets 127 bytes 9199 (8.9 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 127 bytes 9199 (8.9 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 更改配置信息从上面可以看到我的网卡号是ens33123456789101112131415161718192021[root@localhost ~]# vim /etc/sysconfig/network-scripts/ifcfg-ens33 TYPE="Ethernet"BOOTPROTO="static"IPADDR=192.168.19.128NETMASK=255.255.255.0GATEWAY=192.168.19.1DEFROUTE="yes"PEERDNS="yes"PEERROUTES="yes"IPV4_FAILURE_FATAL="no"IPV6INIT="yes"IPV6_AUTOCONF="yes"IPV6_DEFROUTE="yes"IPV6_PEERDNS="yes"IPV6_PEERROUTES="yes"IPV6_FAILURE_FATAL="no"IPV6_ADDR_GEN_MODE="stable-privacy"NAME="ens33"UUID="f9e34fd2-c12f-4d4c-ad93-37d0b9cc43ce"DEVICE="ens33"ONBOOT="yes" BOOTPROTO代表的是获取ip方式（“dhcp”＝动态获取／“static”＝设置静态ip） IPADDR代表静态ip地址 （地址就用之前ifconfig获取的inet 192.168.19.128） NETMASK代表子网掩码（地址就用之前ifconfig获取的netmask 255.255.255.0） GATEWAY代表网关（由于你的ip是192.168.58网段的，所以使用192.168.19.1，注意：你是ip地址前三位是什么网段就在后面加个1就行了） DNS1就是dns了（需要你知道你的网络的dns，一般在路由器管理后台有配置，可以不设置dns）最后重启下网络服务注意，fail是有问题的配置12[root@localhost ~]# service network restart Restarting network (via systemctl): [ OK ]]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SAMBA共享]]></title>
    <url>%2Fsamba.html</url>
    <content type="text"><![CDATA[简介 Samba是在Linux和UNIX系统上实现SMB协议的一个免费软件，由服务器及客户端程序构成。SMB（Server Messages Block，信息服务块）是一种在局域网上共享文件和打印机的一种通信协议，它为局域网内的不同计算机之间提供文件及打印机等资源的共享服务。 SMB协议是客户机/服务器型协议，客户机通过该协议可以访问服务器上的共享文件系统、打印机及其他资源。通过设置NetBIOS over TCP/IP使得Samba不但能与局域网络主机分享资源，还能与全世界的电脑分享资源。 安装samba 可以先检查下是否已经安装：rpm -qa | grep samba这里使用yum安装，可以不用担心一些依赖包的问题：yum install samba 创建共享文件夹，这里就是mkdir -m 777 /home/user1/share 修改/etc/samba/smb.conf，这里面的参数就比较多，主要是workgroup = WORKGROUP（这个就是windows工作组模式，还有一种是域模式，可以不改使用MYGROUP）hosts allow = 192.168.19.207（可以放问的IP地址，这里写的时windows地址，一般不填写）然后在文件的结尾加上[public]（共享名，就是windows访问时会显示的名称）comment = Public Stuff（注释）path = /home/user1/share（共享名）public = yes（公开）writable = yes（可写）当然这里只是些基础的参数，还有其他的参数根据情况设置，比如会出现乱码，还要指定编码格式。 重启smb服务：service smb restart、 service smb status 查看状态 创建samba客户：smbpasswd -a user1,回车后会提示输入密码。这个就是将来远程主机登录时需要的密码，这里的user1帐号必须是系统已经有的帐号，没有的话会报错，然后新输的密码就是远程登录密码，这样做的好处就是自己的密码和远程登录的密码分开。 windows下连接，启动运行，输入\\192.168.19.185,输入smb帐号密码就可以了 由于暂时还不会防火墙和SELINUX配置，而下面有些方法中的操作会受到他们的限制，因此先关闭这俩。关闭防火墙的命令：service iptables stop关闭SELINUX命令：setenforce 0 window下关闭网络共享连接 cmd &gt;&gt;net use * /del /y 如果访问的是当前用户下的文件，不需要配置 如果访问的不是当前用户下的文件或者文件夹，需要配置/etc/samba/smb.conf，加入： [Share] 为在共享中显示的文件夹名123456789101112131415[Share]comment = Shared Folder with username and passwordpath = /datapublic = yeswritable = yesvalid users = user1available = yesbrowseable = yes 启动 samba 服务systemctl start smb.service 测试服务我使用的是windows客户端连接，输入Ip \\192.168.19.185我使用的是user1账户 账户有权限可以正常进入到文件中]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven使用tomcat7-maven-plugin插件run时出现错误： A child container failed during start]]></title>
    <url>%2Fmaven-plugins-error.html</url>
    <content type="text"><![CDATA[eclipse上使用maven项目总是会爆各种奇怪的错误，看不懂哇看不懂。这次又出现A child container failed during start… 环境: maven - 3.3.9 jdk1.8.0_144 eclipse - 4.6 os - win10-1703 出现错误：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778严重: A child container failed during startjava.util.concurrent.ExecutionException: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat].StandardHost[localhost].StandardContext[]] at java.util.concurrent.FutureTask.report(FutureTask.java:122) at java.util.concurrent.FutureTask.get(FutureTask.java:192) at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:1123) at org.apache.catalina.core.StandardHost.startInternal(StandardHost.java:800) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1559) at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1549) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat].StandardHost[localhost].StandardContext[]] at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154) ... 6 moreCaused by: java.lang.ClassCastException: org.springframework.web.SpringServletContainerInitializer cannot be cast to javax.servlet.ServletContainerInitializer at org.apache.catalina.startup.ContextConfig.getServletContainerInitializer(ContextConfig.java:1661) at org.apache.catalina.startup.ContextConfig.processServletContainerInitializers(ContextConfig.java:1569) at org.apache.catalina.startup.ContextConfig.webConfig(ContextConfig.java:1277) at org.apache.catalina.startup.ContextConfig.configureStart(ContextConfig.java:878) at org.apache.catalina.startup.ContextConfig.lifecycleEvent(ContextConfig.java:369) at org.apache.catalina.util.LifecycleSupport.fireLifecycleEvent(LifecycleSupport.java:119) at org.apache.catalina.util.LifecycleBase.fireLifecycleEvent(LifecycleBase.java:90) at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5179) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) ... 6 more八月 24, 2017 5:26:11 下午 org.apache.catalina.core.ContainerBase startInternal严重: A child container failed during startjava.util.concurrent.ExecutionException: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat].StandardHost[localhost]] at java.util.concurrent.FutureTask.report(FutureTask.java:122) at java.util.concurrent.FutureTask.get(FutureTask.java:192) at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:1123) at org.apache.catalina.core.StandardEngine.startInternal(StandardEngine.java:302) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) at org.apache.catalina.core.StandardService.startInternal(StandardService.java:443) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) at org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:732) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) at org.apache.catalina.startup.Tomcat.start(Tomcat.java:335) at org.apache.tomcat.maven.plugin.tomcat7.run.AbstractRunMojo.startContainer(AbstractRunMojo.java:1091) at org.apache.tomcat.maven.plugin.tomcat7.run.AbstractRunMojo.execute(AbstractRunMojo.java:512) at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:134) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:207) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153) at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145) at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116) at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80) at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51) at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128) at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:307) at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:193) at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:106) at org.apache.maven.cli.MavenCli.execute(MavenCli.java:863) at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:288) at org.apache.maven.cli.MavenCli.main(MavenCli.java:199) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289) at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229) at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415) at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)Caused by: org.apache.catalina.LifecycleException: Failed to start component [StandardEngine[Tomcat].StandardHost[localhost]] at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:154) at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1559) at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1549) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748)Caused by: org.apache.catalina.LifecycleException: A child container failed during start at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:1131) at org.apache.catalina.core.StandardHost.startInternal(StandardHost.java:800) at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150) ... 6 more 尝试解决的方法： 更换maven 至最新版本 - 结果：无效 网上搜索都说web版本太高 2.5 ,2.4都没效果 注意问题所在org.springframework.web.SpringServletContainerInitializer cannot be cast to javax.servlet.ServletContainerInitializer 这句话上，根本上就是jar包有问题。首先在项目排除这个javax.servlet-api包，可以运行成功; 1234567&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;!-- 加上这句，作用域改成编译时使用，而打包时不使用 --&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;version&gt;3.1.0&lt;/version&gt;&lt;/dependency&gt; 但是也有可能jdk的问题，有人说是Jdk中毒了，我看到这个回答感觉自己中毒了 doge.jpg。 感觉使用idea怎么没出错，嗯~，就是坑你，没商量~。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于辞职]]></title>
    <url>%2Ffirst-quit-job.html</url>
    <content type="text"><![CDATA[今天总算是把工作交接完了，又要开始一段新的职业生涯了。 记得是去年11月25号入职金拓维，当时面试我的还记得是友爱的周总，在金拓维很长的实习生活中，公司氛围很好，哈哈，第一位项目经理是光哥，当然，我现在跳槽也是来到光哥手下干事的，又回来了。 来公司认识第一位员工应该是我们的秦~，现在是我的室友，比我早来一天。 后来一位大学同学也来了，感觉这个世界真的小，工作的时候还有大学同学一起，还是很知足的，是不是。 后来还有饶~~，等等一些同事，真的庆幸遇到这些兄弟们，让工作历程，变得不再孤单。 即使目前跳槽了，也还在附近，仍然一起的。That`s ok! 具体跳槽原因，可能是我这个人不太安分吧，在这个公司刚签合同一个多月，就跑了，我也很窘迫的，鼓起勇气去辞职的，经理也谈了一堆道理，balabala,省略。。。 去了初创公司，可能会很累，但是为了梦想，总得向前迈出一小步。虽然最近发生的事情有点多，人也有点沉沦，但是不失本心，我想只会越来越好的。 也希望大家都能越来越好！ 真的很晚了，今晚又要失眠了。 对自己说声，晚安！]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>辞职</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中位运算符]]></title>
    <url>%2FJAVA_Bitwise_Operators.html</url>
    <content type="text"><![CDATA[1、 今天在读ConcurrentHashMap的源码中突然发现一段很好玩的代码，大概理解它的意思。不多说上代码：12345678910111213/** * Returns a power of two table size for the given desired capacity. * See Hackers Delight, sec 3.2 */private static final int tableSizeFor(int c) &#123; int n = c - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 在 ConcurrentHashMap 源码的第688~700 line 疑问 见过&gt;&gt;、&lt;&lt;的位运算符，但没见过&gt;&gt;&gt;估计意思差不多； |=运算符，目测是或； 不知道写段代码测试吧 123456789101112131415public static void main(String[] args) &#123; System.out.println("15的二进制数是 "+ Integer.toBinaryString(15)); System.out.println("-15的二进制数是 "+ Integer.toBinaryString(-15)); System.out.println("15 &gt;&gt; 2 的运算结果是 " + (15 &gt;&gt; 2)); System.out.println("15 &lt;&lt; 2 的运算结果是 " + (15 &lt;&lt; 2)); System.out.println("15 &gt;&gt;&gt; 2 的运算结果是 " + (15 &gt;&gt;&gt; 2)); //遗憾的是没有&lt;&lt;&lt;运算符,我的jdk是jdk1.8.0_144 //System.out.println(15 &lt;&lt;&lt; 2); System.out.println("-15 &gt;&gt; 2 的运算结果是 " + (-15 &gt;&gt; 2)); System.out.println("-15 &lt;&lt; 2 的运算结果是 " + (-15 &lt;&lt; 2)); System.out.println("-15 &gt;&gt;&gt; 2 的运算结果是 " + (-15 &gt;&gt;&gt; 2)); int index = 8; System.out.println(index + " | 15 &gt;&gt;&gt; 2的运算结果是 " + (index | 15 &gt;&gt;&gt; 2)); System.out.println(index + " |= 15 &gt;&gt;&gt; 2 的运算结果是 " + (index |= 15 &gt;&gt;&gt; 2)); &#125; 运行结果 1234567891015的二进制数是 1111-15的二进制数是 1111111111111111111111111111000115 &gt;&gt; 2 的运算结果是 315 &lt;&lt; 2 的运算结果是 6015 &gt;&gt;&gt; 2 的运算结果是 3-15 &gt;&gt; 2 的运算结果是 -4-15 &lt;&lt; 2 的运算结果是 -60-15 &gt;&gt;&gt; 2 的运算结果是 10737418208 | 3的运算结果是 118 |= 15 &gt;&gt;&gt; 2 的运算结果是 11 分析 15 &gt;&gt; 215 的 二 进 制 表 示 00000000 00000000 00000000 00001111 正数补码反码都一样得 -15的补码表示 11111111 11111111 11111111 11110001将 15右移2位 00000000 00000000 00000000 00000011 得3 -15 &gt;&gt; 2将-15右移2位 11111111 11111111 11111111 11111100在高位补1保留符号位，然后按位取反10000000 00000000 00000000 00000011然后加1，即为所求数的原码：10000000 00000000 00000000 00000100所以 -15&gt;&gt;2 右移两位结果是 -4 &gt;&gt;&gt; 符号结果是无符号规则右移 主要区别是在负数上面-15的二进制表示 11111111 11111111 11111111 11110001将-15右移2位， 在高位补0， 00111111 11111111 11111111 11111100所得结果 1073741820 从上面的结果可以看出 8|=15就是 8|15 就是或运算符，唯一的区别的就是temp = temp | temp1 等于 temp |= temp1，重新复习下与或非运算符： 与运算符用符号“&amp;”表示，其使用规律如下：两个操作数中位都为1，结果才为1，否则结果为0， 或运算符用符号“|”表示，其运算规律如下：两个位只要有一个为1，那么结果就是1，否则就为0， 非运算符用符号“~”表示，其运算规律如下：如果位为0，结果是1，如果位为1，结果是0， 异或运算是用符号“^”表示的，其运算规律是：两个操作数的位中，相同则结果为0，不同则结果为1。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[提升生活质量的日常方法]]></title>
    <url>%2Fimprove-lives-quality.html</url>
    <content type="text"><![CDATA[提升生活质量的日常方法大方面那些什么学习、坚定梦想、诚恳、谦虚，进入大的圈子等等太大，在此记录下生活细节需要提升的。 每天整理桌子// 坚持啊，桌子每次都乱 ， 至少每周要彻底打扫次卫生// 反正我要赤脚 床单、被子每个月最好洗一次，晒一次// 作为个工科男，最不爱做的卫生就是这个了 恍惚恍惚 (逃://1708 没办到 理发，一个月一次// 哈哈，我的头发生长旺盛，一般一个月 坚持锻炼// 好的身体才能做其他的事情，最最重要的。。。 出门最好带个伞// 结果回来伞就没了 。。。 多读点书，多学习// 虽然经常去图书馆，但是读书不是我的目的啊，超难。。。 但是不得不说读书是有好处的，这个没有终点，需要保持才行，像我们这种IT男，好难坚持做这个，忙的要死。。。 // 学习是必须的，加油。 gdvl 唱歌// mmp，像我这种五音不全得是不是没救了 // 没打游戏了，可以练习下，有大神走过来，可以教我啊啊啊，请加我，联系，万分感谢。。 做菜// 大部分时候被大厨室友承包了， // 感觉男同袍做菜，貌似只看能不能吃，哈哈 ，逃，不要打我我 // 是的要做得好点才行，不然就一尘不变了，没意义。。 少打游戏// 戒了，戒了，不要跟我谈游戏了。。 不然我会跟一直谈下去的。。。 // 不知道以前那么多年，怎么这么大的瘾在打游戏上面，现在，失去的太多，不知道我还能不能追回来。。加油boy… 关于洗碗机// 好东西啊啊，可惜现在好贵 最便宜也要3000大洋，要赚钱了 每天一个苹果吧// 今年牙齿上做了手术，估计好长段时间不能吃啊，口水.jpg，// 说到苹果，是不要个削苹果的，到时候淘宝吧。 欢迎有人给我提意见，万分感谢！！！ (To Be Continue:]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fastDFS与java整合文件上传下载]]></title>
    <url>%2Ffsds-java.html</url>
    <content type="text"><![CDATA[准备 下载fastdfs-client-java源码 源码地址 密码：s3sw 修改pom.xml第一个plugins是必需要的，是maven用来编译的插件，第二个是maven打源码包的，可以不要。 123456789101112131415161718192021222324252627&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.5.1&lt;/version&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;source&gt;$&#123;jdk.version&#125;&lt;/source&gt; &lt;target&gt;$&#123;jdk.version&#125;&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 将 fastdfs-client-java 打包直接项目右键，run as maven installinstall成功后，fastdfs-client-java就成功的被安装到本地仓库了。 编写工具类： 把fdfs_client.conf文件复制一份放到自己项目的resource下面;修改里面的tracker.server,其它的都不用动： 在项目的pom.xml中添加依赖12345&lt;dependency&gt; &lt;groupId&gt;org.csource&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client-java&lt;/artifactId&gt; &lt;version&gt;1.27-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 首先来实现文件上传，fastdfs-client-java的上传是通过传入一个byte[ ]来完成的，简单看一下源码：12345public String[] upload_file(byte[] file_buff, String file_ext_name, NameValuePair[] meta_list) throws IOException, MyException&#123; final String group_name = null; return this.upload_file(group_name, file_buff, 0, file_buff.length, file_ext_name, meta_list);&#125; 文件属性12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.wuwii.utils;import java.io.Serializable;import java.util.Arrays;/** * @ClassName FastDFSFile * @Description FastDFS上传文件业务对象 * @author zhangkai * @date 2017年7月18日 */public class FastDFSFile implements Serializable&#123; private static final long serialVersionUID = 2637755431406080379L; /** * 文件二进制 */ private byte[] content; /** * 文件名称 */ private String name; /** * 文件长度 */ private Long size; public FastDFSFile()&#123; &#125; public FastDFSFile(byte[] content, String name, Long size)&#123; this.content = content; this.name = name; this.size = size; &#125; public byte[] getContent() &#123; return content; &#125; public void setContent(byte[] content) &#123; this.content = content; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Long getSize() &#123; return size; &#125; public void setSize(Long size) &#123; this.size = size; &#125; public static long getSerialversionuid() &#123; return serialVersionUID; &#125;&#125; 编写FastDFS工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109package com.wuwii.utils;import java.io.Serializable;import org.apache.commons.io.FilenameUtils;import org.csource.common.NameValuePair;import org.csource.fastdfs.ClientGlobal;import org.csource.fastdfs.StorageClient1;import org.csource.fastdfs.TrackerClient;import org.csource.fastdfs.TrackerServer;import org.jetbrains.annotations.NotNull;import org.springframework.core.io.ClassPathResource;import org.springframework.http.HttpHeaders;import org.springframework.http.HttpStatus;import org.springframework.http.MediaType;import org.springframework.http.ResponseEntity;/** * @ClassName FastDFSUtils * @Description FastDFS工具类 * @author zhangkai * @date 2017年7月18日 */public class FastDFSUtils implements Serializable&#123; /** * */ private static final long serialVersionUID = -4462272673174266738L; private static TrackerClient trackerClient; private static TrackerServer trackerServer; private static StorageClient1 storageClient1; static &#123; try &#123; //clientGloble读配置文件 ClassPathResource resource = new ClassPathResource("fdfs_client.conf"); ClientGlobal.init(resource.getClassLoader().getResource("fdfs_client.conf").getPath()); //trackerclient trackerClient = new TrackerClient(); trackerServer = trackerClient.getConnection(); //storageclient storageClient1 = new StorageClient1(trackerServer,null); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * fastDFS文件上传 * @param file 上传的文件 FastDFSFile * @return String 返回文件的绝对路径 */ public static String uploadFile(FastDFSFile file)&#123; String path = null; try &#123; //文件扩展名 String ext = FilenameUtils.getExtension(file.getName()); //mata list是表文件的描述 NameValuePair[] mata_list = new NameValuePair[3]; mata_list[0] = new NameValuePair("fileName",file.getName()); mata_list[1] = new NameValuePair("fileExt",ext); mata_list[2] = new NameValuePair("fileSize",String.valueOf(file.getSize())); path = storageClient1.upload_file1(file.getContent(), ext, mata_list); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return path; &#125; /** * fastDFS文件下载 * @param groupName 组名 * @param remoteFileName 文件名 * @param specFileName 真实文件名 * @return ResponseEntity&lt;byte[]&gt; */ @org.jetbrains.annotations.NotNull public static ResponseEntity&lt;byte[]&gt; downloadFile(String groupName, String remoteFileName, String specFileName)&#123; byte[] content = null; HttpHeaders headers = new HttpHeaders(); try &#123; content = storageClient1.download_file(groupName, remoteFileName); headers.setContentDispositionFormData("attachment", new String(specFileName.getBytes("UTF-8"),"iso-8859-1")); headers.setContentType(MediaType.APPLICATION_OCTET_STREAM); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return new ResponseEntity&lt;byte[]&gt;(content, headers, HttpStatus.CREATED); &#125; /** * 根据fastDFS返回的path得到文件的组名 * @param path fastDFS返回的path * @return */ public static String getGroupFormFilePath(String path)&#123; return path.split("/")[0]; &#125; /** * 根据fastDFS返回的path得到文件名 * @param path fastDFS返回的path * @return */ @NotNull public static String getFileNameFormFilePath(String path) &#123; return path.substring(path.indexOf("/")+1); &#125;&#125; 测试Controller123456789101112131415161718192021222324252627282930313233343536373839404142package com.wuwii.controller;import java.io.IOException;import org.springframework.http.ResponseEntity;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.multipart.MultipartFile;import com.wuwii.utils.FastDFSFile;import com.wuwii.utils.FastDFSUtils;import com.wuwii.utils.PropertyUtil;/** * FastFDS控制器 * @author zhangkai * */@Controller@RequestMapping(value = "/fastdfs")public class FastFDSController &#123; @RequestMapping(value = "/upload", method = RequestMethod.POST) public String upload (MultipartFile file)&#123; try &#123; FastDFSFile fastDFSFile = new FastDFSFile(file.getBytes(), file.getOriginalFilename(), file.getSize()); String path = FastDFSUtils.uploadFile(fastDFSFile); return "redirect:"+ PropertyUtil.get("fastFDS_server") + path; &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; return null; &#125; @RequestMapping(value = "/download") public ResponseEntity&lt;byte[]&gt; download (String path, String specFileName)&#123; String filename = FastDFSUtils.getFileNameFormFilePath(path); String group = FastDFSUtils.getGroupFormFilePath(path); return FastDFSUtils.downloadFile(group, filename, specFileName); &#125;&#125; 最后附上读取配置文件的工具类PropertyUtil1234567891011121314151617181920212223242526272829303132package com.wuwii.utils;import java.io.InputStream;import java.util.Properties;/** * @ClassName PropertyUtil * @Description 读取配置文件的内容（key，value） * @author zhangkai * @date 2017年7月18日 */public class PropertyUtil &#123; public static final Properties PROP = new Properties(); /** * @Method: get * @Description: 读取配置文件的内容（key，value） * @param key * @return String * @throws */ public static String get(String key) &#123; if (PROP.isEmpty()) &#123; try &#123; InputStream in = PropertyUtil.class.getResourceAsStream("/config.properties"); PROP.load(in); in.close(); &#125; catch (Exception e) &#123;&#125; &#125; return PROP.getProperty(key); &#125;&#125; 测试上传! 下载下载就很简单了，因为直接获得到二进制流了，返回给客户端即可。下载需要主要的是，要注意从FastDFS返回的文件名是这种随机码，因此我们需要在上传的时候将文件本身的名字存到数据库，再到下载的时候对文件头重新设置名字即可。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>fastDFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[念]]></title>
    <url>%2Ffetter-tears.html</url>
    <content type="text"><![CDATA[夜总是格外的静，月光就可以通过窗户观赏我这残酷的心情了。 想想过去，我有好几年都没跟你见过面，即使是聊天也是随意的说说，心中确实有写隔阂，没有以前那么天真，忧伤了。现在节奏太快了现在做事都是太认真了，总是考虑会不会有结果，渐渐的失去了一些目标，一些梦想，一些人。 事情总是那么凑巧，这个时候室友都封闭开发去，需要一个人，偌大的房间留个我一个人享受，想可以慢慢的在这里疗伤了，是的，下班后，比往常安静了，没以前在一起讲段子的欢声，骂做的菜真难吃，米是不是又没有煮·····现在只剩下我每天做一个菜，煮一碗米，一个人在吃饭，夜真是寂静的无聊，只有这个残酷的月光能在一旁陪伴。 真的想，一个人静静的吃饭。得不到可能就是最好的结果，毕竟这么长时间都没有联系过的人，早就应该消失的人，为什么还要在她幸福的时刻出现。 难以启齿，大道理真的没几个人能说的清楚，但是我还是清楚心中所想，只是心底还是存在那么一些执念，不愿意放下罢了，估计今生也没那么容易放下吧。 但是，人总是要往前走的，也不能一直活在这个回忆里去放弃，要努力前行。有可能时间不会让我忘记，只是削弱它的程度，它的悲伤吧。 曾经看到你的签名，想要制造羁绊，就必须要承担流泪的风险，我不太清楚你心中所想，也不懂你，这么多年了没见，每个人都发生了无数的可能。这句话我看出来，你是真的想找到爱情，而且已经可能找到了对的人了，成了一段绚丽多彩的美丽故事。 我可能是个执着的傻瓜，总是伤害到人，最终也伤害到自己了；我也是追求完美的人，都只去接触身边符合自己的人。所以总是这个患得患失的状态。我想上面这句话来形容我最好的了，选择来到了这个世界，就应该住在这里，与它融合，影响它，不必去选择什么对与错。可能会很痛，可能会是错误的道路，但那样生活就会不一样的精彩，不是吗？我希望不在抗拒这个世界带来的美好，也不去害怕去开辟新的人生。 你是唯一，我会记得，也有可能遗忘，但不会消失，一直都在；用心去看，才能看得真切，你是幸福的。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建fastDFS单实例服务器]]></title>
    <url>%2Fcentos-fastDFS.html</url>
    <content type="text"><![CDATA[简介 FastDFS是一个开源的轻量级分布式文件系统，它对文件进行管理，功能包括：文件存储、文件同步、文件访问（文件上传、文件下载）等，解决了大容量存储和负载均衡的问题。特别适合以文件为载体的在线服务，如相册网站、视频网站等等。 FastDFS为互联网量身定制，充分考虑了冗余备份、负载均衡、线性扩容等机制，并注重高可用、高性能等指标，使用FastDFS很容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。 FastDFS服务端有两个角色：跟踪器tracker和存储节点storage。跟踪器主要做调度工作，在访问上起负载均衡的作用。 安装并配置FastDFS运行环境及相关软件12345CentOS 7.0FastDFS_v5.08.tar.gznginx-1.8.1.tar.gzfastdfs-nginx-module_v1.16.tar.gzlibfastcommon 服务器规划 服务器名称 IP地址及端口 备注 fastdfs-tracker 192.168.114.128:22122 跟踪服务器/调度服务器 fastdfs-storage 192.168.114.128:23000 存储服务器 安装FastDFS首先创建工具目录（非必须）12[root@fastdfs-storage ~]# mkdir -p /home/oldcat/tools[root@fastdfs-storage ~]# cd /home/oldcat/tools/ 首先安装一些必须的的工具： libevent库文件： yum -y install libevent； 系统没有安装make、vim等常用命令: yum -y install gcc automake autoconf libtool make 下载并安装FastDFS依赖包libfastcommon1234567[root@fastdfs-storage tools]# wget https://codeload.github.com/happyfish100/libfastcommon/zip/master[root@fastdfs-storage tools]# unzip master[root@fastdfs-storage tools]# cd libfastcommon-master/[root@fastdfs-storage libfastcommon-master]# lsHISTORY INSTALL libfastcommon.spec make.sh php-fastcommon README src[root@fastdfs-storage libfastcommon-master]# ./make.sh[root@fastdfs-storage libfastcommon-master]# ./make.sh install 下载并安装FastDFS1234[root@fastdfs-tracker tools]# wget http://jaist.dl.sourceforge.net/project/fastdfs/FastDFS%20Server%20Source%20Code/FastDFS%20Server%20with%20PHP%20Extension%20Source%20Code%20V5.08/FastDFS_v5.08.tar.gz[root@fastdfs-tracker tools]# tar xf FastDFS_v5.08.tar.gz[root@fastdfs-tracker tools]# cd FastDFS[root@fastdfs-tracker FastDFS]# ./make.sh &amp;&amp; ./make.sh install 采用默认方式安装后的文件及目录：服务脚本：123[root@fastdfs-tracker ~]# ll /etc/init.d/ |grep fdfs-rwxr-xr-x. 1 root root 918 4月 22 22:08 fdfs_storaged-rwxr-xr-x. 1 root root 920 4月 22 22:08 fdfs_trackerd 样例配置文件12345[root@fastdfs-tracker ~]# ll /etc/fdfs/总用量 20-rw-r--r--. 1 root root 1461 4月 22 22:08 client.conf.sample-rw-r--r--. 1 root root 7927 4月 22 22:08 storage.conf.sample-rw-r--r--. 1 root root 7200 4月 22 22:08 tracker.conf.sample 命令行工具123456789101112131415[root@fastdfs-tracker ~]# ll /usr/bin|grep fdfs-rwxr-xr-x. 1 root root 252272 4月 22 22:08 fdfs_appender_test-rwxr-xr-x. 1 root root 252225 4月 22 22:08 fdfs_appender_test1-rwxr-xr-x. 1 root root 242449 4月 22 22:08 fdfs_append_file-rwxr-xr-x. 1 root root 242013 4月 22 22:08 fdfs_crc32-rwxr-xr-x. 1 root root 242508 4月 22 22:08 fdfs_delete_file-rwxr-xr-x. 1 root root 243627 4月 22 22:08 fdfs_download_file-rwxr-xr-x. 1 root root 243369 4月 22 22:08 fdfs_file_info-rwxr-xr-x. 1 root root 255657 4月 22 22:08 fdfs_monitor-rwxr-xr-x. 1 root root 863913 4月 22 22:08 fdfs_storaged-rwxr-xr-x. 1 root root 258712 4月 22 22:08 fdfs_test-rwxr-xr-x. 1 root root 257881 4月 22 22:08 fdfs_test1-rwxr-xr-x. 1 root root 365232 4月 22 22:08 fdfs_trackerd-rwxr-xr-x. 1 root root 243547 4月 22 22:08 fdfs_upload_appender-rwxr-xr-x. 1 root root 244453 4月 22 22:08 fdfs_upload_file 配置跟踪服务器（tracker server）拷贝tracker server和client端样例配置文件并重命名12[root@fastdfs-tracker ~]# cp /etc/fdfs/tracker.conf.sample /etc/fdfs/tracker.conf[root@fastdfs-storage ~]# cp /etc/fdfs/client.conf.sample /etc/fdfs/client.conf 编辑tracker server配置文件tracker.conf，需要修改内容如下：123disabled=false（默认为false，表示是否无效）port=22122（默认为22122）base_path=/data/fastdfs/tracker 编辑client端的配置文件client.conf，需要修改内容如下12base_path=/data/fastdfs/trackertracker_server=172.18.10.232:22122 创建tracker server数据目录1[root@fastdfs-tracker ~]# mkdir -p /data/fastdfs/tracker 测试启动tracker server，启动成功会自动在/data/fastdfs/tracker目录新建data和logs目录12345678[root@fastdfs-tracker ~]# cd /data/fastdfs/tracker/[root@fastdfs-tracker tracker]# ls[root@fastdfs-tracker tracker]# /etc/init.d/fdfs_trackerd startStarting FastDFS tracker server:[root@fastdfs-tracker tracker]# ss -lntup|grep 22122tcp LISTEN 0 128 *:22122 *:* users:(("fdfs_trackerd",3785,5)) [root@fastdfs-tracker tracker]# lsdata logs 关闭tracker server(目前可以不使用)123[root@fastdfs-tracker tracker]# /etc/init.d/fdfs_trackerd stopwaiting for pid [3785] exit ...pid [3785] exit. 配置存储服务器（storage server）拷贝storage server样例配置文件并重命名1[root@fastdfs-storage ~]# cp /etc/fdfs/storage.conf.sample /etc/fdfs/storage.conf 编辑storage server配置文件storage.conf，需要修改内容如下：123456disabled=false（默认为false，表示是否无效）port=23000（默认为23000）base_path=/data/fastdfs/storagetracker_server=172.18.10.232:22122store_path0=/data/fastdfs/storagehttp.server_port=8888（默认为8888，nginx中配置的监听端口那之一致） 创建storage server数据目录1[root@fastdfs-storage ~]# mkdir -p /data/fastdfs/storage 测试启动storage server，启动成功会自动在/data/fastdfs/tracker目录新建data和logs目录（启动storage server的前提是tracker server必须事先已启动）12345678[root@fastdfs-storage ~]# cd /data/fastdfs/storage/[root@fastdfs-storage storage]# ls[root@fastdfs-storage storage]# /etc/init.d/fdfs_storaged startStarting FastDFS storage server:[root@fastdfs-storage storage]# ss -lntup|grep 23000tcp LISTEN 0 128 *:23000 *:* users:(("fdfs_storaged",3786,5))[root@fastdfs-storage storage]# lsdata logs 验证storage是否登记到tracker服务器~ 使用/usr/bin/fdfs_monitor /etc/fdfs/storage.conf，运行fdfs_monitor查看storage服务器是否已经登记到tracker服务器。 如果出现ip_addr = Active, 则表明storage服务器已经登记到tracker服务器~ Storage 1: id = 192.168.0.1 ip_addr = 192.168.0.1 ==ACTIVE== 文件上传测试 执行如下上传命令：123[root@fastdfs-tracker ~]# /usr/bin/fdfs_upload_file /etc/fdfs/client.conf /etc/fdfs/client.confgroup1/M00/00/00/rBIK6VcaP0aARXXvAAHrUgHEviQ394.conf返回文件ID即说明文件已经上传成功 存储服务器（storage server）安装并配置nginx下载并安装fastdfs-nginx-module模块 FastDFS通过Tracker服务器,将文件放在Storage服务器存储，但是同组存储服务器之间需要进入文件复制，有同步延迟的问题。假设Tracker服务器将文件上传到了192.168.4.125，上传成功后文件ID已经返回给客户端。此时FastDFS存储集群机制会将这个文件同步到同组存储192.168.4.126，在文件还没有复制完成的情况下，客户端如果用这个文件ID在192.168.4.126上取文件,就会出现文件无法访问的错误。而fastdfs-nginx-module可以重定向文件连接到源服务器取文件,避免客户端由于复制延迟导致的文件无法访问错误。 123456[root@fastdfs-storage tools]# wget http://nchc.dl.sourceforge.net/project/fastdfs/FastDFS%20Nginx%20Module%20Source%20Code/fastdfs-nginx-module_v1.16.tar.gz[root@fastdfs-storage tools]# tar xf fastdfs-nginx-module_v1.16.tar.gz [root@fastdfs-storage tools]# cd fastdfs-nginx-module/src/[root@fastdfs-storage src]# vim config编辑config文件，执行如下命令进行批量替换并保存退出:%s+/usr/local/+/usr/+g 拷贝fastdfs-nginx-module模块中配置文件到/etc/fdfs目录中并编辑12345678910[root@fastdfs-storage ~]# cp /home/oldcat/tools/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs/[root@fastdfs-storage ~]# vim /etc/fdfs/mod_fastdfs.conf修改内容如下：connect_timeout=10base_path=/tmp（默认为/tmp）tracker_server=172.18.10.232:22122storage_server_port=23000（默认配置为23000）url_have_group_name = truestore_path0=/data/fastdfs/storagegroup_name=group1（默认配置为group1） 安装nginx依赖库（必须要检查）1[root@fastdfs-storage nginx-1.8.1]# yum install -y pcre-devel zlib-devel 下载并安装nginx12345[root@fastdfs-storage tools]# wget http://nginx.org/download/nginx-1.8.1.tar.gz[root@fastdfs-storage tools]# tar xf nginx-1.8.1.tar.gz [root@fastdfs-storage tools]# cd nginx-1.8.1[root@fastdfs-storage nginx-1.8.1]# ./configure --prefix=/application/nginx/ --add-module=../fastdfs-nginx-module/src/[root@fastdfs-storage nginx-1.8.1]# make &amp;&amp; make install 拷贝FastDFS中的部分配置文件到/etc/fdfs目录中12[root@fastdfs-storage ~]# cp /home/oldcat/tools/FastDFS/conf/http.conf /etc/fdfs/[root@fastdfs-storage ~]# cp /home/oldcat/tools/FastDFS/conf/mime.types /etc/fdfs/ 配置nginx，如下所示：12345678910111213141516171819202122232425262728[root@fastdfs-storage ~]# vim /application/nginx/conf/nginx.conf user root; worker_processes 1; events &#123; worker_connections 1024; &#125; http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 8888; server_name localhost; location / &#123; root html; index index.html index.htm; &#125; location ~/group[0-9]/M00 &#123; root /data/fastdfs/storage/data/; ngx_fastdfs_module; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125; &#125; 说明：a、user root是解决下载操作时报404的问题b、8888端口号与/etc/fdfs/storage.conf中的http.server_port=8888相对应c、storage对应有多个group的情况下，访问路径带group名称，例如：/group1/M00/00/00/**，对应nginx配置：123location ~/group[0-9]/ &#123; ngx_fastdfs_module; &#125; 创建M00至storage存储目录的符号连接：1ln -sv /data/fastdfs/storage/data /data/fastdfs/storage/data/M00 拷贝nginx服务到/etc/init.d/目录下并启动1234[root@fastdfs-storage ~]# cp /application/nginx/sbin/nginx /etc/init.d/[root@fastdfs-storage ~]# /etc/init.d/nginx[root@fastdfs-storage ~]# ss -lntup|grep 8888tcp LISTEN 0 128 *:8888 *:* users:(("nginx",7308,6),("nginx",7309,6)) 防火墙端口设置查看已开启的端口：123[root@localhost nginx-1.12.0]# firewall-cmd --zone=public --list-ports20880/tcp 80/tcp 2181/tcp 23000/tcp 22122/tcp 9999/tcp[root@localhost nginx-1.12.0]# 开放端口号命令：–permanent表示永久生效，不加的话，重启后不生效12sudo firewall-cmd --zone=public --add-port=23000/tcp --permanent #开户端口号sudo firewall-cmd --reload CentOS7 防火墙相关命令：123systemctl enable firewalld.service #开启防火墙systemctl stop firewalld.service #关闭防火墙(开机会仍会启动)systemctl disable firewalld.service #禁用防火墙(开机后不再启动) 添加开机自启首先检查 /etc/rc.d/rc.local 是否有执行权限1234ll /etc/rc.d/rc.local-rwxr--r-x. 1 root root 550 8月 18 10:58 /etc/rc.d/rc.localuser 有x有执行权限，没有则执行chmod u+x /etc/rc.d/rc.local 在 /etc/rc.d/rc.local 最底下加上服务器启动命令123/etc/init.d/fdfs_trackerd start /etc/init.d/fdfs_storaged start /etc/init.d/nginx 查看服务启动12345[root@localhost ~]# netstat -unltp|grep fdfstcp 0 0 0.0.0.0:22122 0.0.0.0:* LISTEN 1239/fdfs_trackerd tcp 0 0 0.0.0.0:23000 0.0.0.0:* LISTEN 1245/fdfs_storaged [root@localhost ~]# netstat -unltp|grep nginxtcp 0 0 0.0.0.0:8888 0.0.0.0:* LISTEN 1278/nginx: master]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>fastDFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何通过Maven的Jetty插件运行Web工程]]></title>
    <url>%2Fmaven-jetty.html</url>
    <content type="text"><![CDATA[Jetty 是一个开源的servlet容器，它为基于Java的web容器，例如JSP和servlet提供运行环境。Jetty是使用Java语言编写的，它的API以一组JAR包的形式发布。开发人员可以将Jetty容器实例化成一个对象，可以迅速为一些独立运行（stand-alone）的Java应用提供网络和web连接。 在pom.xml文件的标签中加入如下配置：123456789101112131415161718&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-maven-plugin&lt;/artifactId&gt; &lt;version&gt;9.4.4.v20170414&lt;/version&gt; &lt;configuration&gt; &lt;scanIntervalSeconds&gt;5&lt;/scanIntervalSeconds&gt; &lt;webApp&gt; &lt;contextPath&gt;/&lt;/contextPath&gt; &lt;/webApp&gt; &lt;connectors&gt; &lt;connector implementation="org.eclipse.jetty.server.nio.SelectChannelConnector"&gt; &lt;port&gt;80&lt;/port&gt; &lt;/connector&gt; &lt;/connectors&gt; &lt;/configuration&gt; &lt;/plugin&gt;&lt;/plugins&gt; 参数配置： configuration.scanIntervalSeconds 配置表示新代码的扫描时间间隔（秒），值 &lt;= 0 表示不扫描。这里利用的是jetty 的定时重载代码的特性，做修改后不用重新启动项目，自动扫描出改动后会自动更新class文件的。 configuration.webApp.contextPath 配置表示工程的虚拟目录名，如果配置为/，则届时访问路径为hostname:port/，如果配置为/jetty，则届时访问路径为hostname:port/jetty，有点相当于namespace的作用。 用Maven Build启动，需在Goals栏中配置如下： jetty:run 或者指定端口 jetty:run -Djetty.port=80 直接在项目根目录下在命令行中用maven命令启动: mvn jetty:run -Djetty.port=80 需要注意的是pom.xml文件中指定的端口优先级要比Goals中指定的端口的优先级要高]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>jetty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何通过Maven的Tomcat插件运行Web工程]]></title>
    <url>%2Fmaven-tomcat.html</url>
    <content type="text"><![CDATA[Tomcat 服务器是一个免费的开放源代码的Web 应用服务器，属于轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试JSP 程序的首选。对于一个初学者来说，可以这样认为，当在一台机器上配置好Apache 服务器，可利用它响应HTML（标准通用标记语言下的一个应用）页面的访问请求。实际上Tomcat是Apache 服务器的扩展，但运行时它是独立运行的，所以当你运行tomcat 时，它实际上作为一个与Apache 独立的进程单独运行的。 maven项目如何使用Tomcat插件运行项目，需要注意的是几个参数的设置，就可以灵活使用了。 maven version - 3.3.9 pom.xml的 build -&gt; plugins 标签下加上: 1234567891011 &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;path&gt;/&lt;/path&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;port&gt;80&lt;/port&gt; &lt;uriEncoding&gt;UTF-8&lt;/uriEncoding&gt; &lt;/configuration&gt;&lt;/plugin&gt; 最后是这样的： 123456789101112131415161718192021222324252627282930313233343536&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!-- 设置项目jdk --&gt; &lt;source&gt;$&#123;java-version&#125;&lt;/source&gt; &lt;target&gt;$&#123;java-version&#125;&lt;/target&gt; &lt;!-- true:跳过测试 --&gt; &lt;skip&gt;true&lt;/skip&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;configuration&gt; &lt;!-- 访问应用的路径 '/xxx' 就是使用 http://[hosthome]:[port]/xxx --&gt; &lt;path&gt;/&lt;/path&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;!-- 配置端口号 --&gt; &lt;port&gt;80&lt;/port&gt; &lt;uriEncoding&gt;UTF-8&lt;/uriEncoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 总结: maven build 启动方式 tomcat7:run maven-compiler-plugin 插件能解决 Dynamic Web Module 3.0 requires Java 1.6 or newer update maven 项目后的java版本不对的问题。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于QQ空间的一点事]]></title>
    <url>%2Fqzone.html</url>
    <content type="text"><![CDATA[以前玩QQ空间也好多年了，不知道什么时候淡下去了，也许人是人在也没有当年的纯真了吧，顾及也太多了，有时候翻出以前发的那些又矫情又作的东西，想想就很好笑吧，但是没删；说是淡了没玩了，我想也不是，还是每天会上去刷刷的，只是没有那些感觉了，重要的东西，由于一点原因，已经没在那上面写了，但是如果我看到喜欢的说说，我还是会点赞，评论的。关于一些点吧： 首先就是匿名访问这一点吧，早期空间存在匿名访问的这一个功能的，还是免费的，后来开始需要黄钻使用的，就是可以预先设置的好友，当里有权限访问她的空间的时候，不会出现在访客记录中，当然也不会计入今日访客数中。还有一个功能稍微弱一点，是差距很大，就是删除本次记录，网不好，但是会计入访客数中，还有QQ订阅了QQ空间的时候，有时候会提示你谁近期什么时间访问过空间，头大，不知道什么玩意儿。当然网上有匿名访问的方法，一般就是这个网站好用。http://www.qqxoo.com/，直接输入QQ就行了，需要好友权限的，根据教程查询自己的QQkey输入就行了，回答问题就输入答案就可以了；不要问我答案也不知道，权限也没有怎么办，只能说没办法。。毕竟空间诟病的地方就是权限复杂，最亮点的地方也是权限，折磨人。 外链音乐，上面的音乐都是要绿钻的，怎么才能使用免费的音乐了。添加网络背景音乐，可是网络上的链接经常失效，而且速度很慢，这个时候就需要网络的存储空间了，七牛云存储可以解决这个问题，把音乐上传上去，获取外链，复制到空间上，效果很好。 相册强大，但是不能做外链图床，可能做了反链了，经常加载不到，速度极差。 其实手机端不错的，电脑网页端，估计没人玩了吧。 属于我们老一辈人的记忆，就好好珍惜了，在互联网迅猛的时刻，但是国内大多数博客平台都覆灭了，很可惜。 最后，为了写笔记，自己弄了这个博客，主要是对外的，可以被搜索引擎抓取。QQ空间就是熟人间的交流了，有生之年，应该是不会放弃QQ空间这个产品（除非倒闭），它是一段记忆的象征。]]></content>
      <categories>
        <category>碎碎念</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于博客改动]]></title>
    <url>%2Ftest.html</url>
    <content type="text"><![CDATA[来到这个世界，被筛选，被挑剔，被赋予使命。我们被杀死，中途夭折，轻易放弃，多次失败，多次重头再来。变成暴躁的炸弹，变成美丽的花，我们恶心难堪，又美丽动人，充满希望，却又满是不堪。你用悲伤去看，这是一个充满死亡的地方。你用努力去看，这里充满了永不停歇的希望，人们都带着笑。诸君共勉 关于改动20170902将改成.com域名wuwii update20171009 以前这个用这个页面测试和调整一些样式，现在把它调整下，记录博客相关的设置改动。 博客图床使用的是七牛云，每月免费10G流量。我外链音乐也是放上面的，当然什么Js，css也可以使用它的CDN加速。 20171022 将一部分文章转入到个人位置，不再展示，一部分链接即将失效，会报错404，等到搜索引擎删除。 20171027 删除故事一栏，存入草稿箱，个人位置，以后整理再展示，链接失效。 20171102 突然发现10月17号手误把360验证网站权限删除了，360收录全没了，哭瞎。 20171108 隐藏掉一部分以前的日记，嘿嘿，私人日志不给看。 20171124 又发现了几个免费的图床，速度很好，推荐使用： https://sm.ms/ 极简图床但是七牛还是最稳定的，但是如果图片多而且大的话，特别是那种gif，很容易欠费的，扎心。 20171125 发现站内搜索挂了，准备更换，这个太不稳定了，即将删除评论系统，发现都是广告，没时间打理了。 20171126 网上查了下。最后决定使用algolia，把algolia搜索集成进来了，搜索的老毛病总算解决了。 Good things should last forever.]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fhello-world.html</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>测试</category>
      </categories>
      <tags>
        <tag>测试下</tag>
      </tags>
  </entry>
</search>
